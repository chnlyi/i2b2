{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:14:00.253071Z",
     "start_time": "2019-04-09T13:13:58.520195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import process_data, multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNGRU, CuDNNLSTM, GRU, LSTM, Reshape, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:14:00.263113Z",
     "start_time": "2019-04-09T13:14:00.255351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining some constants: \n",
    "window_size   = 7   # Window size for word2vec\n",
    "embed_size    = 30   # Length of the vector that we willl get from the embedding layer\n",
    "latent_dim    = 1024  # Hidden layers dimension \n",
    "dropout_rate  = 0.2   # Rate of the dropout layers\n",
    "batch_size    = 2    # Batch size\n",
    "epochs        = 30    # Number of epochs\n",
    "max_features  = 60000\n",
    "#maxlen        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:08.888566Z",
     "start_time": "2019-04-09T13:14:00.264847Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_train_1, labels_train_1, gold_labels_train_1 = process_data('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1', up=3) \n",
    "notes_train_2, labels_train_2, gold_labels_train_2 = process_data('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2', up=3) \n",
    "notes_train = notes_train_1 + notes_train_2\n",
    "labels_train = labels_train_1 + labels_train_2\n",
    "gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "notes_test, labels_test, gold_labels_test = process_data('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete') \n",
    "notes = notes_train + notes_test\n",
    "labels = labels_train + labels_test\n",
    "gold_labels = gold_labels_train + gold_labels_test\n",
    "notes_train = np.array(notes_train)\n",
    "notes_test = np.array(notes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:08.896939Z",
     "start_time": "2019-04-09T13:15:08.891455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 521 521 269 269 269 790 790 790 514 514 514 1304 1304 1304\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_train_1), \n",
    "      len(gold_labels_train_1), \n",
    "      len(notes_train_1),\n",
    "      \n",
    "      len(labels_train_2),\n",
    "      len(gold_labels_train_2), \n",
    "      len(notes_train_2),\n",
    "      \n",
    "      len(labels_train), \n",
    "      len(gold_labels_train),\n",
    "      len(notes_train),\n",
    "      \n",
    "      len(labels_test), \n",
    "      len(gold_labels_test), \n",
    "      len(notes_test),\n",
    "      \n",
    "      len(labels),\n",
    "      len(gold_labels),\n",
    "      len(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:10.269127Z",
     "start_time": "2019-04-09T13:15:08.899763Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(i) for i in notes])\n",
    "\n",
    "X_txt = [' '.join(i) for i in notes]\n",
    "X_train_txt = [' '.join(i) for i in notes_train]\n",
    "X_test_txt = [' '.join(i) for i in notes_test]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "tokenizer.fit_on_texts(X_txt)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X_txt) \n",
    "X_seq = pad_sequences(X_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_txt) \n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_txt) \n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:14.084919Z",
     "start_time": "2019-04-09T13:15:10.271257Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_embedding_matrix(embedding_index, word_index, max_features, embed_size):\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: \n",
    "            continue\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i-1] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# prepare embedding matrix\n",
    "w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, word_index=word_index, max_features=max_features, embed_size=embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:18.564307Z",
     "start_time": "2019-04-09T13:15:14.087550Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels = [label for notes_label in labels for label in notes_label]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(all_labels)\n",
    "l_train = []\n",
    "l_test = []\n",
    "for i in labels_train:\n",
    "    l = mlb.transform(i)\n",
    "    l_train.append(l)\n",
    "for i in labels_test:\n",
    "    l = mlb.transform(i)\n",
    "    l_test.append(l)\n",
    "    \n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_labels = len(mlb.classes_)\n",
    "for i in l_train:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_labels)), i))\n",
    "    Y_train.append(pad_i)\n",
    "for i in l_test:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_labels)), i))\n",
    "    Y_test.append(pad_i)    \n",
    "    \n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "all_gold_labels = [label for notes_label in gold_labels for label in notes_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:18.571076Z",
     "start_time": "2019-04-09T13:15:18.566471Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_labels(label):\n",
    "    c = '.'\n",
    "    positions = [pos for pos, char in enumerate(label) if char == c]\n",
    "    if label != 'O':\n",
    "        sl = slice(positions[0]+1,positions[1])\n",
    "        cat_label = label[sl]\n",
    "    else:\n",
    "        cat_label = label\n",
    "    return cat_label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:25.724957Z",
     "start_time": "2019-04-09T13:15:18.572903Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_labels = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels]\n",
    "cat_labels_train = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_train]\n",
    "cat_labels_test = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_test]\n",
    "\n",
    "all_cat_labels = [label for notes_label in cat_labels for label in notes_label]\n",
    "\n",
    "cat_mlb = MultiLabelBinarizer()\n",
    "cat_mlb.fit(all_cat_labels)\n",
    "l_cat_train = []\n",
    "l_cat_test = []\n",
    "for i in cat_labels_train:\n",
    "    l = cat_mlb.transform(i)\n",
    "    l_cat_train.append(l)\n",
    "for i in cat_labels_test:\n",
    "    l = cat_mlb.transform(i)\n",
    "    l_cat_test.append(l)\n",
    "    \n",
    "Y_cat_train = []\n",
    "Y_cat_test = []\n",
    "num_cat_labels = len(cat_mlb.classes_)\n",
    "for i in l_cat_train:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_cat_labels)), i))\n",
    "    Y_cat_train.append(pad_i)\n",
    "for i in l_cat_test:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_cat_labels)), i))\n",
    "    Y_cat_test.append(pad_i)    \n",
    "    \n",
    "Y_cat_train = np.array(Y_cat_train)\n",
    "Y_cat_test = np.array(Y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:25.743940Z",
     "start_time": "2019-04-09T13:15:25.727977Z"
    }
   },
   "outputs": [],
   "source": [
    "gmlb = MultiLabelBinarizer()\n",
    "gmlb.fit(gold_labels)\n",
    "num_gold_labels = len(gmlb.classes_)\n",
    "Y_gold_train = gmlb.transform(gold_labels_train)\n",
    "Y_gold_test = gmlb.transform(gold_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:25.750475Z",
     "start_time": "2019-04-09T13:15:25.745516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1304, 3674) (790, 3674) (514, 3674) (790, 3674, 97) (514, 3674, 97) 97 (790, 3674, 9) (514, 3674, 9) 9 (790, 96) (514, 96) 96\n"
     ]
    }
   ],
   "source": [
    "print(X_seq.shape, X_train_seq.shape, X_test_seq.shape, Y_train.shape, Y_test.shape, num_labels, Y_cat_train.shape, Y_cat_test.shape, num_cat_labels, Y_gold_train.shape, Y_gold_test.shape, num_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:25.758873Z",
     "start_time": "2019-04-09T13:15:25.752272Z"
    }
   },
   "outputs": [],
   "source": [
    "# model function with pretrained embedding matrix\n",
    "def get_model_1(nb_words, num_labels, model_type='CuDNNLSTM'):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.5)(x)\n",
    "    if model_type=='CuDNNGRU':\n",
    "        x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "    elif model_type=='GRU':\n",
    "        x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
    "    elif model_type=='CuDNNLSTM':\n",
    "        x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    elif model_type=='LSTM':\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    else:\n",
    "        raise ValueError('Please specify model_type as one of the following:n\\CuDNNGRU, CuDNNLSTM, GRU, LSTM')\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense((maxlen * num_labels), activation=\"sigmoid\")(conc)\n",
    "    outp = Reshape((maxlen, num_labels))(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:25.765860Z",
     "start_time": "2019-04-09T13:15:25.760076Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model metrics\n",
    "class CustomEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            y_pred_roc = y_pred.flatten()\n",
    "            y_pred_ham = (y_pred > 0.5).reshape((-1, y_pred.shape[2]))\n",
    "            y_val_roc = self.y_val.flatten()\n",
    "            y_val_ham = self.y_val.reshape((-1, self.y_val.shape[2]))\n",
    "            #print(y_val.sum(), y_pred.sum())\n",
    "            roc = roc_auc_score(y_val_roc, y_pred_roc)\n",
    "            ham = hamming_loss(y_val_ham, y_pred_ham)\n",
    "            sub = accuracy_score(y_val_ham, y_pred_ham)\n",
    "            print(\"Adiitional val metrics: - ROC-AUC: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f\" % (roc, ham, sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:15:28.259503Z",
     "start_time": "2019-04-09T13:15:25.767072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3674)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 3674, 30)     1349940     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 3674, 30)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 3674, 256)    163840      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 356378)       182821914   concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 3674, 97)     0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 184,335,694\n",
      "Trainable params: 184,335,694\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "# train the model\n",
    "model = get_model_1(nb_words=nb_words,num_labels=num_labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:46:33.175502Z",
     "start_time": "2019-04-09T13:16:08.450621Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 790 samples, validate on 514 samples\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 167s 212ms/step - loss: 0.0327 - acc: 0.9969 - val_loss: 0.0034 - val_acc: 0.9992\n",
      "Adiitional val metrics: - ROC-AUC: 0.987455 - Hamming-Loss: 0.000787 - Subset-Accuracy: 0.935685\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 164s 207ms/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0030 - val_acc: 0.9993\n",
      "Adiitional val metrics: - ROC-AUC: 0.988610 - Hamming-Loss: 0.000651 - Subset-Accuracy: 0.950401\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 164s 208ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0027 - val_acc: 0.9995\n",
      "Adiitional val metrics: - ROC-AUC: 0.988504 - Hamming-Loss: 0.000532 - Subset-Accuracy: 0.961680\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 163s 207ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0027 - val_acc: 0.9995\n",
      "Adiitional val metrics: - ROC-AUC: 0.988641 - Hamming-Loss: 0.000501 - Subset-Accuracy: 0.965343\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 163s 207ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0025 - val_acc: 0.9995\n",
      "Adiitional val metrics: - ROC-AUC: 0.988586 - Hamming-Loss: 0.000453 - Subset-Accuracy: 0.969710\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 164s 208ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0026 - val_acc: 0.9995\n",
      "Adiitional val metrics: - ROC-AUC: 0.988758 - Hamming-Loss: 0.000473 - Subset-Accuracy: 0.967786\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 165s 208ms/step - loss: 0.0048 - acc: 0.9990 - val_loss: 0.0025 - val_acc: 0.9995\n",
      "Adiitional val metrics: - ROC-AUC: 0.988825 - Hamming-Loss: 0.000486 - Subset-Accuracy: 0.966502\n"
     ]
    }
   ],
   "source": [
    "custevl = CustomEvaluation(validation_data=(X_test_seq, Y_test), interval=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=3e-4, patience=3, verbose=0, mode='auto')\n",
    "hist = model.fit(X_train_seq,Y_train, \n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(X_test_seq, Y_test),\n",
    "                 callbacks=[custevl, earlystop],\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:49:26.857456Z",
     "start_time": "2019-04-09T13:49:12.724854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1888432,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[1887909,       0],\n",
       "        [    527,       0]],\n",
       "\n",
       "       [[1888431,       0],\n",
       "        [      5,       0]],\n",
       "\n",
       "       [[1887168,       0],\n",
       "        [   1268,       0]],\n",
       "\n",
       "       [[1887904,       0],\n",
       "        [    532,       0]],\n",
       "\n",
       "       [[1888219,       0],\n",
       "        [    217,       0]],\n",
       "\n",
       "       [[1886768,       0],\n",
       "        [   1668,       0]],\n",
       "\n",
       "       [[1888362,       0],\n",
       "        [     74,       0]],\n",
       "\n",
       "       [[1887876,       0],\n",
       "        [    560,       0]],\n",
       "\n",
       "       [[1888296,       0],\n",
       "        [    140,       0]],\n",
       "\n",
       "       [[1888254,       0],\n",
       "        [    182,       0]],\n",
       "\n",
       "       [[1887288,       0],\n",
       "        [   1148,       0]],\n",
       "\n",
       "       [[1888040,       0],\n",
       "        [    396,       0]],\n",
       "\n",
       "       [[1888271,       0],\n",
       "        [    165,       0]],\n",
       "\n",
       "       [[1887288,       0],\n",
       "        [   1148,       0]],\n",
       "\n",
       "       [[1888396,       0],\n",
       "        [     40,       0]],\n",
       "\n",
       "       [[1888372,       0],\n",
       "        [     64,       0]],\n",
       "\n",
       "       [[1887281,       0],\n",
       "        [   1155,       0]],\n",
       "\n",
       "       [[1888222,       0],\n",
       "        [    214,       0]],\n",
       "\n",
       "       [[1888070,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[1888350,       0],\n",
       "        [     86,       0]],\n",
       "\n",
       "       [[1888386,       0],\n",
       "        [     50,       0]],\n",
       "\n",
       "       [[1888070,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[1888430,       0],\n",
       "        [      6,       0]],\n",
       "\n",
       "       [[1888425,       0],\n",
       "        [     11,       0]],\n",
       "\n",
       "       [[1888070,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[1887782,       0],\n",
       "        [    654,       0]],\n",
       "\n",
       "       [[1888323,       0],\n",
       "        [    113,       0]],\n",
       "\n",
       "       [[1887776,       0],\n",
       "        [    660,       0]],\n",
       "\n",
       "       [[1887790,       0],\n",
       "        [    646,       0]],\n",
       "\n",
       "       [[1887771,       0],\n",
       "        [    665,       0]],\n",
       "\n",
       "       [[1888037,       0],\n",
       "        [    399,       0]],\n",
       "\n",
       "       [[1888327,       0],\n",
       "        [    109,       0]],\n",
       "\n",
       "       [[1888432,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[1888436,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[1887981,       0],\n",
       "        [    455,       0]],\n",
       "\n",
       "       [[1887835,       0],\n",
       "        [    601,       0]],\n",
       "\n",
       "       [[1888218,       0],\n",
       "        [    218,       0]],\n",
       "\n",
       "       [[1888303,       0],\n",
       "        [    133,       0]],\n",
       "\n",
       "       [[1888415,       0],\n",
       "        [     21,       0]],\n",
       "\n",
       "       [[1888376,       0],\n",
       "        [     60,       0]],\n",
       "\n",
       "       [[1887948,       0],\n",
       "        [    488,       0]],\n",
       "\n",
       "       [[1888160,       0],\n",
       "        [    276,       0]],\n",
       "\n",
       "       [[1888424,       0],\n",
       "        [     12,       0]],\n",
       "\n",
       "       [[1888252,       0],\n",
       "        [    184,       0]],\n",
       "\n",
       "       [[1887924,       0],\n",
       "        [    512,       0]],\n",
       "\n",
       "       [[1888231,       0],\n",
       "        [    205,       0]],\n",
       "\n",
       "       [[1888390,       0],\n",
       "        [     46,       0]],\n",
       "\n",
       "       [[1888281,       0],\n",
       "        [    155,       0]],\n",
       "\n",
       "       [[1888066,       0],\n",
       "        [    370,       0]],\n",
       "\n",
       "       [[1888305,       0],\n",
       "        [    131,       0]],\n",
       "\n",
       "       [[1888432,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[1888436,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[1887983,       0],\n",
       "        [    453,       0]],\n",
       "\n",
       "       [[1887816,       0],\n",
       "        [    620,       0]],\n",
       "\n",
       "       [[1888216,       0],\n",
       "        [    220,       0]],\n",
       "\n",
       "       [[1888273,       0],\n",
       "        [    163,       0]],\n",
       "\n",
       "       [[1888422,       0],\n",
       "        [     14,       0]],\n",
       "\n",
       "       [[1888380,       0],\n",
       "        [     56,       0]],\n",
       "\n",
       "       [[1887969,       0],\n",
       "        [    467,       0]],\n",
       "\n",
       "       [[1888145,       0],\n",
       "        [    291,       0]],\n",
       "\n",
       "       [[1888425,       0],\n",
       "        [     11,       0]],\n",
       "\n",
       "       [[1888230,       0],\n",
       "        [    206,       0]],\n",
       "\n",
       "       [[1887920,       0],\n",
       "        [    516,       0]],\n",
       "\n",
       "       [[1888221,       0],\n",
       "        [    215,       0]],\n",
       "\n",
       "       [[1888377,       0],\n",
       "        [     59,       0]],\n",
       "\n",
       "       [[1888253,       0],\n",
       "        [    183,       0]],\n",
       "\n",
       "       [[1888086,       0],\n",
       "        [    350,       0]],\n",
       "\n",
       "       [[1888321,       0],\n",
       "        [    115,       0]],\n",
       "\n",
       "       [[1888432,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[1888436,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[1887967,       0],\n",
       "        [    469,       0]],\n",
       "\n",
       "       [[1887833,       0],\n",
       "        [    603,       0]],\n",
       "\n",
       "       [[1888226,       0],\n",
       "        [    210,       0]],\n",
       "\n",
       "       [[1888309,       0],\n",
       "        [    127,       0]],\n",
       "\n",
       "       [[1888422,       0],\n",
       "        [     14,       0]],\n",
       "\n",
       "       [[1888385,       0],\n",
       "        [     51,       0]],\n",
       "\n",
       "       [[1887967,       0],\n",
       "        [    469,       0]],\n",
       "\n",
       "       [[1888201,       0],\n",
       "        [    235,       0]],\n",
       "\n",
       "       [[1888429,       0],\n",
       "        [      7,       0]],\n",
       "\n",
       "       [[1888232,       0],\n",
       "        [    204,       0]],\n",
       "\n",
       "       [[1887952,       0],\n",
       "        [    484,       0]],\n",
       "\n",
       "       [[1888231,       0],\n",
       "        [    205,       0]],\n",
       "\n",
       "       [[1888391,       0],\n",
       "        [     45,       0]],\n",
       "\n",
       "       [[1888273,       0],\n",
       "        [    163,       0]],\n",
       "\n",
       "       [[1888433,       0],\n",
       "        [      3,       0]],\n",
       "\n",
       "       [[1888312,       0],\n",
       "        [    124,       0]],\n",
       "\n",
       "       [[1888433,       0],\n",
       "        [      3,       0]],\n",
       "\n",
       "       [[1888312,       0],\n",
       "        [    124,       0]],\n",
       "\n",
       "       [[1888400,       0],\n",
       "        [     36,       0]],\n",
       "\n",
       "       [[1888296,       0],\n",
       "        [    140,       0]],\n",
       "\n",
       "       [[1888225,       0],\n",
       "        [    211,       0]],\n",
       "\n",
       "       [[1888420,       0],\n",
       "        [     16,       0]],\n",
       "\n",
       "       [[1888102,       1],\n",
       "        [    333,       0]],\n",
       "\n",
       "       [[1887574,       0],\n",
       "        [    862,       0]],\n",
       "\n",
       "       [[1888226,       0],\n",
       "        [    210,       0]],\n",
       "\n",
       "       [[1549980,   37235],\n",
       "        [  24625,  276596]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test_seq)\n",
    "\n",
    "multilabel_confusion_matrix(Y_test.reshape((Y_test.shape[0]*Y_test.shape[1],-1)), np.where(Y_pred.reshape((Y_pred.shape[0]*Y_pred.shape[1],-1)) > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T13:50:18.533004Z",
     "start_time": "2019-04-09T13:50:18.003497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3674)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 3674, 30)     1349940     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 3674, 30)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 3674, 256)    163840      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 33066)        16962858    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 3674, 9)      0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,476,638\n",
      "Trainable params: 18,476,638\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "# train the model\n",
    "cat_model = get_model_1(nb_words=nb_words,num_labels=num_cat_labels)\n",
    "cat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T15:23:36.146992Z",
     "start_time": "2019-04-05T14:54:48.385142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 790 samples, validate on 514 samples\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 109s 138ms/step - loss: 0.0728 - acc: 0.9815 - val_loss: 0.0301 - val_acc: 0.9905\n",
      "Adiitional val metrics: - ROC-AUC: 0.988439 - Hamming-Loss: 0.009499 - Subset-Accuracy: 0.920057\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 107s 136ms/step - loss: 0.0442 - acc: 0.9843 - val_loss: 0.0308 - val_acc: 0.9889\n",
      "Adiitional val metrics: - ROC-AUC: 0.988487 - Hamming-Loss: 0.011072 - Subset-Accuracy: 0.906654\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 107s 136ms/step - loss: 0.0431 - acc: 0.9846 - val_loss: 0.0285 - val_acc: 0.9905\n",
      "Adiitional val metrics: - ROC-AUC: 0.989647 - Hamming-Loss: 0.009544 - Subset-Accuracy: 0.919907\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 108s 137ms/step - loss: 0.0418 - acc: 0.9851 - val_loss: 0.0300 - val_acc: 0.9881\n",
      "Adiitional val metrics: - ROC-AUC: 0.989043 - Hamming-Loss: 0.011908 - Subset-Accuracy: 0.899534\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 109s 137ms/step - loss: 0.0409 - acc: 0.9854 - val_loss: 0.0332 - val_acc: 0.9864\n",
      "Adiitional val metrics: - ROC-AUC: 0.989058 - Hamming-Loss: 0.013589 - Subset-Accuracy: 0.884658\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 107s 136ms/step - loss: 0.0398 - acc: 0.9858 - val_loss: 0.0267 - val_acc: 0.9910\n",
      "Adiitional val metrics: - ROC-AUC: 0.990281 - Hamming-Loss: 0.009002 - Subset-Accuracy: 0.924854\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 108s 137ms/step - loss: 0.0354 - acc: 0.9880 - val_loss: 0.0214 - val_acc: 0.9939\n",
      "Adiitional val metrics: - ROC-AUC: 0.992128 - Hamming-Loss: 0.006139 - Subset-Accuracy: 0.951179\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 110s 139ms/step - loss: 0.0310 - acc: 0.9902 - val_loss: 0.0207 - val_acc: 0.9936\n",
      "Adiitional val metrics: - ROC-AUC: 0.992610 - Hamming-Loss: 0.006449 - Subset-Accuracy: 0.948426\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 108s 136ms/step - loss: 0.0284 - acc: 0.9912 - val_loss: 0.0180 - val_acc: 0.9948\n",
      "Adiitional val metrics: - ROC-AUC: 0.993459 - Hamming-Loss: 0.005202 - Subset-Accuracy: 0.960009\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 105s 134ms/step - loss: 0.0267 - acc: 0.9920 - val_loss: 0.0169 - val_acc: 0.9953\n",
      "Adiitional val metrics: - ROC-AUC: 0.993655 - Hamming-Loss: 0.004672 - Subset-Accuracy: 0.964582\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 103s 130ms/step - loss: 0.0260 - acc: 0.9923 - val_loss: 0.0184 - val_acc: 0.9945\n",
      "Adiitional val metrics: - ROC-AUC: 0.993577 - Hamming-Loss: 0.005518 - Subset-Accuracy: 0.957145\n",
      "Epoch 12/30\n",
      "790/790 [==============================] - 103s 130ms/step - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0165 - val_acc: 0.9956\n",
      "Adiitional val metrics: - ROC-AUC: 0.993802 - Hamming-Loss: 0.004445 - Subset-Accuracy: 0.966748\n",
      "Epoch 13/30\n",
      "790/790 [==============================] - 101s 127ms/step - loss: 0.0246 - acc: 0.9928 - val_loss: 0.0170 - val_acc: 0.9958\n",
      "Adiitional val metrics: - ROC-AUC: 0.993823 - Hamming-Loss: 0.004233 - Subset-Accuracy: 0.968740\n",
      "Epoch 14/30\n",
      "790/790 [==============================] - 103s 130ms/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.0175 - val_acc: 0.9952\n",
      "Adiitional val metrics: - ROC-AUC: 0.993620 - Hamming-Loss: 0.004769 - Subset-Accuracy: 0.964133\n",
      "Epoch 15/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0238 - acc: 0.9930 - val_loss: 0.0178 - val_acc: 0.9951\n",
      "Adiitional val metrics: - ROC-AUC: 0.993497 - Hamming-Loss: 0.004946 - Subset-Accuracy: 0.962235\n"
     ]
    }
   ],
   "source": [
    "custevl = CustomEvaluation(validation_data=(X_test_seq, Y_cat_test), interval=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=3e-4, patience=3, verbose=0, mode='auto')\n",
    "hist = cat_model.fit(X_train_seq,Y_cat_train, \n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(X_test_seq, Y_cat_test),\n",
    "                 callbacks=[custevl, earlystop],\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T12:42:40.186365Z",
     "start_time": "2019-04-08T12:42:37.537034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1884398,       0],\n",
       "        [   4038,       0]],\n",
       "\n",
       "       [[1886629,       0],\n",
       "        [   1807,       0]],\n",
       "\n",
       "       [[1888222,       0],\n",
       "        [    214,       0]],\n",
       "\n",
       "       [[1887919,       0],\n",
       "        [    517,       0]],\n",
       "\n",
       "       [[1887020,       0],\n",
       "        [   1416,       0]],\n",
       "\n",
       "       [[1883990,       0],\n",
       "        [   4446,       0]],\n",
       "\n",
       "       [[1543537,   43678],\n",
       "        [  26137,  275084]],\n",
       "\n",
       "       [[1888261,       0],\n",
       "        [    175,       0]],\n",
       "\n",
       "       [[1886804,       0],\n",
       "        [   1632,       0]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat_pred = cat_model.predict(X_test_seq)\n",
    "\n",
    "multilabel_confusion_matrix(Y_cat_test.reshape((Y_cat_test.shape[0]*Y_cat_test.shape[1],-1)), np.where(Y_cat_pred.reshape((Y_cat_pred.shape[0]*Y_cat_pred.shape[1],-1)) > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
