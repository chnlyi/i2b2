{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T17:28:38.590507Z",
     "start_time": "2019-05-06T17:28:36.513097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "# from keras.callbacks import Callback, EarlyStopping\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNGRU, CuDNNLSTM, GRU, LSTM, Reshape, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from utils import process_data, multilabel_confusion_matrix, get_embedding_matrix, get_cat_labels, data_generator, get_all\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T17:28:38.602869Z",
     "start_time": "2019-05-06T17:28:38.592712Z"
    }
   },
   "outputs": [],
   "source": [
    "class torch_tagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        if embedding_matrix is None:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            weight = torch.FloatTensor(embedding_matrix)\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(weight)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = torch.sigmoid(tag_space)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T17:28:38.611642Z",
     "start_time": "2019-05-06T17:28:38.604776Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T17:50:15.883230Z",
     "start_time": "2019-05-06T17:50:15.846428Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_pad_time_tuning(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test, verbose=1):\n",
    "    \n",
    "    up = int(param['up'])\n",
    "    window_size = int(param['window_size'])\n",
    "    embed_size = int(param['embed_size'] * 10)\n",
    "    latent_dim = int(param['latent_dim'] * 64)\n",
    "    dropout_rate = param['dropout_rate']\n",
    "    epochs = 30 #param['epochs']\n",
    "    max_features = 60000 #param['max_features']\n",
    "    category = False #param['category']\n",
    "    embedding = True #param['embedding']\n",
    "    model_type = 'CuDNNLSTM' #param['model_type']\n",
    "    \n",
    "    # upsampling\n",
    "    if up > 0:\n",
    "        if verbose != 0: print('upsampling for %d times...' % (up))\n",
    "        notes_train = [note + up * up_note for note, up_note in zip(notes_train, up_notes_train)]\n",
    "        labels_train = [label + up * up_label for label, up_label in zip(labels_train, up_labels_train)]\n",
    "        if verbose != 0: print('upsampling done\\n')\n",
    "    notes = notes_train + notes_test\n",
    "    labels = labels_train + labels_test\n",
    "    gold_labels = gold_labels_train + gold_labels_test\n",
    "    \n",
    "    # prepare features\n",
    "    if verbose != 0: print('preparing features ...')\n",
    "    X_txt = [' '.join(i) for i in notes]\n",
    "    X_train_txt = [' '.join(i) for i in notes_train]\n",
    "    X_test_txt = [' '.join(i) for i in notes_test]\n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "    tokenizer.fit_on_texts(X_txt)\n",
    "    X_seq = tokenizer.texts_to_sequences(X_txt) \n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train_txt) \n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test_txt) \n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    if verbose != 0: print('preparing features done\\n')\n",
    "\n",
    "    # prepare embedding matrix\n",
    "    if embedding:\n",
    "        if verbose != 0: print('preparing embedding matrix ...')\n",
    "        w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "        embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "        embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, word_index=word_index, max_features=max_features, embed_size=embed_size)\n",
    "        if verbose != 0: print('preparing embedding matrix done\\n')\n",
    "        \n",
    "    # prepare targets\n",
    "    if verbose != 0: print('preparing targets ...')\n",
    "    if category:\n",
    "        # prepare cagtegory label targets\n",
    "        labels = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels]\n",
    "        labels_train = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_train]\n",
    "        labels_test = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_test]\n",
    "    all_labels = [label for notes_label in labels for label in notes_label]\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(all_labels)\n",
    "    num_labels = len(mlb.classes_)\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    for i in labels_train:\n",
    "        l = mlb.transform(i)\n",
    "        Y_train.append(l)\n",
    "    for i in labels_test:\n",
    "        l = mlb.transform(i)\n",
    "        Y_test.append(l)\n",
    "    if verbose != 0: print('preparing targets done\\n')\n",
    "\n",
    "    # model summary\n",
    "    model = torch_tagger(embed_size, latent_dim, nb_words, num_labels, embedding_matrix).cuda()\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "    early_stopping = EarlyStopping(patience=1, verbose=True)\n",
    "    if verbose != 0: print('\\nmodel summary:')\n",
    "    if verbose != 0: print(model)\n",
    "\n",
    "    # model training\n",
    "    if verbose != 0: print('\\ntraining model ...')\n",
    "    for epoch in tnrange(epochs):  \n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for x, y in tqdm_notebook(zip(X_train_seq, Y_train), total=len(Y_train)):\n",
    "            optimizer.zero_grad()\n",
    "            sentence_in = torch.tensor(x).cuda()\n",
    "            targets = torch.FloatTensor(y).cuda()\n",
    "            tag_scores = model(sentence_in)\n",
    "            loss = loss_function(tag_scores, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss/len(Y_train)\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        model.eval()\n",
    "        Y_pred = []\n",
    "        for i, (x, y) in tqdm_notebook(enumerate(zip(X_test_seq[:513], Y_test[:513])), total=len(Y_test[:513])):   \n",
    "            sentence_in = torch.tensor(x).cuda()\n",
    "            targets = torch.FloatTensor(y).cuda()\n",
    "            tag_scores = model(sentence_in)\n",
    "            loss = loss_function(tag_scores, targets)\n",
    "            valid_loss += loss.item()# * sentence_in.size(0)\n",
    "            Y_pred.append(tag_scores.detach().cpu().numpy())\n",
    "        valid_loss = valid_loss/len(Y_test[:513])\n",
    "        Y_pred_concat = np.concatenate(Y_pred)\n",
    "        Y_pred_ham = Y_pred_concat > 0.5\n",
    "        Y_val = np.concatenate(Y_test[:513])\n",
    "        roc = roc_auc_score(Y_val, Y_pred_concat, average='micro')\n",
    "        loss = log_loss(Y_val, Y_pred_concat)\n",
    "        ham = hamming_loss(Y_val, Y_pred_ham)\n",
    "        sub = accuracy_score(Y_val, Y_pred_ham)\n",
    "        f1 = f1_score(Y_val, Y_pred_ham, average='micro')\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch + 1, train_loss, valid_loss))\n",
    "        print(\"Adiitional val metrics: - ROC-AUC: %.6f - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1-Score: %.6f\" % (roc, loss, ham, sub, f1))\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # confusion matrix \n",
    "    if verbose == 2: \n",
    "        cm = multilabel_confusion_matrix(Y_val, np.where(Y_pred_concat > 0.5, 1, 0))\n",
    "        for i, j in zip(cm, mlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # prepare gold label targets\n",
    "    if verbose != 0: print('predicting gold label targets ...')\n",
    "    gold_labels_pred = [{i for s in mlb.inverse_transform(y_pred>0.5) for i in s if i != 'O'} for y_pred in Y_pred]\n",
    "    gmlb = MultiLabelBinarizer()\n",
    "    gmlb.fit(gold_labels)\n",
    "    num_gold_labels = len(gmlb.classes_)\n",
    "    Y_gold_test = gmlb.transform(gold_labels_test[:513])\n",
    "    Y_gold_pred = gmlb.transform(gold_labels_pred)\n",
    "    if verbose != 0: print('predicting gold label targets done\\n')\n",
    "\n",
    "    # confusion matrix for gold label\n",
    "    if verbose == 2: \n",
    "        gcm = multilabel_confusion_matrix(np.concatenate(Y_gold_test), np.concatenate(Y_gold_pred))\n",
    "        for i, j in zip(gcm, gmlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # f1 scores for gold label\n",
    "    f1 = f1_score(Y_gold_test, Y_gold_pred, average='micro')\n",
    "    print('Parameters: up = %d, window_size = %d, embed_size = %d, latent_dim = %d, dropout_rate = %.3f' % (up, window_size, embed_size, latent_dim, dropout_rate))\n",
    "    print('F1 Scores for global labels:\\nALL (average=\"micro\"):', f1)\n",
    "    \n",
    "    with open(\"results.txt\",\"a\") as f:\n",
    "        f.write('Parameters: up = %d, window_size = %d, embed_size = %d, latent_dim = %d, dropout_rate = %.3f\\n' % (up, window_size, embed_size, latent_dim, dropout_rate))\n",
    "        f.write('F1 Scores for global labels(average=\"micro\"): %.3f\\n' % f1)\n",
    "        \n",
    "    \n",
    "    if verbose == 2: \n",
    "        f1_all = f1_score(Y_gold_test, Y_gold_pred, average=None)\n",
    "        for i, j in zip(f1_all, gmlb.classes_):\n",
    "            print(j+': '+str(i))\n",
    "    \n",
    "    print('\\n\\n')\n",
    "          \n",
    "    return f1\n",
    "\n",
    "def my_bayes_opt(space):\n",
    "    param = {\n",
    "        'up': space[0],               # Times of upsampling for training data\n",
    "        'window_size': space[1],                # Window size for word2vec\n",
    "        'embed_size': space[2],                # Length of the vector that we willl get from the embedding layer\n",
    "        'latent_dim': space[3],               # Hidden layers dimension \n",
    "        'dropout_rate': space[4]}#,             # Rate of the dropout layers\n",
    "        #'epochs': space[0],                    # Number of epochs\n",
    "        #'max_features': space[0],           # Max num of vocabulary\n",
    "        #'category': space[0],               # Is categoty labels\n",
    "        #'embedding': space[0],               # Using pre-made embedidng matrix as weight\n",
    "        #'model_type': space[0]\n",
    "        #}\n",
    "    f1 = no_pad_time_tuning(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test)\n",
    "    return (-f1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T18:49:58.673368Z",
     "start_time": "2019-05-06T17:50:17.633449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32420a8c0503445487cbcbfb69c66384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=521), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed38cfe07234e1b8c691c7e7553f77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=269), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73969bb988af43c5a39eda7df7f693b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=514), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at provided point.\n",
      "upsampling for 7 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 30)\n",
      "  (lstm): LSTM(30, 128, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=256, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed76f73ffdf48cf84e90879eb8f73dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af10ab74d70d45cfa2e107c548b28351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6422a2993cdf4ce2b257f42b22ab0ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.022368 \tValidation Loss: 0.012923\n",
      "Adiitional val metrics: - ROC-AUC: 0.986336 - Log-Loss: 0.774920 - Hamming-Loss: 0.002058 - Subset-Accuracy: 0.885362 - F1-Score: 0.901327\n",
      "Validation loss decreased (inf --> 0.012923).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d9a911a092492a9c7327aed01d7af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4847d5eb227b453a8c5540b945cd6386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.015518 \tValidation Loss: 0.011680\n",
      "Adiitional val metrics: - ROC-AUC: 0.988547 - Log-Loss: 0.687468 - Hamming-Loss: 0.001806 - Subset-Accuracy: 0.904391 - F1-Score: 0.914064\n",
      "Validation loss decreased (0.012923 --> 0.011680).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff6aa2a8bb2478e8eea8b2206998813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ab5bfc9d441f59b666fbc63868ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.015897 \tValidation Loss: 0.010327\n",
      "Adiitional val metrics: - ROC-AUC: 0.988855 - Log-Loss: 0.647933 - Hamming-Loss: 0.001695 - Subset-Accuracy: 0.905144 - F1-Score: 0.919009\n",
      "Validation loss decreased (0.011680 --> 0.010327).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aea0cac57ca4569b57c53b548bee523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c762f0e8be24b1d98d059aa157171be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.014226 \tValidation Loss: 0.009761\n",
      "Adiitional val metrics: - ROC-AUC: 0.989663 - Log-Loss: 0.608024 - Hamming-Loss: 0.001645 - Subset-Accuracy: 0.909576 - F1-Score: 0.921709\n",
      "Validation loss decreased (0.010327 --> 0.009761).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c818718cb9eb46cd9ab12cfc0df1ca3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02ff59e7f1b418c9fbffc0bdfa5f939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.013841 \tValidation Loss: 0.009204\n",
      "Adiitional val metrics: - ROC-AUC: 0.990611 - Log-Loss: 0.579300 - Hamming-Loss: 0.001606 - Subset-Accuracy: 0.912560 - F1-Score: 0.923808\n",
      "Validation loss decreased (0.009761 --> 0.009204).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95543869d1a4f83a1ab6bad67ad1e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf01a08934449b0a8c8d02c2616d94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.013586 \tValidation Loss: 0.009110\n",
      "Adiitional val metrics: - ROC-AUC: 0.990926 - Log-Loss: 0.576213 - Hamming-Loss: 0.001592 - Subset-Accuracy: 0.916986 - F1-Score: 0.924477\n",
      "Validation loss decreased (0.009204 --> 0.009110).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae0a1fcd7d24909b8bd4d249817de86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259291b4416640cb8dea85db4511aca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.013398 \tValidation Loss: 0.008954\n",
      "Adiitional val metrics: - ROC-AUC: 0.991174 - Log-Loss: 0.561094 - Hamming-Loss: 0.001583 - Subset-Accuracy: 0.923563 - F1-Score: 0.925333\n",
      "Validation loss decreased (0.009110 --> 0.008954).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4842715ea284db59f9f50a5c92bc8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702347c9bc3a4c99b7624fcd34d733db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 0.013170 \tValidation Loss: 0.008990\n",
      "Adiitional val metrics: - ROC-AUC: 0.991001 - Log-Loss: 0.566231 - Hamming-Loss: 0.001408 - Subset-Accuracy: 0.931919 - F1-Score: 0.933637\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 7, window_size = 4, embed_size = 30, latent_dim = 128, dropout_rate = 0.153\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.7711388916231912\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at provided point.\n",
      "Time taken: 762.4931\n",
      "Function value obtained: -0.7711\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "upsampling for 8 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 40)\n",
      "  (lstm): LSTM(40, 64, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=128, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ce0e1d7024be9ac1fa34b6788efac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7ded9a8c2b4a1c9c6019512f0a8510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bb0825ac784c6fa614af81a1e87ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.016671 \tValidation Loss: 0.008647\n",
      "Adiitional val metrics: - ROC-AUC: 0.988570 - Log-Loss: 0.558212 - Hamming-Loss: 0.001421 - Subset-Accuracy: 0.934099 - F1-Score: 0.932847\n",
      "Validation loss decreased (inf --> 0.008647).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f28f6022fd477cb470e5751e56bb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2e2d657b434305b9d29f29f7583527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.014185 \tValidation Loss: 0.008612\n",
      "Adiitional val metrics: - ROC-AUC: 0.989489 - Log-Loss: 0.550260 - Hamming-Loss: 0.001508 - Subset-Accuracy: 0.931532 - F1-Score: 0.928927\n",
      "Validation loss decreased (0.008647 --> 0.008612).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79356f90f754d7fb8491a52bdc050f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9796bd6f1f9b450bbafb6cab7197a04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.014016 \tValidation Loss: 0.008364\n",
      "Adiitional val metrics: - ROC-AUC: 0.989819 - Log-Loss: 0.543896 - Hamming-Loss: 0.001381 - Subset-Accuracy: 0.938798 - F1-Score: 0.935247\n",
      "Validation loss decreased (0.008612 --> 0.008364).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad115d7eb51a4937ab93f3cf5ec3e5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504426a188b54123be75d16b3e06281a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.013447 \tValidation Loss: 0.007607\n",
      "Adiitional val metrics: - ROC-AUC: 0.990557 - Log-Loss: 0.504366 - Hamming-Loss: 0.001332 - Subset-Accuracy: 0.940107 - F1-Score: 0.937429\n",
      "Validation loss decreased (0.008364 --> 0.007607).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e26367247242db8e2717c929e4ee4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1012387d38a24bf285cc5d7ca0b5a823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.013209 \tValidation Loss: 0.007226\n",
      "Adiitional val metrics: - ROC-AUC: 0.991396 - Log-Loss: 0.475058 - Hamming-Loss: 0.001281 - Subset-Accuracy: 0.946090 - F1-Score: 0.939936\n",
      "Validation loss decreased (0.007607 --> 0.007226).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aa32ea59b747a38b990764afb7234a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dad8a9945684c0e8ff54ee987fd855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.013187 \tValidation Loss: 0.007141\n",
      "Adiitional val metrics: - ROC-AUC: 0.991501 - Log-Loss: 0.475944 - Hamming-Loss: 0.001316 - Subset-Accuracy: 0.942160 - F1-Score: 0.938140\n",
      "Validation loss decreased (0.007226 --> 0.007141).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbc46d0274b4fe28a30173e3c37a3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cccf94a47149a3a7539902084df935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.013196 \tValidation Loss: 0.007596\n",
      "Adiitional val metrics: - ROC-AUC: 0.991080 - Log-Loss: 0.506588 - Hamming-Loss: 0.001392 - Subset-Accuracy: 0.939500 - F1-Score: 0.934742\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 8, window_size = 5, embed_size = 40, latent_dim = 64, dropout_rate = 0.297\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.7354877318970677\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 709.7175\n",
      "Function value obtained: -0.7355\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "upsampling for 8 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 40)\n",
      "  (lstm): LSTM(40, 128, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=256, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ce19953757419399cc25a8410cf05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1b79b68a7f4193a804e8e4ede5f348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f96f7a79f0c447c9674237148670835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.028099 \tValidation Loss: 0.016114\n",
      "Adiitional val metrics: - ROC-AUC: 0.982421 - Log-Loss: 0.890014 - Hamming-Loss: 0.003638 - Subset-Accuracy: 0.735004 - F1-Score: 0.811815\n",
      "Validation loss decreased (inf --> 0.016114).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0210c0cd0942d4a5a6e2b91af7f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155c45aaf3094cfebf7d494d261bb0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.024872 \tValidation Loss: 0.018060\n",
      "Adiitional val metrics: - ROC-AUC: 0.983234 - Log-Loss: 1.021701 - Hamming-Loss: 0.003782 - Subset-Accuracy: 0.733800 - F1-Score: 0.807580\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 8, window_size = 6, embed_size = 40, latent_dim = 128, dropout_rate = 0.121\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.6857199960027981\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 209.8879\n",
      "Function value obtained: -0.6857\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "upsampling for 7 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 30)\n",
      "  (lstm): LSTM(30, 64, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=128, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b4462b7fe2402b8f81de9094192b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda9c4023c814e9abd069df4640de2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a448cd45b8da4a96baaa5118ec17caf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.018992 \tValidation Loss: 0.010172\n",
      "Adiitional val metrics: - ROC-AUC: 0.986542 - Log-Loss: 0.651104 - Hamming-Loss: 0.001737 - Subset-Accuracy: 0.898859 - F1-Score: 0.916386\n",
      "Validation loss decreased (inf --> 0.010172).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e897ba314ce34bd2a8581ec985e09a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bec90c980c1470b80266d5451f3b83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.013909 \tValidation Loss: 0.008102\n",
      "Adiitional val metrics: - ROC-AUC: 0.990140 - Log-Loss: 0.520882 - Hamming-Loss: 0.001400 - Subset-Accuracy: 0.931474 - F1-Score: 0.933702\n",
      "Validation loss decreased (0.010172 --> 0.008102).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e2ded507cf421a8c128c8edb7ae9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc06451b9ae4b5a9e8cdea97cfbb4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.013314 \tValidation Loss: 0.008548\n",
      "Adiitional val metrics: - ROC-AUC: 0.990866 - Log-Loss: 0.516490 - Hamming-Loss: 0.001407 - Subset-Accuracy: 0.934235 - F1-Score: 0.933742\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 7, window_size = 7, embed_size = 30, latent_dim = 64, dropout_rate = 0.027\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.7470078415187783\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 293.5831\n",
      "Function value obtained: -0.7470\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "upsampling for 10 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 20)\n",
      "  (lstm): LSTM(20, 192, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=384, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36970e6995414afbab6be7d22941dc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340b2d8eff4f4ffdbd46c37d3402605a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8241a836b02c4aa4a4eece171baa91a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.148219 \tValidation Loss: 0.050750\n",
      "Adiitional val metrics: - ROC-AUC: 0.951990 - Log-Loss: 2.912338 - Hamming-Loss: 0.001444 - Subset-Accuracy: 0.938442 - F1-Score: 0.930547\n",
      "Validation loss decreased (inf --> 0.050750).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d68fbfff6d04961bb795794e0d1c8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9000d87f60644bfe9f1938a99411b396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.144231 \tValidation Loss: 0.047240\n",
      "Adiitional val metrics: - ROC-AUC: 0.954683 - Log-Loss: 2.911936 - Hamming-Loss: 0.001469 - Subset-Accuracy: 0.935281 - F1-Score: 0.929196\n",
      "Validation loss decreased (0.050750 --> 0.047240).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965de670f92e4f5e9211b9297ddac5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d603bbe4996f40ae8a02bf751c5e80b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.144777 \tValidation Loss: 0.056175\n",
      "Adiitional val metrics: - ROC-AUC: 0.946450 - Log-Loss: 2.974676 - Hamming-Loss: 0.001353 - Subset-Accuracy: 0.954923 - F1-Score: 0.935716\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 10, window_size = 7, embed_size = 20, latent_dim = 192, dropout_rate = 0.002\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.0\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 337.6461\n",
      "Function value obtained: -0.0000\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "upsampling for 10 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 40)\n",
      "  (lstm): LSTM(40, 64, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=128, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2c8f08c5b144f38043552a67164181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc55985cabf4c6c909f875a48edb611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc18271b684ce6acbfdbf9db9bcf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.017149 \tValidation Loss: 0.007977\n",
      "Adiitional val metrics: - ROC-AUC: 0.988237 - Log-Loss: 0.529148 - Hamming-Loss: 0.001432 - Subset-Accuracy: 0.933648 - F1-Score: 0.932355\n",
      "Validation loss decreased (inf --> 0.007977).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6326b53136f4444f8f547c50923889ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd9a26c04646f0b5492647edeb266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.014147 \tValidation Loss: 0.008419\n",
      "Adiitional val metrics: - ROC-AUC: 0.990216 - Log-Loss: 0.540097 - Hamming-Loss: 0.001956 - Subset-Accuracy: 0.876011 - F1-Score: 0.904792\n",
      "EarlyStopping counter: 1 out of 1\n",
      "Early stopping\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up = 10, window_size = 5, embed_size = 40, latent_dim = 64, dropout_rate = 0.113\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.762418334543192\n",
      "\n",
      "\n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 230.0612\n",
      "Function value obtained: -0.7624\n",
      "Current minimum: -0.7711\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "upsampling for 10 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "torch_tagger(\n",
      "  (word_embeddings): Embedding(44984, 30)\n",
      "  (lstm): LSTM(30, 192, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=384, out_features=97, bias=True)\n",
      ")\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31fd2ec5ff1497181cb39fa612348d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf741e8f3acb4735b07529c4affeee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04171534c4e4a22968dd93711e064ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.073289 \tValidation Loss: 0.021297\n",
      "Adiitional val metrics: - ROC-AUC: 0.975961 - Log-Loss: 1.332075 - Hamming-Loss: 0.003228 - Subset-Accuracy: 0.786829 - F1-Score: 0.849224\n",
      "Validation loss decreased (inf --> 0.021297).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ecaf3b65df45998badbdec3a3f7127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34358b2a740b4587beb7b472c0b4b95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.025119 \tValidation Loss: 0.011609\n",
      "Adiitional val metrics: - ROC-AUC: 0.986752 - Log-Loss: 0.756394 - Hamming-Loss: 0.001920 - Subset-Accuracy: 0.895227 - F1-Score: 0.909264\n",
      "Validation loss decreased (0.021297 --> 0.011609).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c32ef1fc5d94cc48dffa84fdc4de33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ae844d972e4a0f9353c4838d902a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.016734 \tValidation Loss: 0.009559\n",
      "Adiitional val metrics: - ROC-AUC: 0.989191 - Log-Loss: 0.612168 - Hamming-Loss: 0.001572 - Subset-Accuracy: 0.917672 - F1-Score: 0.925575\n",
      "Validation loss decreased (0.011609 --> 0.009559).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3090295748c54f2aa585a0877ab9ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fba8c2cf5b74294bce7243e267f7ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.015467 \tValidation Loss: 0.009491\n",
      "Adiitional val metrics: - ROC-AUC: 0.990146 - Log-Loss: 0.605044 - Hamming-Loss: 0.001593 - Subset-Accuracy: 0.915187 - F1-Score: 0.924906\n",
      "Validation loss decreased (0.009559 --> 0.009491).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f099dbf5eac474fb8a8eba4b814e385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22dc3b0f9764281806b29f8f74c4a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.015503 \tValidation Loss: 0.008939\n",
      "Adiitional val metrics: - ROC-AUC: 0.989439 - Log-Loss: 0.564650 - Hamming-Loss: 0.001572 - Subset-Accuracy: 0.920271 - F1-Score: 0.925805\n",
      "Validation loss decreased (0.009491 --> 0.008939).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee5539dcb6c48908e14c5cae1d3f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a62c421c1d94a4c960cca12d2b2840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.015289 \tValidation Loss: 0.008414\n",
      "Adiitional val metrics: - ROC-AUC: 0.991062 - Log-Loss: 0.538514 - Hamming-Loss: 0.001477 - Subset-Accuracy: 0.933241 - F1-Score: 0.931055\n",
      "Validation loss decreased (0.008939 --> 0.008414).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c87e8a31664438bd56514f86643326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc22995bb14f148cae1bde94e83408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.014602 \tValidation Loss: 0.007986\n",
      "Adiitional val metrics: - ROC-AUC: 0.991179 - Log-Loss: 0.519201 - Hamming-Loss: 0.001391 - Subset-Accuracy: 0.936202 - F1-Score: 0.934896\n",
      "Validation loss decreased (0.008414 --> 0.007986).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa88fca61274b3895766119adb324cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4767b7e4a124c9fb3c27326ba57813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 0.014494 \tValidation Loss: 0.007514\n",
      "Adiitional val metrics: - ROC-AUC: 0.991569 - Log-Loss: 0.497915 - Hamming-Loss: 0.001251 - Subset-Accuracy: 0.942900 - F1-Score: 0.941369\n",
      "Validation loss decreased (0.007986 --> 0.007514).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab8bb75b964f6a821dd8bd02123b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1971503fd9f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#Categorical(['CuDNNLSTM'], name='model_type')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15253569878187465\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_bayes_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# python command: python heart_no_pad_bayes_opt.py > result_heart_no_pad_bayes_opt.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-720bf14ef803>\u001b[0m in \u001b[0;36mmy_bayes_opt\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m#'model_type': space[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_pad_time_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_notes_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_labels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-720bf14ef803>\u001b[0m in \u001b[0;36mno_pad_time_tuning\u001b[0;34m(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test, verbose)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # loading data \n",
    "    notes_train_1, labels_train_1, up_notes_train_1, up_labels_train_1, gold_labels_train_1 = get_all('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1') \n",
    "    notes_train_2, labels_train_2, up_notes_train_2, up_labels_train_2, gold_labels_train_2 = get_all('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2') \n",
    "\n",
    "    notes_train = notes_train_1 + notes_train_2\n",
    "    labels_train = labels_train_1 + labels_train_2\n",
    "    up_notes_train = up_notes_train_1 + up_notes_train_2\n",
    "    up_labels_train = up_labels_train_1 + up_labels_train_2\n",
    "    gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "\n",
    "    notes_test, labels_test, _1, _2, gold_labels_test = get_all('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete') \n",
    "\n",
    "    space = [Integer(5, 10, name='up'),\n",
    "            Integer(3, 7, name='window_size'),\n",
    "            Integer(2, 4, name='embed_size'),\n",
    "            Integer(1, 3, name='latent_dim'),\n",
    "            Real(0, 0.3, name='dropout_rate')]\n",
    "            #Integer(30, 30, name='epochs'),\n",
    "            #Integer(1, 60000, name='max_features'),\n",
    "            #Categorical([False], name='category'),\n",
    "            #Categorical([True], name='embedding'),\n",
    "            #Categorical(['CuDNNLSTM'], name='model_type')]\n",
    "    x0 = [7, 4, 3, 2, 0.15253569878187465]\n",
    "    res = gp_minimize(my_bayes_opt, space, x0=x0, n_calls=100, verbose=True)\n",
    "    \n",
    "    # python command: python heart_no_pad_bayes_opt.py > result_heart_no_pad_bayes_opt.txt\n",
    "    \n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
