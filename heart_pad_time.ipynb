{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:13:33.651374Z",
     "start_time": "2019-04-09T20:13:32.018928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import process_data, multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNGRU, CuDNNLSTM, GRU, LSTM, Reshape, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:13:49.976572Z",
     "start_time": "2019-04-09T20:13:49.959000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining some constants: \n",
    "window_size   = 5   # Window size for word2vec\n",
    "embed_size    = 10   # Length of the vector that we willl get from the embedding layer\n",
    "latent_dim    = 1024  # Hidden layers dimension \n",
    "dropout_rate  = 0.2   # Rate of the dropout layers\n",
    "batch_size    = 2    # Batch size\n",
    "epochs        = 30    # Number of epochs\n",
    "max_features  = 60000\n",
    "#maxlen        = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:14:57.914440Z",
     "start_time": "2019-04-09T20:13:51.543388Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_train_1, labels_train_1, gold_labels_train_1 = process_data('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1', up=3) \n",
    "notes_train_2, labels_train_2, gold_labels_train_2 = process_data('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2', up=3) \n",
    "notes_train = notes_train_1 + notes_train_2\n",
    "labels_train = labels_train_1 + labels_train_2\n",
    "gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "notes_test, labels_test, gold_labels_test = process_data('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete') \n",
    "notes = notes_train + notes_test\n",
    "labels = labels_train + labels_test\n",
    "gold_labels = gold_labels_train + gold_labels_test\n",
    "notes_train = np.array(notes_train)\n",
    "notes_test = np.array(notes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:14:57.924380Z",
     "start_time": "2019-04-09T20:14:57.918942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 521 521 269 269 269 790 790 790 514 514 514 1304 1304 1304\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_train_1), \n",
    "      len(gold_labels_train_1), \n",
    "      len(notes_train_1),\n",
    "      \n",
    "      len(labels_train_2),\n",
    "      len(gold_labels_train_2), \n",
    "      len(notes_train_2),\n",
    "      \n",
    "      len(labels_train), \n",
    "      len(gold_labels_train),\n",
    "      len(notes_train),\n",
    "      \n",
    "      len(labels_test), \n",
    "      len(gold_labels_test), \n",
    "      len(notes_test),\n",
    "      \n",
    "      len(labels),\n",
    "      len(gold_labels),\n",
    "      len(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:14:59.613639Z",
     "start_time": "2019-04-09T20:14:57.926499Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(i) for i in notes])\n",
    "\n",
    "X_txt = [' '.join(i) for i in notes]\n",
    "X_train_txt = [' '.join(i) for i in notes_train]\n",
    "X_test_txt = [' '.join(i) for i in notes_test]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "tokenizer.fit_on_texts(X_txt)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X_txt) \n",
    "X_seq = pad_sequences(X_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_txt) \n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_txt) \n",
    "X_test_seq = pad_sequences(X_test_seq, maxlen=maxlen, padding='post')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:03.223990Z",
     "start_time": "2019-04-09T20:14:59.616154Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_embedding_matrix(embedding_index, word_index, max_features, embed_size):\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: \n",
    "            continue\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i-1] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# prepare embedding matrix\n",
    "w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, word_index=word_index, max_features=max_features, embed_size=embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:09.225833Z",
     "start_time": "2019-04-09T20:15:03.226291Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels = [label for notes_label in labels for label in notes_label]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(all_labels)\n",
    "l_train = []\n",
    "l_test = []\n",
    "for i in labels_train:\n",
    "    l = mlb.transform(i)\n",
    "    l_train.append(l)\n",
    "for i in labels_test:\n",
    "    l = mlb.transform(i)\n",
    "    l_test.append(l)\n",
    "    \n",
    "Y_train = []\n",
    "Y_test = []\n",
    "num_labels = len(mlb.classes_)\n",
    "for i in l_train:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_labels)), i))\n",
    "    Y_train.append(pad_i)\n",
    "for i in l_test:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_labels)), i))\n",
    "    Y_test.append(pad_i)    \n",
    "    \n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "all_gold_labels = [label for notes_label in gold_labels for label in notes_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:09.231952Z",
     "start_time": "2019-04-09T20:15:09.228090Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_labels(label):\n",
    "    c = '.'\n",
    "    positions = [pos for pos, char in enumerate(label) if char == c]\n",
    "    if label != 'O':\n",
    "        sl = slice(positions[0]+1,positions[1])\n",
    "        cat_label = label[sl]\n",
    "    else:\n",
    "        cat_label = label\n",
    "    return cat_label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:18.218340Z",
     "start_time": "2019-04-09T20:15:09.233727Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_labels = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels]\n",
    "cat_labels_train = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_train]\n",
    "cat_labels_test = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_test]\n",
    "\n",
    "all_cat_labels = [label for notes_label in cat_labels for label in notes_label]\n",
    "\n",
    "cat_mlb = MultiLabelBinarizer()\n",
    "cat_mlb.fit(all_cat_labels)\n",
    "l_cat_train = []\n",
    "l_cat_test = []\n",
    "for i in cat_labels_train:\n",
    "    l = cat_mlb.transform(i)\n",
    "    l_cat_train.append(l)\n",
    "for i in cat_labels_test:\n",
    "    l = cat_mlb.transform(i)\n",
    "    l_cat_test.append(l)\n",
    "    \n",
    "Y_cat_train = []\n",
    "Y_cat_test = []\n",
    "num_cat_labels = len(cat_mlb.classes_)\n",
    "for i in l_cat_train:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_cat_labels)), i))\n",
    "    Y_cat_train.append(pad_i)\n",
    "for i in l_cat_test:\n",
    "    pad_i = np.concatenate((np.zeros((maxlen-i.shape[0],num_cat_labels)), i))\n",
    "    Y_cat_test.append(pad_i)    \n",
    "    \n",
    "Y_cat_train = np.array(Y_cat_train)\n",
    "Y_cat_test = np.array(Y_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:18.236493Z",
     "start_time": "2019-04-09T20:15:18.221860Z"
    }
   },
   "outputs": [],
   "source": [
    "gmlb = MultiLabelBinarizer()\n",
    "gmlb.fit(gold_labels)\n",
    "num_gold_labels = len(gmlb.classes_)\n",
    "Y_gold_train = gmlb.transform(gold_labels_train)\n",
    "Y_gold_test = gmlb.transform(gold_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:18.242618Z",
     "start_time": "2019-04-09T20:15:18.238150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1304, 5590) (790, 5590) (514, 5590) (790, 5590, 97) (514, 5590, 97) 97 (790, 5590, 9) (514, 5590, 9) 9 (790, 96) (514, 96) 96\n"
     ]
    }
   ],
   "source": [
    "print(X_seq.shape, X_train_seq.shape, X_test_seq.shape, Y_train.shape, Y_test.shape, num_labels, Y_cat_train.shape, Y_cat_test.shape, num_cat_labels, Y_gold_train.shape, Y_gold_test.shape, num_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:18.250389Z",
     "start_time": "2019-04-09T20:15:18.243843Z"
    }
   },
   "outputs": [],
   "source": [
    "# model function with pretrained embedding matrix and Timedistributed\n",
    "def get_model_2(nb_words, num_labels, model_type='CuDNNLSTM'):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.5)(x)\n",
    "    if model_type=='CuDNNGRU':\n",
    "        x = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "    elif model_type=='GRU':\n",
    "        x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
    "    elif model_type=='CuDNNLSTM':\n",
    "        x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    elif model_type=='LSTM':\n",
    "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    else:\n",
    "        raise ValueError('Please specify model_type as one of the following:n\\CuDNNGRU, CuDNNLSTM, GRU, LSTM')\n",
    "    outp = TimeDistributed(Dense((num_labels), activation=\"sigmoid\"))(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:18.257714Z",
     "start_time": "2019-04-09T20:15:18.251822Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model metrics\n",
    "class CustomEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            y_pred_roc = y_pred.flatten()\n",
    "            y_pred_ham = (y_pred > 0.5).reshape((-1, y_pred.shape[2]))\n",
    "            y_val_roc = self.y_val.flatten()\n",
    "            y_val_ham = self.y_val.reshape((-1, self.y_val.shape[2]))\n",
    "            #print(y_val.sum(), y_pred.sum())\n",
    "            roc = roc_auc_score(y_val_roc, y_pred_roc)\n",
    "            ham = hamming_loss(y_val_ham, y_pred_ham)\n",
    "            sub = accuracy_score(y_val_ham, y_pred_ham)\n",
    "            print(\"Adiitional val metrics: - ROC-AUC: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f\" % (roc, ham, sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:15:20.784445Z",
     "start_time": "2019-04-09T20:15:18.259081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5590)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 5590, 10)          449840    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 5590, 10)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 5590, 256)         143360    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5590, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 618,129\n",
      "Trainable params: 618,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "# train the model\n",
    "model = get_model_2(nb_words=nb_words,num_labels=num_labels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:37:33.723506Z",
     "start_time": "2019-04-09T20:15:20.786591Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 790 samples, validate on 514 samples\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 47s 59ms/step - loss: 0.0821 - acc: 0.9746 - val_loss: 0.0053 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.963937 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0050 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.972643 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0053 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974703 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0047 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.977654 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.0052 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.978812 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0046 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.978533 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 45s 57ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0048 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.979469 - Hamming-Loss: 0.001178 - Subset-Accuracy: 0.890217\n"
     ]
    }
   ],
   "source": [
    "custevl = CustomEvaluation(validation_data=(X_test_seq, Y_test), interval=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=3e-4, patience=3, verbose=0, mode='auto')\n",
    "hist = model.fit(X_train_seq,Y_train, \n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(X_test_seq, Y_test),\n",
    "                 callbacks=[custevl, earlystop],\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:37:54.524312Z",
     "start_time": "2019-04-09T20:37:33.725932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2873256,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[2872733,       0],\n",
       "        [    527,       0]],\n",
       "\n",
       "       [[2873255,       0],\n",
       "        [      5,       0]],\n",
       "\n",
       "       [[2871992,       0],\n",
       "        [   1268,       0]],\n",
       "\n",
       "       [[2872728,       0],\n",
       "        [    532,       0]],\n",
       "\n",
       "       [[2873043,       0],\n",
       "        [    217,       0]],\n",
       "\n",
       "       [[2871592,       0],\n",
       "        [   1668,       0]],\n",
       "\n",
       "       [[2873186,       0],\n",
       "        [     74,       0]],\n",
       "\n",
       "       [[2872700,       0],\n",
       "        [    560,       0]],\n",
       "\n",
       "       [[2873120,       0],\n",
       "        [    140,       0]],\n",
       "\n",
       "       [[2873078,       0],\n",
       "        [    182,       0]],\n",
       "\n",
       "       [[2872112,       0],\n",
       "        [   1148,       0]],\n",
       "\n",
       "       [[2872864,       0],\n",
       "        [    396,       0]],\n",
       "\n",
       "       [[2873095,       0],\n",
       "        [    165,       0]],\n",
       "\n",
       "       [[2872112,       0],\n",
       "        [   1148,       0]],\n",
       "\n",
       "       [[2873220,       0],\n",
       "        [     40,       0]],\n",
       "\n",
       "       [[2873196,       0],\n",
       "        [     64,       0]],\n",
       "\n",
       "       [[2872105,       0],\n",
       "        [   1155,       0]],\n",
       "\n",
       "       [[2873046,       0],\n",
       "        [    214,       0]],\n",
       "\n",
       "       [[2872894,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[2873174,       0],\n",
       "        [     86,       0]],\n",
       "\n",
       "       [[2873210,       0],\n",
       "        [     50,       0]],\n",
       "\n",
       "       [[2872894,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[2873254,       0],\n",
       "        [      6,       0]],\n",
       "\n",
       "       [[2873249,       0],\n",
       "        [     11,       0]],\n",
       "\n",
       "       [[2872894,       0],\n",
       "        [    366,       0]],\n",
       "\n",
       "       [[2872606,       0],\n",
       "        [    654,       0]],\n",
       "\n",
       "       [[2873147,       0],\n",
       "        [    113,       0]],\n",
       "\n",
       "       [[2872600,       0],\n",
       "        [    660,       0]],\n",
       "\n",
       "       [[2872614,       0],\n",
       "        [    646,       0]],\n",
       "\n",
       "       [[2872595,       0],\n",
       "        [    665,       0]],\n",
       "\n",
       "       [[2872861,       0],\n",
       "        [    399,       0]],\n",
       "\n",
       "       [[2873151,       0],\n",
       "        [    109,       0]],\n",
       "\n",
       "       [[2873256,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[2873260,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[2872805,       0],\n",
       "        [    455,       0]],\n",
       "\n",
       "       [[2872659,       0],\n",
       "        [    601,       0]],\n",
       "\n",
       "       [[2873042,       0],\n",
       "        [    218,       0]],\n",
       "\n",
       "       [[2873127,       0],\n",
       "        [    133,       0]],\n",
       "\n",
       "       [[2873239,       0],\n",
       "        [     21,       0]],\n",
       "\n",
       "       [[2873200,       0],\n",
       "        [     60,       0]],\n",
       "\n",
       "       [[2872772,       0],\n",
       "        [    488,       0]],\n",
       "\n",
       "       [[2872984,       0],\n",
       "        [    276,       0]],\n",
       "\n",
       "       [[2873248,       0],\n",
       "        [     12,       0]],\n",
       "\n",
       "       [[2873076,       0],\n",
       "        [    184,       0]],\n",
       "\n",
       "       [[2872748,       0],\n",
       "        [    512,       0]],\n",
       "\n",
       "       [[2873055,       0],\n",
       "        [    205,       0]],\n",
       "\n",
       "       [[2873214,       0],\n",
       "        [     46,       0]],\n",
       "\n",
       "       [[2873105,       0],\n",
       "        [    155,       0]],\n",
       "\n",
       "       [[2872890,       0],\n",
       "        [    370,       0]],\n",
       "\n",
       "       [[2873129,       0],\n",
       "        [    131,       0]],\n",
       "\n",
       "       [[2873256,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[2873260,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[2872807,       0],\n",
       "        [    453,       0]],\n",
       "\n",
       "       [[2872640,       0],\n",
       "        [    620,       0]],\n",
       "\n",
       "       [[2873040,       0],\n",
       "        [    220,       0]],\n",
       "\n",
       "       [[2873097,       0],\n",
       "        [    163,       0]],\n",
       "\n",
       "       [[2873246,       0],\n",
       "        [     14,       0]],\n",
       "\n",
       "       [[2873204,       0],\n",
       "        [     56,       0]],\n",
       "\n",
       "       [[2872793,       0],\n",
       "        [    467,       0]],\n",
       "\n",
       "       [[2872969,       0],\n",
       "        [    291,       0]],\n",
       "\n",
       "       [[2873249,       0],\n",
       "        [     11,       0]],\n",
       "\n",
       "       [[2873054,       0],\n",
       "        [    206,       0]],\n",
       "\n",
       "       [[2872744,       0],\n",
       "        [    516,       0]],\n",
       "\n",
       "       [[2873045,       0],\n",
       "        [    215,       0]],\n",
       "\n",
       "       [[2873201,       0],\n",
       "        [     59,       0]],\n",
       "\n",
       "       [[2873077,       0],\n",
       "        [    183,       0]],\n",
       "\n",
       "       [[2872910,       0],\n",
       "        [    350,       0]],\n",
       "\n",
       "       [[2873145,       0],\n",
       "        [    115,       0]],\n",
       "\n",
       "       [[2873256,       0],\n",
       "        [      4,       0]],\n",
       "\n",
       "       [[2873260,       0],\n",
       "        [      0,       0]],\n",
       "\n",
       "       [[2872791,       0],\n",
       "        [    469,       0]],\n",
       "\n",
       "       [[2872657,       0],\n",
       "        [    603,       0]],\n",
       "\n",
       "       [[2873050,       0],\n",
       "        [    210,       0]],\n",
       "\n",
       "       [[2873133,       0],\n",
       "        [    127,       0]],\n",
       "\n",
       "       [[2873246,       0],\n",
       "        [     14,       0]],\n",
       "\n",
       "       [[2873209,       0],\n",
       "        [     51,       0]],\n",
       "\n",
       "       [[2872791,       0],\n",
       "        [    469,       0]],\n",
       "\n",
       "       [[2873025,       0],\n",
       "        [    235,       0]],\n",
       "\n",
       "       [[2873253,       0],\n",
       "        [      7,       0]],\n",
       "\n",
       "       [[2873056,       0],\n",
       "        [    204,       0]],\n",
       "\n",
       "       [[2872776,       0],\n",
       "        [    484,       0]],\n",
       "\n",
       "       [[2873055,       0],\n",
       "        [    205,       0]],\n",
       "\n",
       "       [[2873215,       0],\n",
       "        [     45,       0]],\n",
       "\n",
       "       [[2873097,       0],\n",
       "        [    163,       0]],\n",
       "\n",
       "       [[2873257,       0],\n",
       "        [      3,       0]],\n",
       "\n",
       "       [[2873136,       0],\n",
       "        [    124,       0]],\n",
       "\n",
       "       [[2873257,       0],\n",
       "        [      3,       0]],\n",
       "\n",
       "       [[2873136,       0],\n",
       "        [    124,       0]],\n",
       "\n",
       "       [[2873224,       0],\n",
       "        [     36,       0]],\n",
       "\n",
       "       [[2873120,       0],\n",
       "        [    140,       0]],\n",
       "\n",
       "       [[2873049,       0],\n",
       "        [    211,       0]],\n",
       "\n",
       "       [[2873244,       0],\n",
       "        [     16,       0]],\n",
       "\n",
       "       [[2872927,       0],\n",
       "        [    333,       0]],\n",
       "\n",
       "       [[2872398,       0],\n",
       "        [    862,       0]],\n",
       "\n",
       "       [[2873050,       0],\n",
       "        [    210,       0]],\n",
       "\n",
       "       [[2572039,       0],\n",
       "        [ 301221,       0]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test_seq)\n",
    "\n",
    "multilabel_confusion_matrix(Y_test.reshape((Y_test.shape[0]*Y_test.shape[1],-1)), np.where(Y_pred.reshape((Y_pred.shape[0]*Y_pred.shape[1],-1)) > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:37:55.037478Z",
     "start_time": "2019-04-09T20:37:54.527598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 5590)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 5590, 10)          449840    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 5590, 10)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 5590, 256)         143360    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5590, 9)           2313      \n",
      "=================================================================\n",
      "Total params: 595,513\n",
      "Trainable params: 595,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "# train the model\n",
    "cat_model = get_model_2(nb_words=nb_words,num_labels=num_cat_labels)\n",
    "cat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:41:31.885372Z",
     "start_time": "2019-04-09T20:37:55.039589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 790 samples, validate on 514 samples\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 42s 53ms/step - loss: 0.1101 - acc: 0.9656 - val_loss: 0.0427 - val_acc: 0.9878\n",
      "Adiitional val metrics: - ROC-AUC: 0.924898 - Hamming-Loss: 0.012199 - Subset-Accuracy: 0.890217\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 42s 53ms/step - loss: 0.0658 - acc: 0.9776 - val_loss: 0.0474 - val_acc: 0.9878\n",
      "Adiitional val metrics: - ROC-AUC: 0.953333 - Hamming-Loss: 0.012199 - Subset-Accuracy: 0.890217\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 42s 53ms/step - loss: 0.0660 - acc: 0.9776 - val_loss: 0.0459 - val_acc: 0.9878\n",
      "Adiitional val metrics: - ROC-AUC: 0.941866 - Hamming-Loss: 0.012199 - Subset-Accuracy: 0.890217\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 42s 53ms/step - loss: 0.0652 - acc: 0.9776 - val_loss: 0.0425 - val_acc: 0.9878\n",
      "Adiitional val metrics: - ROC-AUC: 0.915749 - Hamming-Loss: 0.012199 - Subset-Accuracy: 0.890217\n"
     ]
    }
   ],
   "source": [
    "custevl = CustomEvaluation(validation_data=(X_test_seq, Y_cat_test), interval=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=3e-4, patience=3, verbose=0, mode='auto')\n",
    "hist = cat_model.fit(X_train_seq,Y_cat_train, \n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 validation_data=(X_test_seq, Y_cat_test),\n",
    "                 callbacks=[custevl, earlystop],\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T20:41:36.001791Z",
     "start_time": "2019-04-09T20:41:31.887954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2869222,       0],\n",
       "        [   4038,       0]],\n",
       "\n",
       "       [[2871453,       0],\n",
       "        [   1807,       0]],\n",
       "\n",
       "       [[2873046,       0],\n",
       "        [    214,       0]],\n",
       "\n",
       "       [[2872743,       0],\n",
       "        [    517,       0]],\n",
       "\n",
       "       [[2871844,       0],\n",
       "        [   1416,       0]],\n",
       "\n",
       "       [[2868814,       0],\n",
       "        [   4446,       0]],\n",
       "\n",
       "       [[2572039,       0],\n",
       "        [ 301221,       0]],\n",
       "\n",
       "       [[2873085,       0],\n",
       "        [    175,       0]],\n",
       "\n",
       "       [[2871628,       0],\n",
       "        [   1632,       0]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat_pred = cat_model.predict(X_test_seq)\n",
    "\n",
    "multilabel_confusion_matrix(Y_cat_test.reshape((Y_cat_test.shape[0]*Y_cat_test.shape[1],-1)), np.where(Y_cat_pred.reshape((Y_cat_pred.shape[0]*Y_cat_pred.shape[1],-1)) > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
