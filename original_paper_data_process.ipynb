{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T14:26:12.462215Z",
     "start_time": "2019-07-05T14:26:12.428387Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-caffce18eadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnowball\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagName\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SMOKER'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagName\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FAMILY_HIST'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from xml.dom import minidom\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "\n",
    "def get_annotation(element, indicator):\n",
    "    if element.tagName == 'SMOKER' or element.tagName == 'FAMILY_HIST':\n",
    "        return (element.getAttribute('text').strip().lower(), element.tagName.lower() + '.' + \n",
    "                element.getAttribute(indicator).lower().strip().replace(' ', '_'))\n",
    "    else:\n",
    "        return (element.getAttribute('text').strip().lower(), element.tagName.lower() + '.' + \n",
    "                element.getAttribute(indicator).lower().strip().replace(' ', '_'), \n",
    "                element.getAttribute('time').lower().strip().replace(' ', '_'))\n",
    "    \n",
    "def tokenise_annotation(annotation):\n",
    "    return (word_tokenize(annotation[0]), annotation[1])\n",
    "\n",
    "def combine_annotations(annotations):\n",
    "    types = list()\n",
    "    results = list()\n",
    "    n = 0\n",
    "    for annotation in annotations:\n",
    "        if len(annotation) == 3:\n",
    "            types.append((annotation[1], annotation[2]))\n",
    "    for annotation in annotations:\n",
    "        if len(annotation) == 3:\n",
    "            if ((annotation[1], 'before_dct') in types and \n",
    "                (annotation[1], 'during_dct') in types and \n",
    "                (annotation[1], 'after_dct') in types):\n",
    "                 results.append((annotation[0], annotation[1] + '.continuing'))\n",
    "            else:\n",
    "                results.append((annotation[0], annotation[1] + '.' + annotation[2]))\n",
    "        else:\n",
    "            results.append(annotation)\n",
    "    return list(set(results))\n",
    "\n",
    "def find_sublist(sublist, alist):\n",
    "    indices = list()\n",
    "    for index in (i for i, e in enumerate(alist) if e == sublist[0]):\n",
    "        if alist[index:index + len(sublist)] == sublist:\n",
    "            indices.append((index, index + len(sublist) - 1))\n",
    "    return indices\n",
    "\n",
    "def annotate(tags, annotations, indices):\n",
    "    for i in range(len(indices)):\n",
    "        for j in range(len(indices[i])):\n",
    "            for k in range(indices[i][j][0], indices[i][j][1] + 1):\n",
    "                tags[k] = 'I-' + annotations[i][1]\n",
    "\n",
    "def isplit(iterable, splitters):\n",
    "    return [list(g) for k, g in itertools.groupby(iterable, lambda x: x in splitters) if not k]\n",
    "\n",
    "def replace_elements(alist, indices):\n",
    "    for i in range(len(indices)):\n",
    "        for j in range(len(indices[i])):\n",
    "            alist[i][indices[i][j]] = -1\n",
    "            \n",
    "def write_to_file(filename, data, index):\n",
    "    file = open(filename, 'w')\n",
    "    for i in range(len(data)):\n",
    "        file.write(\"%d %s\\n\" % (i + index, data[i][0]))\n",
    "    file.close()\n",
    "\n",
    "def generate_files(data, labels, files):\n",
    "    paths = ['../models/cnn/data/training/', '../models/rnn/data/training/', '../models/lstm/data/training/']\n",
    "    for i in range(0, len(data)):\n",
    "        for path in paths:\n",
    "            file = open(path + files[i][17:-4] + '.txt', 'w')\n",
    "            for j in range(0, len(data[i])):\n",
    "                file.write(','.join(str(x) for x in data[i][j]) + ' ' + (','.join(str(x) for x in labels[i][j])) + '\\n')\n",
    "            file.close()\n",
    "    \n",
    "def print_data(encoded_data, encoded_labels, data_indices, label_indices):\n",
    "    for i in range(len(encoded_data)):\n",
    "        for j in range(len(encoded_data[i])):\n",
    "            for k in range(len(encoded_data[i][j])):\n",
    "                print(data_indices[encoded_data[i][j][k] - 2][0] + \" \" + \n",
    "                    label_indices[encoded_labels[i][j][k] - 1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T14:25:51.881880Z",
     "start_time": "2019-07-05T14:25:51.869496Z"
    }
   },
   "outputs": [],
   "source": [
    "tagnames = ['CAD', 'DIABETES', 'FAMILY_HIST', 'HYPERLIPIDEMIA', 'HYPERTENSION', 'MEDICATION', 'OBESE', 'SMOKER']\n",
    "folder1 = '/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1'\n",
    "folder2 = '/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2'\n",
    "files1 = glob.glob(folder1+'/*.xml')\n",
    "files2 = glob.glob(folder2+'/*.xml')\n",
    "files = files1 + files2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T14:27:09.003317Z",
     "start_time": "2019-07-05T14:26:53.458579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, data_list, labels, label_list = list(), list(), list(), list()\n",
    "\n",
    "for file in files:\n",
    "    root = minidom.parse(file)\n",
    "    annotation_objects = [root.getElementsByTagName(x) for x in tagnames]\n",
    "    annotations = [[[get_annotation(z, 'type1')\n",
    "                if z.tagName == 'MEDICATION' else get_annotation(z, 'status')\n",
    "                if z.tagName == 'SMOKER' else get_annotation(z, 'indicator')\n",
    "                for z in y.getElementsByTagName(y.tagName)] \n",
    "                for y in x] for x in annotation_objects]\n",
    "    annotations = [[y for y in x if len(y) > 0] for x in annotations if len(x) > 0]\n",
    "    annotations = list(set([y for x in [y for x in annotations for y in x] for y in x]))\n",
    "    annotations = [x for x in annotations if x[1] != 'family_hist.not_present' and x[1] != 'smoker.unknown']\n",
    "    annotations = [x for x in annotations if x[0] != '']\n",
    "    \n",
    "    annotations = combine_annotations(annotations)\n",
    "    annotations = [tokenise_annotation(x) for x in annotations]\n",
    "    annotations.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    text = root.getElementsByTagName(\"TEXT\")[0].firstChild.data\n",
    "    text = word_tokenize(text.lower())\n",
    "    \n",
    "    indices = [find_sublist(x[0], text) for x in annotations]\n",
    "    tags = ['O' for x in text]\n",
    "    annotate(tags, annotations, indices)\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    text = [stemmer.stem(x) for x in text]\n",
    "    data.extend(text)\n",
    "    labels.extend(tags)\n",
    "    data_list.append(text)\n",
    "    label_list.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T19:06:28.075324Z",
     "start_time": "2019-06-19T19:03:42.166733Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9c3cc22548a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9c3cc22548a1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9c3cc22548a1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_indices = Counter(data).most_common()\n",
    "label_indices = Counter(labels).most_common()\n",
    "\n",
    "encoded_data = [[(i + 2) for y in x for i, a in enumerate(data_indices) if y == a[0]] for x in data_list]\n",
    "encoded_labels = [[(i + 1) for y in x for i, a in enumerate(label_indices) if y == a[0]] for x in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T14:36:18.942966Z",
     "start_time": "2019-06-19T14:36:18.830666Z"
    }
   },
   "outputs": [],
   "source": [
    "period_index = [i + 2 for i, x in enumerate(data_indices) if x[0] == \".\"][0]\n",
    "period_indices = [[i for i, y in enumerate(x) if y == period_index] for x in encoded_data]\n",
    "\n",
    "encoded_data = [isplit(x, (period_index,)) for x in encoded_data]\n",
    "replace_elements(encoded_labels, period_indices)\n",
    "encoded_labels = [isplit(x, (-1,)) for x in encoded_labels]\n",
    "\n",
    "print_data(encoded_data, encoded_labels, data_indices, label_indices)\n",
    "\n",
    "write_to_file('../data/dictionary.txt', data_indices, 2)\n",
    "write_to_file('../data/classes.txt', label_indices, 1)\n",
    "generate_files(encoded_data, encoded_labels, files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
