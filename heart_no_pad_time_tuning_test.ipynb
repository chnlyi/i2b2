{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:53:24.192873Z",
     "start_time": "2019-05-03T19:53:22.442096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, CuDNNGRU, CuDNNLSTM, GRU, LSTM, Reshape, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from utils import process_data, multilabel_confusion_matrix, get_embedding_matrix, get_cat_labels, data_generator, get_all\n",
    "\n",
    "# Customized Evaluation\n",
    "class CustomEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = list(validation_data)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = []\n",
    "            for x in self.X_val:\n",
    "                y = np.squeeze(self.model.predict_on_batch(x))\n",
    "                y_pred.append(y)\n",
    "            y_pred = np.concatenate(y_pred)\n",
    "            y_pred_ham = y_pred > 0.5\n",
    "            y_val = np.concatenate(self.y_val)\n",
    "            roc = roc_auc_score(y_val, y_pred, average='micro')\n",
    "            loss = log_loss(y_val, y_pred)\n",
    "            ham = hamming_loss(y_val, y_pred_ham)\n",
    "            sub = accuracy_score(y_val, y_pred_ham)\n",
    "            f1 = f1_score(y_val, y_pred_ham, average='micro')\n",
    "            print(\"Adiitional val metrics: - ROC-AUC: %.6f - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1-Score: %.6f\" % (roc, loss, ham, sub, f1))\n",
    "\n",
    "def no_pad_time_tuning(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test, verbose=1):\n",
    "    \n",
    "    up = param['up']\n",
    "    window_size = param['window_size']\n",
    "    embed_size = param['embed_size'] * 10\n",
    "    latent_dim = param['latent_dim'] * 64\n",
    "    dropout_rate = param['dropout_rate']\n",
    "    epochs = 30 #param['epochs']\n",
    "    max_features = 60000 #param['max_features']\n",
    "    category = False #param['category']\n",
    "    embedding = True #param['embedding']\n",
    "    model_type = 'CuDNNLSTM' #param['model_type']\n",
    "    \n",
    "    # upsampling\n",
    "    if up > 0:\n",
    "        if verbose != 0: print('upsampling for %d times...' % (up))\n",
    "        notes_train = [note + up * up_note for note, up_note in zip(notes_train, up_notes_train)]\n",
    "        labels_train = [label + up * up_label for label, up_label in zip(labels_train, up_labels_train)]\n",
    "        if verbose != 0: print('upsampling done\\n')\n",
    "    notes = notes_train + notes_test\n",
    "    labels = labels_train + labels_test\n",
    "    gold_labels = gold_labels_train + gold_labels_test\n",
    "    \n",
    "    # prepare features\n",
    "    if verbose != 0: print('preparing features ...')\n",
    "    X_txt = [' '.join(i) for i in notes]\n",
    "    X_train_txt = [' '.join(i) for i in notes_train]\n",
    "    X_test_txt = [' '.join(i) for i in notes_test]\n",
    "    tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "    tokenizer.fit_on_texts(X_txt)\n",
    "    X_seq = tokenizer.texts_to_sequences(X_txt) \n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train_txt) \n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test_txt) \n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    if verbose != 0: print('preparing features done\\n')\n",
    "\n",
    "    # prepare embedding matrix\n",
    "    if embedding:\n",
    "        if verbose != 0: print('preparing embedding matrix ...')\n",
    "        w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "        embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "        embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, word_index=word_index, max_features=max_features, embed_size=embed_size)\n",
    "        if verbose != 0: print('preparing embedding matrix done\\n')\n",
    "        \n",
    "    # prepare targets\n",
    "    if verbose != 0: print('preparing targets ...')\n",
    "    if category:\n",
    "        # prepare cagtegory label targets\n",
    "        labels = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels]\n",
    "        labels_train = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_train]\n",
    "        labels_test = [[set([get_cat_labels(i) for i in list(j)]) for j in k] for k in labels_test]\n",
    "    all_labels = [label for notes_label in labels for label in notes_label]\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(all_labels)\n",
    "    num_labels = len(mlb.classes_)\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "    for i in labels_train:\n",
    "        l = mlb.transform(i)\n",
    "        Y_train.append(l)\n",
    "    for i in labels_test:\n",
    "        l = mlb.transform(i)\n",
    "        Y_test.append(l)\n",
    "    if verbose != 0: print('preparing targets done\\n')\n",
    "\n",
    "    # model function with pretrained embedding matrix and Timedistributed\n",
    "    def get_model(nb_words, num_labels, model_type, embedding):\n",
    "        inp = Input(shape=(None, ))\n",
    "        if embedding:\n",
    "            x = Embedding(nb_words, embed_size, weights=[embedding_matrix])(inp)\n",
    "        else:    \n",
    "            x = Embedding(nb_words, embed_size)(inp)\n",
    "        x = SpatialDropout1D(dropout_rate)(x)\n",
    "        if model_type=='CuDNNGRU':\n",
    "            x = Bidirectional(CuDNNGRU(latent_dim, return_sequences=True))(x)\n",
    "        elif model_type=='GRU':\n",
    "            x = Bidirectional(GRU(latent_dim, return_sequences=True))(x)\n",
    "        elif model_type=='CuDNNLSTM':\n",
    "            x = Bidirectional(CuDNNLSTM(latent_dim, return_sequences=True))(x)\n",
    "        elif model_type=='LSTM':\n",
    "            x = Bidirectional(LSTM(latent_dim, return_sequences=True))(x)\n",
    "        else:\n",
    "            raise ValueError('Please specify model_type as one of the following:n\\CuDNNGRU, CuDNNLSTM, GRU, LSTM')\n",
    "        #x = SeqSelfAttention(attention_width=15, attention_activation='sigmoid')(x)\n",
    "        #outp = TimeDistributed(Dense((num_labels), activation=\"sigmoid\"))(x)\n",
    "        outp = Dense((num_labels), activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=outp)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # model summary\n",
    "    model = get_model(nb_words=nb_words, num_labels=num_labels, model_type=model_type, embedding=embedding)\n",
    "    if verbose != 0: print('\\nmodel summary:')\n",
    "    if verbose != 0: print(model.summary())\n",
    "\n",
    "    # model training\n",
    "    if verbose != 0: print('\\ntraining model ...')\n",
    "    custevl = CustomEvaluation(validation_data=(X_test_seq, Y_test), interval=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=3e-4, patience=3, verbose=0, mode='auto')\n",
    "    train_gen = data_generator(X_train_seq, Y_train)\n",
    "    test_gen = data_generator(X_test_seq, Y_test)\n",
    "    v = 1 if verbose != 0 else 0  \n",
    "    hist = model.fit_generator(train_gen,\n",
    "                                steps_per_epoch=len(Y_train),\n",
    "                                epochs=epochs,\n",
    "                                validation_data=test_gen,\n",
    "                                validation_steps=len(Y_test),\n",
    "                                callbacks=[custevl, earlystop],\n",
    "                                verbose=v)\n",
    "    if verbose != 0: print('training model done')\n",
    "\n",
    "    # prediction of test data\n",
    "    if verbose != 0: print('predicting test data ...')\n",
    "    Y_pred = []\n",
    "    for x in X_test_seq:\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y_pred = np.squeeze(model.predict_on_batch(x))\n",
    "        Y_pred.append(y_pred)\n",
    "    Y_pred_concat = np.concatenate(Y_pred)\n",
    "    Y_val = np.concatenate(Y_test)\n",
    "    if verbose != 0: print('predicting test data done\\n')\n",
    "\n",
    "    # confusion matrix \n",
    "    if verbose == 2: \n",
    "        cm = multilabel_confusion_matrix(Y_val, np.where(Y_pred_concat > 0.5, 1, 0))\n",
    "        for i, j in zip(cm, mlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # prepare gold label targets\n",
    "    if verbose != 0: print('predicting gold label targets ...')\n",
    "    gold_labels_pred = [{i for s in mlb.inverse_transform(y_pred>0.5) for i in s if i != 'O'} for y_pred in Y_pred]\n",
    "    gmlb = MultiLabelBinarizer()\n",
    "    gmlb.fit(gold_labels)\n",
    "    num_gold_labels = len(gmlb.classes_)\n",
    "    Y_gold_test = gmlb.transform(gold_labels_test)\n",
    "    Y_gold_pred = gmlb.transform(gold_labels_pred)\n",
    "    if verbose != 0: print('predicting gold label targets done\\n')\n",
    "\n",
    "    # confusion matrix for gold label\n",
    "    if verbose == 2:\n",
    "        gcm = multilabel_confusion_matrix(np.concatenate(Y_gold_test), np.concatenate(Y_gold_pred))\n",
    "        for i, j in zip(gcm, gmlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # f1 scores for gold label\n",
    "    f1 = f1_score(Y_gold_test, Y_gold_pred, average='micro')\n",
    "    \n",
    "    print('Parameters: up - %d, window_size - %d, embed_size - %d, latent_dim - %d, dropout_rate - %.3f' % (up, window_size, embed_size, latent_dim, dropout_rate))\n",
    "    print('F1 Scores for global labels:\\nALL (average=\"micro\"):', f1)\n",
    "    \n",
    "    if verbose == 2:\n",
    "        f1_all = f1_score(Y_gold_test, Y_gold_pred, average=None)\n",
    "        for i, j in zip(f1_all, gmlb.classes_):\n",
    "            print(j+': '+str(i))\n",
    "    \n",
    "    print('\\n\\n')\n",
    "          \n",
    "    return f1\n",
    "\n",
    "def my_bayes_opt(space):\n",
    "    param = {\n",
    "        'up': space[0],               # Times of upsampling for training data\n",
    "        'window_size': space[1],                # Window size for word2vec\n",
    "        'embed_size': space[2],                # Length of the vector that we willl get from the embedding layer\n",
    "        'latent_dim': space[3],               # Hidden layers dimension \n",
    "        'dropout_rate': space[4]}#,             # Rate of the dropout layers\n",
    "        #'epochs': space[0],                    # Number of epochs\n",
    "        #'max_features': space[0],           # Max num of vocabulary\n",
    "        #'category': space[0],               # Is categoty labels\n",
    "        #'embedding': space[0],               # Using pre-made embedidng matrix as weight\n",
    "        #'model_type': space[0]\n",
    "        #}\n",
    "    f1 = no_pad_time_tuning(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test)\n",
    "    return (-f1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:54:29.759529Z",
     "start_time": "2019-05-03T19:53:25.709869Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d785e183880441f80a03d3ba6498fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=521), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c7f97921eb416b8c6904fbeb6b6c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=269), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5b64b5a7fc4597a359a1b726f58b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=514), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loading data \n",
    "notes_train_1, labels_train_1, up_notes_train_1, up_labels_train_1, gold_labels_train_1 = get_all('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1') \n",
    "notes_train_2, labels_train_2, up_notes_train_2, up_labels_train_2, gold_labels_train_2 = get_all('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2') \n",
    "\n",
    "notes_train = notes_train_1 + notes_train_2\n",
    "labels_train = labels_train_1 + labels_train_2\n",
    "up_notes_train = up_notes_train_1 + up_notes_train_2\n",
    "up_labels_train = up_labels_train_1 + up_labels_train_2\n",
    "gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "\n",
    "notes_test, labels_test, _1, _2, gold_labels_test = get_all('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T22:57:15.689766Z",
     "start_time": "2019-05-03T19:54:29.762050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampling for 8 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 40)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         174080    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,998,369\n",
      "Trainable params: 1,998,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 96s 121ms/step - loss: 0.0265 - acc: 0.9941 - val_loss: 0.0077 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.955823 - Log-Loss: 3.984269 - Hamming-Loss: 0.027579 - Subset-Accuracy: 0.761929 - F1-Score: 0.397254\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 93s 118ms/step - loss: 0.0134 - acc: 0.9969 - val_loss: 0.0057 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.970024 - Log-Loss: 3.639516 - Hamming-Loss: 0.024766 - Subset-Accuracy: 0.806702 - F1-Score: 0.435268\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 96s 121ms/step - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.974932 - Log-Loss: 3.362042 - Hamming-Loss: 0.020889 - Subset-Accuracy: 0.798158 - F1-Score: 0.474616\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978042 - Log-Loss: 3.118441 - Hamming-Loss: 0.016424 - Subset-Accuracy: 0.811793 - F1-Score: 0.534619\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 91s 116ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.979741 - Log-Loss: 2.943506 - Hamming-Loss: 0.012216 - Subset-Accuracy: 0.823051 - F1-Score: 0.606683\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 91s 116ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981229 - Log-Loss: 2.791367 - Hamming-Loss: 0.009543 - Subset-Accuracy: 0.831864 - F1-Score: 0.663553\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 95s 120ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983620 - Log-Loss: 2.613614 - Hamming-Loss: 0.006725 - Subset-Accuracy: 0.859201 - F1-Score: 0.739901\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 96s 121ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984363 - Log-Loss: 2.480719 - Hamming-Loss: 0.005345 - Subset-Accuracy: 0.858155 - F1-Score: 0.780792\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 95s 120ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985320 - Log-Loss: 2.347331 - Hamming-Loss: 0.004532 - Subset-Accuracy: 0.840370 - F1-Score: 0.804405\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 8, window_size - 5, embed_size - 40, latent_dim - 128, dropout_rate - 0.105\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.863720073664825\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 6 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 20)          899680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 256)         153600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,078,209\n",
      "Trainable params: 1,078,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0262 - acc: 0.9940 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.960454 - Log-Loss: 4.091828 - Hamming-Loss: 0.020135 - Subset-Accuracy: 0.811064 - F1-Score: 0.479587\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 81s 103ms/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0067 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.968491 - Log-Loss: 3.812063 - Hamming-Loss: 0.019275 - Subset-Accuracy: 0.793530 - F1-Score: 0.491383\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 78s 98ms/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0056 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.974419 - Log-Loss: 3.561821 - Hamming-Loss: 0.016275 - Subset-Accuracy: 0.825432 - F1-Score: 0.538146\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978447 - Log-Loss: 3.324244 - Hamming-Loss: 0.012684 - Subset-Accuracy: 0.840186 - F1-Score: 0.601545\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 75s 95ms/step - loss: 0.0092 - acc: 0.9977 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980796 - Log-Loss: 3.118234 - Hamming-Loss: 0.009685 - Subset-Accuracy: 0.871305 - F1-Score: 0.666377\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 73s 93ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982846 - Log-Loss: 2.990022 - Hamming-Loss: 0.007641 - Subset-Accuracy: 0.871283 - F1-Score: 0.716500\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 76s 96ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984299 - Log-Loss: 2.798219 - Hamming-Loss: 0.005623 - Subset-Accuracy: 0.881208 - F1-Score: 0.774365\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 76s 96ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adiitional val metrics: - ROC-AUC: 0.985561 - Log-Loss: 2.675922 - Hamming-Loss: 0.003951 - Subset-Accuracy: 0.878935 - F1-Score: 0.829174\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 76s 96ms/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986647 - Log-Loss: 2.558476 - Hamming-Loss: 0.003239 - Subset-Accuracy: 0.883963 - F1-Score: 0.856027\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 78s 98ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987060 - Log-Loss: 2.467826 - Hamming-Loss: 0.002954 - Subset-Accuracy: 0.874786 - F1-Score: 0.865602\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 6, window_size - 5, embed_size - 20, latent_dim - 128, dropout_rate - 0.098\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8532042096941549\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 6 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, None, 40)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 256)         174080    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,998,369\n",
      "Trainable params: 1,998,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0260 - acc: 0.9941 - val_loss: 0.0086 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.967027 - Log-Loss: 3.909359 - Hamming-Loss: 0.007641 - Subset-Accuracy: 0.861414 - F1-Score: 0.708861\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 77s 98ms/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975152 - Log-Loss: 3.519229 - Hamming-Loss: 0.008492 - Subset-Accuracy: 0.854680 - F1-Score: 0.689873\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980600 - Log-Loss: 3.198354 - Hamming-Loss: 0.006499 - Subset-Accuracy: 0.879668 - F1-Score: 0.748152\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983695 - Log-Loss: 2.938664 - Hamming-Loss: 0.004716 - Subset-Accuracy: 0.899063 - F1-Score: 0.805269\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 79s 100ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984210 - Log-Loss: 2.757971 - Hamming-Loss: 0.003860 - Subset-Accuracy: 0.885957 - F1-Score: 0.832273\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 76s 96ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986362 - Log-Loss: 2.546328 - Hamming-Loss: 0.003103 - Subset-Accuracy: 0.898521 - F1-Score: 0.861900\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 76s 97ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987118 - Log-Loss: 2.378302 - Hamming-Loss: 0.002896 - Subset-Accuracy: 0.875198 - F1-Score: 0.867020\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 79s 99ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987560 - Log-Loss: 2.232354 - Hamming-Loss: 0.002650 - Subset-Accuracy: 0.873156 - F1-Score: 0.876350\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987896 - Log-Loss: 2.120397 - Hamming-Loss: 0.002556 - Subset-Accuracy: 0.868711 - F1-Score: 0.879487\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 6, window_size - 4, embed_size - 40, latent_dim - 128, dropout_rate - 0.076\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8624920565087746\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 8 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, None, 30)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 128)         49152     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 97)          12513     \n",
      "=================================================================\n",
      "Total params: 1,411,185\n",
      "Trainable params: 1,411,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0348 - acc: 0.9915 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.947270 - Log-Loss: 3.953917 - Hamming-Loss: 0.018030 - Subset-Accuracy: 0.755709 - F1-Score: 0.479684\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0066 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.966728 - Log-Loss: 3.706433 - Hamming-Loss: 0.016111 - Subset-Accuracy: 0.781128 - F1-Score: 0.530124\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 91s 115ms/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0055 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.974102 - Log-Loss: 3.447424 - Hamming-Loss: 0.012088 - Subset-Accuracy: 0.798539 - F1-Score: 0.606759\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 91s 115ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978209 - Log-Loss: 3.233455 - Hamming-Loss: 0.009228 - Subset-Accuracy: 0.804270 - F1-Score: 0.665261\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 93s 117ms/step - loss: 0.0088 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980689 - Log-Loss: 3.036237 - Hamming-Loss: 0.007153 - Subset-Accuracy: 0.817912 - F1-Score: 0.719228\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 93s 118ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983071 - Log-Loss: 2.865090 - Hamming-Loss: 0.005775 - Subset-Accuracy: 0.810880 - F1-Score: 0.757945\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 92s 116ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984291 - Log-Loss: 2.730427 - Hamming-Loss: 0.005117 - Subset-Accuracy: 0.804632 - F1-Score: 0.777388\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 93s 118ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985581 - Log-Loss: 2.579873 - Hamming-Loss: 0.004064 - Subset-Accuracy: 0.842370 - F1-Score: 0.820401\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 95s 121ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985919 - Log-Loss: 2.479957 - Hamming-Loss: 0.004000 - Subset-Accuracy: 0.821155 - F1-Score: 0.818718\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 93s 118ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986273 - Log-Loss: 2.422109 - Hamming-Loss: 0.003989 - Subset-Accuracy: 0.799303 - F1-Score: 0.814389\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 8, window_size - 5, embed_size - 30, latent_dim - 64, dropout_rate - 0.004\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8468304519259933\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 7 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, None, 40)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 256)         174080    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,998,369\n",
      "Trainable params: 1,998,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 81s 102ms/step - loss: 0.0276 - acc: 0.9935 - val_loss: 0.0084 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.960435 - Log-Loss: 3.948959 - Hamming-Loss: 0.012857 - Subset-Accuracy: 0.775123 - F1-Score: 0.580758\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.969754 - Log-Loss: 3.615409 - Hamming-Loss: 0.011736 - Subset-Accuracy: 0.793517 - F1-Score: 0.608654\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977266 - Log-Loss: 3.329897 - Hamming-Loss: 0.008724 - Subset-Accuracy: 0.860168 - F1-Score: 0.687234\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0094 - acc: 0.9977 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978747 - Log-Loss: 3.144163 - Hamming-Loss: 0.007663 - Subset-Accuracy: 0.822981 - F1-Score: 0.704840\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980579 - Log-Loss: 2.952861 - Hamming-Loss: 0.006120 - Subset-Accuracy: 0.853507 - F1-Score: 0.754287\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 84s 107ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981719 - Log-Loss: 2.744284 - Hamming-Loss: 0.005406 - Subset-Accuracy: 0.805484 - F1-Score: 0.766215\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 80s 102ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982809 - Log-Loss: 2.576295 - Hamming-Loss: 0.004543 - Subset-Accuracy: 0.809847 - F1-Score: 0.796085\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 77s 98ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981158 - Log-Loss: 2.496225 - Hamming-Loss: 0.004473 - Subset-Accuracy: 0.764411 - F1-Score: 0.789241\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 77s 97ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.982706 - Log-Loss: 2.363322 - Hamming-Loss: 0.004112 - Subset-Accuracy: 0.777694 - F1-Score: 0.807091\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 7, window_size - 5, embed_size - 40, latent_dim - 128, dropout_rate - 0.174\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8612234950036559\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 10 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, None, 20)          899680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, None, 384)         328704    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, None, 97)          37345     \n",
      "=================================================================\n",
      "Total params: 1,265,729\n",
      "Trainable params: 1,265,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 106s 134ms/step - loss: 0.0273 - acc: 0.9937 - val_loss: 0.0087 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.939509 - Log-Loss: 4.169083 - Hamming-Loss: 0.044783 - Subset-Accuracy: 0.621672 - F1-Score: 0.264779\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 105s 132ms/step - loss: 0.0167 - acc: 0.9963 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.931412 - Log-Loss: 3.982629 - Hamming-Loss: 0.042902 - Subset-Accuracy: 0.562880 - F1-Score: 0.249168\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0145 - acc: 0.9966 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.938949 - Log-Loss: 3.746338 - Hamming-Loss: 0.036567 - Subset-Accuracy: 0.598111 - F1-Score: 0.283051\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 111s 140ms/step - loss: 0.0130 - acc: 0.9969 - val_loss: 0.0054 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.948056 - Log-Loss: 3.531706 - Hamming-Loss: 0.030432 - Subset-Accuracy: 0.601962 - F1-Score: 0.314643\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 111s 141ms/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.962799 - Log-Loss: 3.308136 - Hamming-Loss: 0.023583 - Subset-Accuracy: 0.661379 - F1-Score: 0.391426\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 113s 142ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.970467 - Log-Loss: 3.144593 - Hamming-Loss: 0.018683 - Subset-Accuracy: 0.716531 - F1-Score: 0.469339\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 113s 143ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.975711 - Log-Loss: 2.936490 - Hamming-Loss: 0.013827 - Subset-Accuracy: 0.761013 - F1-Score: 0.556526\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 112s 142ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980917 - Log-Loss: 2.727107 - Hamming-Loss: 0.010395 - Subset-Accuracy: 0.812545 - F1-Score: 0.637391\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 113s 143ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982853 - Log-Loss: 2.542958 - Hamming-Loss: 0.007835 - Subset-Accuracy: 0.837057 - F1-Score: 0.704699\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 113s 143ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984184 - Log-Loss: 2.387010 - Hamming-Loss: 0.006304 - Subset-Accuracy: 0.846593 - F1-Score: 0.747950\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 110s 140ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985531 - Log-Loss: 2.264656 - Hamming-Loss: 0.005034 - Subset-Accuracy: 0.873914 - F1-Score: 0.791777\n",
      "Epoch 12/30\n",
      "790/790 [==============================] - 109s 138ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985832 - Log-Loss: 2.161531 - Hamming-Loss: 0.005031 - Subset-Accuracy: 0.828072 - F1-Score: 0.782223\n",
      "Epoch 13/30\n",
      "790/790 [==============================] - 108s 137ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986861 - Log-Loss: 2.006680 - Hamming-Loss: 0.003714 - Subset-Accuracy: 0.887581 - F1-Score: 0.837983\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 10, window_size - 4, embed_size - 20, latent_dim - 192, dropout_rate - 0.280\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8575738406890178\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 6 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, None, 30)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, None, 256)         163840    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,538,289\n",
      "Trainable params: 1,538,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 78s 98ms/step - loss: 0.0256 - acc: 0.9945 - val_loss: 0.0085 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.952694 - Log-Loss: 4.071035 - Hamming-Loss: 0.007174 - Subset-Accuracy: 0.753883 - F1-Score: 0.693981\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 75s 95ms/step - loss: 0.0139 - acc: 0.9969 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.967089 - Log-Loss: 3.731086 - Hamming-Loss: 0.007014 - Subset-Accuracy: 0.777602 - F1-Score: 0.704158\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.972144 - Log-Loss: 3.384806 - Hamming-Loss: 0.006078 - Subset-Accuracy: 0.793010 - F1-Score: 0.736202\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 77s 98ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.976310 - Log-Loss: 3.109077 - Hamming-Loss: 0.005159 - Subset-Accuracy: 0.788226 - F1-Score: 0.766799\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 79s 100ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980147 - Log-Loss: 2.888592 - Hamming-Loss: 0.004174 - Subset-Accuracy: 0.803636 - F1-Score: 0.805487\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982275 - Log-Loss: 2.699434 - Hamming-Loss: 0.003786 - Subset-Accuracy: 0.804312 - F1-Score: 0.819576\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 77s 98ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984058 - Log-Loss: 2.523787 - Hamming-Loss: 0.003461 - Subset-Accuracy: 0.813997 - F1-Score: 0.834341\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 74s 94ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985102 - Log-Loss: 2.366824 - Hamming-Loss: 0.003341 - Subset-Accuracy: 0.810325 - F1-Score: 0.838239\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 74s 93ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985368 - Log-Loss: 2.235378 - Hamming-Loss: 0.003254 - Subset-Accuracy: 0.799534 - F1-Score: 0.840246\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 71s 90ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985766 - Log-Loss: 2.111588 - Hamming-Loss: 0.003268 - Subset-Accuracy: 0.787788 - F1-Score: 0.837719\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 71s 89ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986856 - Log-Loss: 1.982179 - Hamming-Loss: 0.002943 - Subset-Accuracy: 0.811102 - F1-Score: 0.854909\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 6, window_size - 3, embed_size - 30, latent_dim - 128, dropout_rate - 0.044\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8734925287080191\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 7 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, None, 20)          899680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, None, 256)         153600    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 1,078,209\n",
      "Trainable params: 1,078,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 78s 98ms/step - loss: 0.0274 - acc: 0.9940 - val_loss: 0.0088 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.959923 - Log-Loss: 4.100820 - Hamming-Loss: 0.014820 - Subset-Accuracy: 0.743383 - F1-Score: 0.550269\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0156 - acc: 0.9965 - val_loss: 0.0067 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.966786 - Log-Loss: 3.847084 - Hamming-Loss: 0.015088 - Subset-Accuracy: 0.718734 - F1-Score: 0.546020\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.0057 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.971957 - Log-Loss: 3.615658 - Hamming-Loss: 0.013000 - Subset-Accuracy: 0.753984 - F1-Score: 0.584015\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.975810 - Log-Loss: 3.405108 - Hamming-Loss: 0.010913 - Subset-Accuracy: 0.762737 - F1-Score: 0.632097\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978254 - Log-Loss: 3.206338 - Hamming-Loss: 0.008837 - Subset-Accuracy: 0.799341 - F1-Score: 0.680984\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 90s 113ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.979853 - Log-Loss: 3.023629 - Hamming-Loss: 0.007224 - Subset-Accuracy: 0.821320 - F1-Score: 0.722260\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981496 - Log-Loss: 2.846850 - Hamming-Loss: 0.005968 - Subset-Accuracy: 0.830558 - F1-Score: 0.760072\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 88s 111ms/step - loss: 0.0080 - acc: 0.9979 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981611 - Log-Loss: 2.718602 - Hamming-Loss: 0.005594 - Subset-Accuracy: 0.811178 - F1-Score: 0.767507\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 88s 111ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984566 - Log-Loss: 2.510629 - Hamming-Loss: 0.004424 - Subset-Accuracy: 0.854620 - F1-Score: 0.810245\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 86s 108ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985061 - Log-Loss: 2.366506 - Hamming-Loss: 0.004595 - Subset-Accuracy: 0.805079 - F1-Score: 0.795501\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985974 - Log-Loss: 2.259925 - Hamming-Loss: 0.004012 - Subset-Accuracy: 0.815163 - F1-Score: 0.817615\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 7, window_size - 5, embed_size - 20, latent_dim - 128, dropout_rate - 0.180\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8523440201551155\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 10 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, None, 20)          899680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, None, 384)         328704    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 97)          37345     \n",
      "=================================================================\n",
      "Total params: 1,265,729\n",
      "Trainable params: 1,265,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 110s 139ms/step - loss: 0.0269 - acc: 0.9939 - val_loss: 0.0087 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.942925 - Log-Loss: 4.201725 - Hamming-Loss: 0.032656 - Subset-Accuracy: 0.696600 - F1-Score: 0.327170\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 109s 137ms/step - loss: 0.0162 - acc: 0.9964 - val_loss: 0.0065 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.944688 - Log-Loss: 4.002136 - Hamming-Loss: 0.028223 - Subset-Accuracy: 0.587335 - F1-Score: 0.331345\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 107s 135ms/step - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.940611 - Log-Loss: 3.795413 - Hamming-Loss: 0.024927 - Subset-Accuracy: 0.492707 - F1-Score: 0.324534\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 106s 134ms/step - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.946003 - Log-Loss: 3.607561 - Hamming-Loss: 0.021280 - Subset-Accuracy: 0.507534 - F1-Score: 0.363715\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.957702 - Log-Loss: 3.404057 - Hamming-Loss: 0.016795 - Subset-Accuracy: 0.610303 - F1-Score: 0.454996\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.962360 - Log-Loss: 3.223364 - Hamming-Loss: 0.013877 - Subset-Accuracy: 0.614073 - F1-Score: 0.502333\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 107s 136ms/step - loss: 0.0093 - acc: 0.9976 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.972104 - Log-Loss: 2.979716 - Hamming-Loss: 0.010764 - Subset-Accuracy: 0.673365 - F1-Score: 0.585745\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 106s 135ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.975660 - Log-Loss: 2.827952 - Hamming-Loss: 0.009300 - Subset-Accuracy: 0.651320 - F1-Score: 0.612777\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 104s 132ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.979138 - Log-Loss: 2.638046 - Hamming-Loss: 0.007798 - Subset-Accuracy: 0.686468 - F1-Score: 0.663914\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981906 - Log-Loss: 2.456747 - Hamming-Loss: 0.007252 - Subset-Accuracy: 0.708333 - F1-Score: 0.685400\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 105s 133ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984596 - Log-Loss: 2.252914 - Hamming-Loss: 0.005785 - Subset-Accuracy: 0.775900 - F1-Score: 0.747758\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 10, window_size - 4, embed_size - 20, latent_dim - 192, dropout_rate - 0.208\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8514997783578782\n",
      "\n",
      "\n",
      "\n",
      "upsampling for 5 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, None, 20)          899680    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, None, 384)         328704    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, None, 97)          37345     \n",
      "=================================================================\n",
      "Total params: 1,265,729\n",
      "Trainable params: 1,265,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0222 - acc: 0.9955 - val_loss: 0.0086 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.961375 - Log-Loss: 4.145612 - Hamming-Loss: 0.008576 - Subset-Accuracy: 0.780281 - F1-Score: 0.668564\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 77s 97ms/step - loss: 0.0130 - acc: 0.9972 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.971877 - Log-Loss: 3.767661 - Hamming-Loss: 0.007126 - Subset-Accuracy: 0.818685 - F1-Score: 0.719398\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.973840 - Log-Loss: 3.432563 - Hamming-Loss: 0.006258 - Subset-Accuracy: 0.810284 - F1-Score: 0.741083\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 79s 99ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.970893 - Log-Loss: 3.186894 - Hamming-Loss: 0.005297 - Subset-Accuracy: 0.802774 - F1-Score: 0.769203\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 79s 100ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.970432 - Log-Loss: 2.999218 - Hamming-Loss: 0.004686 - Subset-Accuracy: 0.781334 - F1-Score: 0.786138\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.974766 - Log-Loss: 2.812263 - Hamming-Loss: 0.003955 - Subset-Accuracy: 0.803072 - F1-Score: 0.816931\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 78s 98ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978634 - Log-Loss: 2.625855 - Hamming-Loss: 0.003452 - Subset-Accuracy: 0.811885 - F1-Score: 0.836865\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 77s 97ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.982914 - Log-Loss: 2.470032 - Hamming-Loss: 0.003313 - Subset-Accuracy: 0.802523 - F1-Score: 0.841961\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 77s 98ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984139 - Log-Loss: 2.348634 - Hamming-Loss: 0.003297 - Subset-Accuracy: 0.789881 - F1-Score: 0.840283\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 78s 99ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984972 - Log-Loss: 2.179238 - Hamming-Loss: 0.002882 - Subset-Accuracy: 0.818032 - F1-Score: 0.860422\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "predicting gold label targets ...\n",
      "predicting gold label targets done\n",
      "\n",
      "Parameters: up - 5, window_size - 4, embed_size - 20, latent_dim - 192, dropout_rate - 0.023\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8608092826589311\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "space = [Integer(5, 10, name='up'),\n",
    "        Integer(3, 5, name='window_size'),\n",
    "        Integer(2, 4, name='embed_size'),\n",
    "        Integer(1, 3, name='latent_dim'),\n",
    "        Real(0, 0.3, name='dropout_rate')]\n",
    "        #Integer(30, 30, name='epochs'),\n",
    "        #Integer(1, 60000, name='max_features'),\n",
    "        #Categorical([False], name='category'),\n",
    "        #Categorical([True], name='embedding'),\n",
    "        #Categorical(['CuDNNLSTM'], name='model_type')]\n",
    "\n",
    "res = gp_minimize(my_bayes_opt, space, n_calls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T22:57:15.709388Z",
     "start_time": "2019-05-03T22:57:15.693589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 3, 2, 0.044008894048118946]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T22:57:15.717754Z",
     "start_time": "2019-05-03T22:57:15.712600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8734925287080191"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T22:57:15.724863Z",
     "start_time": "2019-05-03T22:57:15.720262Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameter:\n",
    "param = {\n",
    "        'up': 2,                         # Times of upsampling for training data\n",
    "        'window_size': 5,                # Window size for word2vec\n",
    "        'embed_size': 10,                # Length of the vector that we willl get from the embedding layer\n",
    "        'latent_dim': 128,               # Hidden layers dimension \n",
    "        'dropout_rate': 0.5,             # Rate of the dropout layers\n",
    "        'epochs': 30,                    # Number of epochs\n",
    "        'max_features': 60000,           # Max num of vocabulary\n",
    "        'category': False,               # Is categoty labels\n",
    "        'embedding': True,               # Using pre-made embedidng matrix as weight\n",
    "        'model_type': 'CuDNNLSTM'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T15:57:00.806384Z",
     "start_time": "2019-04-16T15:26:09.629562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampling for 2 times...\n",
      "upsampling done\n",
      "\n",
      "preparing features ...\n",
      "preparing features done\n",
      "\n",
      "preparing embedding matrix ...\n",
      "preparing embedding matrix done\n",
      "\n",
      "preparing targets ...\n",
      "preparing targets done\n",
      "\n",
      "\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_56 (Embedding)     (None, None, 10)          449840    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_56 (Spatia (None, None, 10)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_56 (Bidirectio (None, None, 256)         143360    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_4 (SeqSel (None, None, 256)         16449     \n",
      "_________________________________________________________________\n",
      "time_distributed_54 (TimeDis (None, None, 97)          24929     \n",
      "=================================================================\n",
      "Total params: 634,578\n",
      "Trainable params: 634,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/30\n",
      "790/790 [==============================] - 98s 123ms/step - loss: 0.0268 - acc: 0.9935 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.960406 - Log-Loss: 4.268863 - Hamming-Loss: 0.004071 - Subset-Accuracy: 0.871473 - F1-Score: 0.816684\n",
      "Epoch 2/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0144 - acc: 0.9975 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.962378 - Log-Loss: 4.238472 - Hamming-Loss: 0.004537 - Subset-Accuracy: 0.873724 - F1-Score: 0.800203\n",
      "Epoch 3/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0142 - acc: 0.9975 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.961494 - Log-Loss: 4.194651 - Hamming-Loss: 0.006307 - Subset-Accuracy: 0.800111 - F1-Score: 0.725712\n",
      "Epoch 4/30\n",
      "790/790 [==============================] - 81s 103ms/step - loss: 0.0139 - acc: 0.9975 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.963885 - Log-Loss: 4.074402 - Hamming-Loss: 0.008229 - Subset-Accuracy: 0.798355 - F1-Score: 0.671856\n",
      "Epoch 5/30\n",
      "790/790 [==============================] - 81s 102ms/step - loss: 0.0133 - acc: 0.9975 - val_loss: 0.0083 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.961302 - Log-Loss: 3.974813 - Hamming-Loss: 0.012526 - Subset-Accuracy: 0.725474 - F1-Score: 0.562469\n",
      "Epoch 6/30\n",
      "790/790 [==============================] - 81s 102ms/step - loss: 0.0130 - acc: 0.9975 - val_loss: 0.0079 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.965208 - Log-Loss: 3.784160 - Hamming-Loss: 0.012554 - Subset-Accuracy: 0.728993 - F1-Score: 0.577950\n",
      "Epoch 7/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0125 - acc: 0.9975 - val_loss: 0.0075 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.968596 - Log-Loss: 3.629792 - Hamming-Loss: 0.011727 - Subset-Accuracy: 0.694149 - F1-Score: 0.601676\n",
      "Epoch 8/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0072 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.970881 - Log-Loss: 3.461921 - Hamming-Loss: 0.010956 - Subset-Accuracy: 0.667168 - F1-Score: 0.622276\n",
      "Epoch 9/30\n",
      "790/790 [==============================] - 83s 106ms/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.0069 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.971446 - Log-Loss: 3.368487 - Hamming-Loss: 0.011185 - Subset-Accuracy: 0.605916 - F1-Score: 0.617804\n",
      "Epoch 10/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0066 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.971381 - Log-Loss: 3.227504 - Hamming-Loss: 0.011002 - Subset-Accuracy: 0.664501 - F1-Score: 0.617865\n",
      "Epoch 11/30\n",
      "790/790 [==============================] - 84s 106ms/step - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0063 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.972550 - Log-Loss: 3.132271 - Hamming-Loss: 0.012266 - Subset-Accuracy: 0.629271 - F1-Score: 0.595846\n",
      "Epoch 12/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0062 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.971139 - Log-Loss: 3.086235 - Hamming-Loss: 0.014103 - Subset-Accuracy: 0.630345 - F1-Score: 0.555694\n",
      "Epoch 13/30\n",
      "790/790 [==============================] - 82s 103ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0060 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.967934 - Log-Loss: 3.092502 - Hamming-Loss: 0.016302 - Subset-Accuracy: 0.601604 - F1-Score: 0.514480\n",
      "Epoch 14/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0099 - acc: 0.9976 - val_loss: 0.0059 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.967255 - Log-Loss: 2.969672 - Hamming-Loss: 0.015854 - Subset-Accuracy: 0.589713 - F1-Score: 0.515806\n",
      "Epoch 15/30\n",
      "790/790 [==============================] - 82s 104ms/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0058 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.964471 - Log-Loss: 2.936507 - Hamming-Loss: 0.016980 - Subset-Accuracy: 0.582995 - F1-Score: 0.495016\n",
      "Epoch 16/30\n",
      "790/790 [==============================] - 80s 102ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0058 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.965964 - Log-Loss: 2.795623 - Hamming-Loss: 0.016454 - Subset-Accuracy: 0.608474 - F1-Score: 0.503414\n",
      "Epoch 17/30\n",
      "790/790 [==============================] - 80s 101ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.0057 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.955033 - Log-Loss: 2.831757 - Hamming-Loss: 0.017514 - Subset-Accuracy: 0.550785 - F1-Score: 0.477667\n",
      "Epoch 18/30\n",
      "790/790 [==============================] - 83s 105ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0056 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.951945 - Log-Loss: 2.916483 - Hamming-Loss: 0.019125 - Subset-Accuracy: 0.524568 - F1-Score: 0.454863\n",
      "training model done\n",
      "predicting test data ...\n",
      "predicting test data done\n",
      "\n",
      "I.CAD.after_DCT.event:\n",
      " [[315431      0]\n",
      " [     4      0]] \n",
      "\n",
      "I.CAD.after_DCT.mention:\n",
      " [[314842     66]\n",
      " [   439     88]] \n",
      "\n",
      "I.CAD.after_DCT.symptom:\n",
      " [[315430      0]\n",
      " [     5      0]] \n",
      "\n",
      "I.CAD.before_DCT.event:\n",
      " [[314167      0]\n",
      " [  1268      0]] \n",
      "\n",
      "I.CAD.before_DCT.mention:\n",
      " [[314832     71]\n",
      " [   444     88]] \n",
      "\n",
      "I.CAD.before_DCT.symptom:\n",
      " [[315218      0]\n",
      " [   217      0]] \n",
      "\n",
      "I.CAD.before_DCT.test:\n",
      " [[313419    348]\n",
      " [  1430    238]] \n",
      "\n",
      "I.CAD.during_DCT.event:\n",
      " [[315361      0]\n",
      " [    74      0]] \n",
      "\n",
      "I.CAD.during_DCT.mention:\n",
      " [[314807     68]\n",
      " [   478     82]] \n",
      "\n",
      "I.CAD.during_DCT.symptom:\n",
      " [[315295      0]\n",
      " [   140      0]] \n",
      "\n",
      "I.CAD.during_DCT.test:\n",
      " [[315253      0]\n",
      " [   182      0]] \n",
      "\n",
      "I.DIABETES.after_DCT.mention:\n",
      " [[313966    321]\n",
      " [   668    480]] \n",
      "\n",
      "I.DIABETES.before_DCT.A1C:\n",
      " [[315039      0]\n",
      " [   396      0]] \n",
      "\n",
      "I.DIABETES.before_DCT.glucose:\n",
      " [[315270      0]\n",
      " [   165      0]] \n",
      "\n",
      "I.DIABETES.before_DCT.mention:\n",
      " [[313963    324]\n",
      " [   660    488]] \n",
      "\n",
      "I.DIABETES.during_DCT.A1C:\n",
      " [[315395      0]\n",
      " [    40      0]] \n",
      "\n",
      "I.DIABETES.during_DCT.glucose:\n",
      " [[315371      0]\n",
      " [    64      0]] \n",
      "\n",
      "I.DIABETES.during_DCT.mention:\n",
      " [[313952    328]\n",
      " [   663    492]] \n",
      "\n",
      "I.FAMILY_HIST.present:\n",
      " [[315221      0]\n",
      " [   214      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.after_DCT.mention:\n",
      " [[315069      0]\n",
      " [   366      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.before_DCT.high_LDL:\n",
      " [[315349      0]\n",
      " [    86      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.before_DCT.high_chol.:\n",
      " [[315385      0]\n",
      " [    50      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.before_DCT.mention:\n",
      " [[315069      0]\n",
      " [   366      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.during_DCT.high_LDL:\n",
      " [[315429      0]\n",
      " [     6      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.during_DCT.high_chol.:\n",
      " [[315424      0]\n",
      " [    11      0]] \n",
      "\n",
      "I.HYPERLIPIDEMIA.during_DCT.mention:\n",
      " [[315069      0]\n",
      " [   366      0]] \n",
      "\n",
      "I.HYPERTENSION.after_DCT.mention:\n",
      " [[314779      2]\n",
      " [   652      2]] \n",
      "\n",
      "I.HYPERTENSION.before_DCT.high_bp:\n",
      " [[315322      0]\n",
      " [   113      0]] \n",
      "\n",
      "I.HYPERTENSION.before_DCT.mention:\n",
      " [[314775      0]\n",
      " [   657      3]] \n",
      "\n",
      "I.HYPERTENSION.during_DCT.high_bp:\n",
      " [[314775     14]\n",
      " [   627     19]] \n",
      "\n",
      "I.HYPERTENSION.during_DCT.mention:\n",
      " [[314768      2]\n",
      " [   663      2]] \n",
      "\n",
      "I.MEDICATION.after_DCT.ACE_inhibitor:\n",
      " [[315036      0]\n",
      " [   399      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.ARB:\n",
      " [[315326      0]\n",
      " [   109      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.DPP4_inhibitors:\n",
      " [[315431      0]\n",
      " [     4      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.anti_diabetes:\n",
      " [[315435      0]\n",
      " [     0      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.aspirin:\n",
      " [[314980      0]\n",
      " [   455      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.beta_blocker:\n",
      " [[314834      0]\n",
      " [   601      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.calcium_channel_blocker:\n",
      " [[315217      0]\n",
      " [   218      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.diuretic:\n",
      " [[315302      0]\n",
      " [   133      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.ezetimibe:\n",
      " [[315414      0]\n",
      " [    21      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.fibrate:\n",
      " [[315375      0]\n",
      " [    60      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.insulin:\n",
      " [[314897     50]\n",
      " [   446     42]] \n",
      "\n",
      "I.MEDICATION.after_DCT.metformin:\n",
      " [[315159      0]\n",
      " [   276      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.niacin:\n",
      " [[315423      0]\n",
      " [    12      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.nitrate:\n",
      " [[315251      0]\n",
      " [   184      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.statin:\n",
      " [[314923      0]\n",
      " [   512      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.sulfonylureas:\n",
      " [[315230      0]\n",
      " [   205      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.thiazolidinedione:\n",
      " [[315389      0]\n",
      " [    46      0]] \n",
      "\n",
      "I.MEDICATION.after_DCT.thienopyridine:\n",
      " [[315280      0]\n",
      " [   155      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.ACE_inhibitor:\n",
      " [[315065      0]\n",
      " [   370      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.ARB:\n",
      " [[315304      0]\n",
      " [   131      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.DPP4_inhibitors:\n",
      " [[315431      0]\n",
      " [     4      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.anti_diabetes:\n",
      " [[315435      0]\n",
      " [     0      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.aspirin:\n",
      " [[314982      0]\n",
      " [   453      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.beta_blocker:\n",
      " [[314815      0]\n",
      " [   620      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.calcium_channel_blocker:\n",
      " [[315215      0]\n",
      " [   220      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.diuretic:\n",
      " [[315272      0]\n",
      " [   163      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.ezetimibe:\n",
      " [[315421      0]\n",
      " [    14      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.fibrate:\n",
      " [[315379      0]\n",
      " [    56      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.insulin:\n",
      " [[314919     49]\n",
      " [   431     36]] \n",
      "\n",
      "I.MEDICATION.before_DCT.metformin:\n",
      " [[315144      0]\n",
      " [   291      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.niacin:\n",
      " [[315424      0]\n",
      " [    11      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.nitrate:\n",
      " [[315229      0]\n",
      " [   206      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.statin:\n",
      " [[314919      0]\n",
      " [   516      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.sulfonylureas:\n",
      " [[315220      0]\n",
      " [   215      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.thiazolidinedione:\n",
      " [[315376      0]\n",
      " [    59      0]] \n",
      "\n",
      "I.MEDICATION.before_DCT.thienopyridine:\n",
      " [[315252      0]\n",
      " [   183      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.ACE_inhibitor:\n",
      " [[315085      0]\n",
      " [   350      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.ARB:\n",
      " [[315320      0]\n",
      " [   115      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.DPP4_inhibitors:\n",
      " [[315431      0]\n",
      " [     4      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.anti_diabetes:\n",
      " [[315435      0]\n",
      " [     0      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.aspirin:\n",
      " [[314966      0]\n",
      " [   469      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.beta_blocker:\n",
      " [[314832      0]\n",
      " [   603      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.calcium_channel_blocker:\n",
      " [[315225      0]\n",
      " [   210      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.diuretic:\n",
      " [[315308      0]\n",
      " [   127      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.ezetimibe:\n",
      " [[315421      0]\n",
      " [    14      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.fibrate:\n",
      " [[315384      0]\n",
      " [    51      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.insulin:\n",
      " [[314912     54]\n",
      " [   423     46]] \n",
      "\n",
      "I.MEDICATION.during_DCT.metformin:\n",
      " [[315200      0]\n",
      " [   235      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.niacin:\n",
      " [[315428      0]\n",
      " [     7      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.nitrate:\n",
      " [[315231      0]\n",
      " [   204      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.statin:\n",
      " [[314951      0]\n",
      " [   484      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.sulfonylureas:\n",
      " [[315230      0]\n",
      " [   205      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.thiazolidinedione:\n",
      " [[315390      0]\n",
      " [    45      0]] \n",
      "\n",
      "I.MEDICATION.during_DCT.thienopyridine:\n",
      " [[315272      0]\n",
      " [   163      0]] \n",
      "\n",
      "I.OBESE.after_DCT.BMI:\n",
      " [[315432      0]\n",
      " [     3      0]] \n",
      "\n",
      "I.OBESE.after_DCT.mention:\n",
      " [[315311      0]\n",
      " [   124      0]] \n",
      "\n",
      "I.OBESE.before_DCT.BMI:\n",
      " [[315432      0]\n",
      " [     3      0]] \n",
      "\n",
      "I.OBESE.before_DCT.mention:\n",
      " [[315311      0]\n",
      " [   124      0]] \n",
      "\n",
      "I.OBESE.during_DCT.BMI:\n",
      " [[315399      0]\n",
      " [    36      0]] \n",
      "\n",
      "I.OBESE.during_DCT.mention:\n",
      " [[315295      0]\n",
      " [   140      0]] \n",
      "\n",
      "I.SMOKER.current:\n",
      " [[315224      0]\n",
      " [   211      0]] \n",
      "\n",
      "I.SMOKER.ever:\n",
      " [[315419      0]\n",
      " [    16      0]] \n",
      "\n",
      "I.SMOKER.never:\n",
      " [[315102      0]\n",
      " [   333      0]] \n",
      "\n",
      "I.SMOKER.past:\n",
      " [[314573      0]\n",
      " [   861      1]] \n",
      "\n",
      "I.SMOKER.unknown:\n",
      " [[315089    136]\n",
      " [   113     97]] \n",
      "\n",
      "O:\n",
      " [[  5027   9187]\n",
      " [  2759 298462]] \n",
      "\n",
      "predicting gold label targets ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting gold label targets done\n",
      "\n",
      "I.CAD.after_DCT.event:\n",
      " [[  998  9307]\n",
      " [  174 38865]] \n",
      "\n",
      "I.CAD.after_DCT.mention:\n",
      " [[38865   174]\n",
      " [ 9307   998]] \n",
      "\n",
      "F1 Scores:\n",
      "ALL (average=\"micro\"): 0.1739130434782609\n",
      "I.CAD.after_DCT.event: 0.0\n",
      "I.CAD.after_DCT.mention: 0.47787610619469034\n",
      "I.CAD.after_DCT.symptom: 0.0\n",
      "I.CAD.before_DCT.event: 0.0\n",
      "I.CAD.before_DCT.mention: 0.4978165938864629\n",
      "I.CAD.before_DCT.symptom: 0.0\n",
      "I.CAD.before_DCT.test: 0.5319148936170213\n",
      "I.CAD.during_DCT.event: 0.0\n",
      "I.CAD.during_DCT.mention: 0.47413793103448276\n",
      "I.CAD.during_DCT.symptom: 0.0\n",
      "I.CAD.during_DCT.test: 0.0\n",
      "I.DIABETES.after_DCT.mention: 0.7346221441124782\n",
      "I.DIABETES.before_DCT.A1C: 0.0\n",
      "I.DIABETES.before_DCT.glucose: 0.0\n",
      "I.DIABETES.before_DCT.mention: 0.7288732394366196\n",
      "I.DIABETES.during_DCT.A1C: 0.0\n",
      "I.DIABETES.during_DCT.glucose: 0.0\n",
      "I.DIABETES.during_DCT.mention: 0.7412587412587414\n",
      "I.FAMILY_HIST.present: 0.0\n",
      "I.HYPERLIPIDEMIA.after_DCT.mention: 0.0\n",
      "I.HYPERLIPIDEMIA.before_DCT.high_LDL: 0.0\n",
      "I.HYPERLIPIDEMIA.before_DCT.high_chol.: 0.0\n",
      "I.HYPERLIPIDEMIA.before_DCT.mention: 0.0\n",
      "I.HYPERLIPIDEMIA.during_DCT.high_LDL: 0.0\n",
      "I.HYPERLIPIDEMIA.during_DCT.high_chol.: 0.0\n",
      "I.HYPERLIPIDEMIA.during_DCT.mention: 0.0\n",
      "I.HYPERTENSION.after_DCT.mention: 0.021798365122615803\n",
      "I.HYPERTENSION.before_DCT.high_bp: 0.0\n",
      "I.HYPERTENSION.before_DCT.mention: 0.01643835616438356\n",
      "I.HYPERTENSION.during_DCT.high_bp: 0.043243243243243246\n",
      "I.HYPERTENSION.during_DCT.mention: 0.016348773841961855\n",
      "I.MEDICATION.after_DCT.ACE_inhibitor: 0.0\n",
      "I.MEDICATION.after_DCT.ARB: 0.0\n",
      "I.MEDICATION.after_DCT.DPP4_inhibitors: 0.0\n",
      "I.MEDICATION.after_DCT.anti_diabetes: 0.0\n",
      "I.MEDICATION.after_DCT.aspirin: 0.0\n",
      "I.MEDICATION.after_DCT.beta_blocker: 0.0\n",
      "I.MEDICATION.after_DCT.calcium_channel_blocker: 0.0\n",
      "I.MEDICATION.after_DCT.diuretic: 0.0\n",
      "I.MEDICATION.after_DCT.ezetimibe: 0.0\n",
      "I.MEDICATION.after_DCT.fibrate: 0.0\n",
      "I.MEDICATION.after_DCT.insulin: 0.2054794520547945\n",
      "I.MEDICATION.after_DCT.metformin: 0.0\n",
      "I.MEDICATION.after_DCT.niacin: 0.0\n",
      "I.MEDICATION.after_DCT.nitrate: 0.0\n",
      "I.MEDICATION.after_DCT.statin: 0.0\n",
      "I.MEDICATION.after_DCT.sulfonylureas: 0.0\n",
      "I.MEDICATION.after_DCT.thiazolidinedione: 0.0\n",
      "I.MEDICATION.after_DCT.thienopyridine: 0.0\n",
      "I.MEDICATION.before_DCT.ACE_inhibitor: 0.0\n",
      "I.MEDICATION.before_DCT.ARB: 0.0\n",
      "I.MEDICATION.before_DCT.DPP4_inhibitors: 0.0\n",
      "I.MEDICATION.before_DCT.anti_diabetes: 0.0\n",
      "I.MEDICATION.before_DCT.aspirin: 0.0\n",
      "I.MEDICATION.before_DCT.beta_blocker: 0.0\n",
      "I.MEDICATION.before_DCT.calcium_channel_blocker: 0.0\n",
      "I.MEDICATION.before_DCT.diuretic: 0.0\n",
      "I.MEDICATION.before_DCT.ezetimibe: 0.0\n",
      "I.MEDICATION.before_DCT.fibrate: 0.0\n",
      "I.MEDICATION.before_DCT.insulin: 0.19444444444444445\n",
      "I.MEDICATION.before_DCT.metformin: 0.0\n",
      "I.MEDICATION.before_DCT.niacin: 0.0\n",
      "I.MEDICATION.before_DCT.nitrate: 0.0\n",
      "I.MEDICATION.before_DCT.statin: 0.0\n",
      "I.MEDICATION.before_DCT.sulfonylureas: 0.0\n",
      "I.MEDICATION.before_DCT.thiazolidinedione: 0.0\n",
      "I.MEDICATION.before_DCT.thienopyridine: 0.0\n",
      "I.MEDICATION.during_DCT.ACE_inhibitor: 0.0\n",
      "I.MEDICATION.during_DCT.ARB: 0.0\n",
      "I.MEDICATION.during_DCT.DPP4_inhibitors: 0.0\n",
      "I.MEDICATION.during_DCT.anti_diabetes: 0.0\n",
      "I.MEDICATION.during_DCT.aspirin: 0.0\n",
      "I.MEDICATION.during_DCT.beta_blocker: 0.0\n",
      "I.MEDICATION.during_DCT.calcium_channel_blocker: 0.0\n",
      "I.MEDICATION.during_DCT.diuretic: 0.0\n",
      "I.MEDICATION.during_DCT.ezetimibe: 0.0\n",
      "I.MEDICATION.during_DCT.fibrate: 0.0\n",
      "I.MEDICATION.during_DCT.insulin: 0.20689655172413793\n",
      "I.MEDICATION.during_DCT.metformin: 0.0\n",
      "I.MEDICATION.during_DCT.niacin: 0.0\n",
      "I.MEDICATION.during_DCT.nitrate: 0.0\n",
      "I.MEDICATION.during_DCT.statin: 0.0\n",
      "I.MEDICATION.during_DCT.sulfonylureas: 0.0\n",
      "I.MEDICATION.during_DCT.thiazolidinedione: 0.0\n",
      "I.MEDICATION.during_DCT.thienopyridine: 0.0\n",
      "I.OBESE.after_DCT.BMI: 0.0\n",
      "I.OBESE.after_DCT.mention: 0.0\n",
      "I.OBESE.before_DCT.BMI: 0.0\n",
      "I.OBESE.before_DCT.mention: 0.0\n",
      "I.OBESE.during_DCT.BMI: 0.0\n",
      "I.OBESE.during_DCT.mention: 0.0\n",
      "I.SMOKER.current: 0.0\n",
      "I.SMOKER.ever: 0.0\n",
      "I.SMOKER.never: 0.0\n",
      "I.SMOKER.past: 0.017543859649122806\n",
      "I.SMOKER.unknown: 0.5607476635514018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1 = no_pad_time_tuning(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T16:15:15.477947Z",
     "start_time": "2019-04-16T16:15:15.467995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1739130434782609"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T13:36:36.186065Z",
     "start_time": "2019-04-11T13:25:08.620985Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b11c4f142a74ba79392447e4637590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='total progress', max=10, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7513b6f0f674f469a352c809821c5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8ccde4a5fe463fad26cef5a3c2e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 val metrics: - Log-Loss: 0.351766 - Hamming-Loss: 0.001083 - Subset-Accuracy: 0.957040 - F1-Score: 0.949087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d87c57359ca45e0a346e68aff4dc302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86770373d9724fbabf17d384900e66ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 val metrics: - Log-Loss: 0.347610 - Hamming-Loss: 0.001072 - Subset-Accuracy: 0.957779 - F1-Score: 0.949651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b6af6577c84fba9b7ab5b7b9b84beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 3 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cecc6d71264acfaae89f1d150d380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 3 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 val metrics: - Log-Loss: 0.337398 - Hamming-Loss: 0.001058 - Subset-Accuracy: 0.957161 - F1-Score: 0.950335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f563c7f61648f889ed1ef972aee5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 4 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bed8c3c35c2486dbc13fd4de8e9b24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 4 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 val metrics: - Log-Loss: 0.333103 - Hamming-Loss: 0.001052 - Subset-Accuracy: 0.956803 - F1-Score: 0.950598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84d4e8849c44cc89c81f1d8ed734e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 5 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d337f48d73c7436198a10389683f59ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 5 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 val metrics: - Log-Loss: 0.322978 - Hamming-Loss: 0.001027 - Subset-Accuracy: 0.956368 - F1-Score: 0.951716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7886b496cb449a951ed2d49083b57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 6 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e6260244cb4df7a393a34c323f2b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 6 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 val metrics: - Log-Loss: 0.321765 - Hamming-Loss: 0.001019 - Subset-Accuracy: 0.956749 - F1-Score: 0.952139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eaac125a9a4c729ae2b9ad9b18a325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 7 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6824658bad4631963d0f546dcc3bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 7 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 val metrics: - Log-Loss: 0.319472 - Hamming-Loss: 0.001020 - Subset-Accuracy: 0.957300 - F1-Score: 0.952150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67447e48d78c45b88db4f86298450c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 8 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4622edacf18d4eb28f45f81fa279ab45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 8 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 val metrics: - Log-Loss: 0.311171 - Hamming-Loss: 0.001006 - Subset-Accuracy: 0.956390 - F1-Score: 0.952800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96a5c452c3a4192ad0f136a3d88bf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 9 training', max=790, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db470483ec647e99aae0aa74dad9d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 9 validating', max=514, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 val metrics: - Log-Loss: 0.312243 - Hamming-Loss: 0.001003 - Subset-Accuracy: 0.956964 - F1-Score: 0.952942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec33517026f45ae998fb9c3d2979dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 10 training', max=790, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79092a657bca475bbe855316071b148f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 10 validating', max=514, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 val metrics: - Log-Loss: 0.304512 - Hamming-Loss: 0.000993 - Subset-Accuracy: 0.957218 - F1-Score: 0.953429\n"
     ]
    }
   ],
   "source": [
    "# model training batch by batch\n",
    "epochs = 10\n",
    "patience = 3\n",
    "threshhold = 0.001\n",
    "loss_n = []\n",
    "for epoch in tnrange(epochs, desc='total progress'):\n",
    "    for x, y in tqdm_notebook(zip(X_train_seq, Y_train), desc='epoch '+str(epoch+1)+' training', total=len(Y_train)):\n",
    "        ly = len(y)\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y = np.array(y).reshape((1,ly,-1))\n",
    "        model.train_on_batch(x, y)\n",
    "    Y_pred = []\n",
    "    for x in tqdm_notebook(X_test_seq, desc='epoch '+str(epoch+1)+' validating'):\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y_pred = np.squeeze(model.predict_on_batch(x))\n",
    "        Y_pred.append(y_pred)\n",
    "    Y_pred = np.concatenate(Y_pred)\n",
    "    Y_pred_ham = Y_pred > 0.5\n",
    "    Y_val = np.concatenate(Y_test)\n",
    "    loss = log_loss(Y_val, Y_pred)\n",
    "    ham = hamming_loss(Y_val, Y_pred_ham)\n",
    "    sub = accuracy_score(Y_val, Y_pred_ham)\n",
    "    f1 = f1_score(Y_val, Y_pred_ham, average='micro')\n",
    "    print(\"Epoch %d val metrics: - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1-Score: %.6f\" % (epoch, loss, ham, sub, f1))\n",
    "    loss_n.append(loss)\n",
    "    if len(loss_n) > patience:\n",
    "        for i in loss_n[-4:]:\n",
    "            if loss_n[-1] >= i + threshhold:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T19:54:19.765875Z",
     "start_time": "2019-04-10T19:43:41.057393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33757a182c2249ff8ba0c28823f552e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb453f68d3684f6dba9391fb090efa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8398e875dc54809a9864a8625351694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 val metrics: - Log-Loss: 0.239218 - Hamming-Loss: 0.010005 - Subset-Accuracy: 0.954910\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399938569dd24019a7676f4ef594c2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1b97df571749c1bfc49b82f087442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 val metrics: - Log-Loss: 0.212364 - Hamming-Loss: 0.009780 - Subset-Accuracy: 0.955373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318d1af79b6b484396616b6fbcf9ec21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1430ca00c1143d89ae78607da369b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 val metrics: - Log-Loss: 0.196264 - Hamming-Loss: 0.009550 - Subset-Accuracy: 0.955572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d5c49481534e89a822c29270718e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff530d2406544c3b05a92b583e77734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 val metrics: - Log-Loss: 0.179833 - Hamming-Loss: 0.009293 - Subset-Accuracy: 0.955243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947023b3062b4843bdfbf9c925cbab7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b458d7820ccb4c0484fb3894ab919fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 val metrics: - Log-Loss: 0.165139 - Hamming-Loss: 0.008795 - Subset-Accuracy: 0.956336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66473635cc93414c88a3b2a50b95eab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ec1782959c4fbe851006a4089360d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 val metrics: - Log-Loss: 0.154288 - Hamming-Loss: 0.008518 - Subset-Accuracy: 0.956742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e969f0ebc046499abe42746f9475a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d500b95c102741208b01820022dc6962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 val metrics: - Log-Loss: 0.148316 - Hamming-Loss: 0.008245 - Subset-Accuracy: 0.957681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef7f2deab4c494aa0086031cca5b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608faccd9b8b400bbeac0c3ac1145018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 val metrics: - Log-Loss: 0.141742 - Hamming-Loss: 0.008039 - Subset-Accuracy: 0.958841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a245fe95eb42478e246b2364ac8793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5eb7c584da465b8f7c4c10fd64cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 val metrics: - Log-Loss: 0.137761 - Hamming-Loss: 0.007891 - Subset-Accuracy: 0.959345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879833b1b85545b3ae1d7137fce3beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='training', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6454aad561144d16a28ba7f74233a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='predicting', max=514, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 val metrics: - Log-Loss: 0.135815 - Hamming-Loss: 0.007833 - Subset-Accuracy: 0.959215\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "epochs = 10\n",
    "for epoch in tnrange(epochs):\n",
    "    for x, y in tqdm_notebook(zip(X_train_seq, Y_cat_train), desc='training'):\n",
    "        ly = len(y)\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y = np.array(y).reshape((1,ly,-1))\n",
    "        #if x.shape[1] != y.shape[1]:\n",
    "        #    print(x.shape,y.shape)\n",
    "        cat_model.train_on_batch(x, y)\n",
    "    Y_cat_pred = []\n",
    "    for x in tqdm_notebook(X_test_seq, desc='predicting'):\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        #if x.shape[1] != y.shape[1]:\n",
    "        #    print(x.shape,y.shape)\n",
    "        y_pred = np.squeeze(cat_model.predict_on_batch(x))\n",
    "        Y_cat_pred.append(y_pred)\n",
    "    Y_cat_pred = np.concatenate(Y_cat_pred)\n",
    "    Y_cat_pred_ham = Y_cat_pred > 0.5\n",
    "    Y_cat_val = np.concatenate(Y_cat_test)\n",
    "    #print(y_val.sum(), y_pred.sum())\n",
    "    #roc = roc_auc_score(Y_val, Y_pred)\n",
    "    loss = log_loss(Y_cat_val, Y_cat_pred)\n",
    "    ham = hamming_loss(Y_cat_val, Y_cat_pred_ham)\n",
    "    sub = accuracy_score(Y_cat_val, Y_cat_pred_ham)\n",
    "    f1 = f1_score(Y_val, Y_pred_ham, average='micro')\n",
    "    print(\"Epoch %d val metrics: - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1_Score: %.6f\" % (epoch, loss, ham, sub, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
