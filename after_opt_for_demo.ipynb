{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T09:59:32.209805Z",
     "start_time": "2019-06-03T14:08:52.391611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 11, 'window_size': 4, 'embed_size': 4, 'latent_dim': 5, 'dropout_rate': 0.37619637288650404, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 11 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_101 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_101 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_101 (Bidirecti (None, None, 640)         926720    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_101 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,947,577\n",
      "Trainable params: 2,947,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 217s 275ms/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0071 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.960419 - Log-Loss: 3.326347 - Hamming-Loss: 0.004666 - Subset-Accuracy: 0.737172 - F1-Score: 0.771772\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 183s 231ms/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978919 - Log-Loss: 2.604794 - Hamming-Loss: 0.002658 - Subset-Accuracy: 0.870246 - F1-Score: 0.877080\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 184s 233ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982394 - Log-Loss: 2.223452 - Hamming-Loss: 0.001956 - Subset-Accuracy: 0.893249 - F1-Score: 0.908339\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 184s 233ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984926 - Log-Loss: 1.923077 - Hamming-Loss: 0.001642 - Subset-Accuracy: 0.903375 - F1-Score: 0.922570\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 184s 233ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986287 - Log-Loss: 1.661972 - Hamming-Loss: 0.001532 - Subset-Accuracy: 0.908827 - F1-Score: 0.927648\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8599048039648658\n",
      "\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1118.9903\n",
      "Function value obtained: -0.8599\n",
      "Current minimum: -0.8599\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 7, 'window_size': 4, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.006443453264670109, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 7 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_102 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_102 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_102 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_102 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 177s 224ms/step - loss: 0.0208 - acc: 0.9954 - val_loss: 0.0075 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.970953 - Log-Loss: 3.342580 - Hamming-Loss: 0.003357 - Subset-Accuracy: 0.821107 - F1-Score: 0.839547\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 141s 179ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978947 - Log-Loss: 2.701533 - Hamming-Loss: 0.002125 - Subset-Accuracy: 0.895814 - F1-Score: 0.899737\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 143s 181ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982097 - Log-Loss: 2.308042 - Hamming-Loss: 0.001971 - Subset-Accuracy: 0.891474 - F1-Score: 0.905485\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 142s 180ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983901 - Log-Loss: 2.025250 - Hamming-Loss: 0.001853 - Subset-Accuracy: 0.892431 - F1-Score: 0.910710\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 142s 179ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985491 - Log-Loss: 1.839574 - Hamming-Loss: 0.001813 - Subset-Accuracy: 0.894225 - F1-Score: 0.912694\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8532100772043886\n",
      "\n",
      "\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 910.7336\n",
      "Function value obtained: -0.8532\n",
      "Current minimum: -0.8599\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 14, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.13504761179447702, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 14 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_103 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_103 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_103 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "790/790 [==============================] - 250s 317ms/step - loss: 0.0220 - acc: 0.9949 - val_loss: 0.0064 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.956992 - Log-Loss: 3.342014 - Hamming-Loss: 0.006210 - Subset-Accuracy: 0.647712 - F1-Score: 0.690825\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 216s 274ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.976304 - Log-Loss: 2.692041 - Hamming-Loss: 0.003769 - Subset-Accuracy: 0.820296 - F1-Score: 0.824044\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 217s 275ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981220 - Log-Loss: 2.331304 - Hamming-Loss: 0.002903 - Subset-Accuracy: 0.841974 - F1-Score: 0.863321\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 216s 274ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984836 - Log-Loss: 1.970563 - Hamming-Loss: 0.002064 - Subset-Accuracy: 0.888411 - F1-Score: 0.902411\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 216s 274ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985575 - Log-Loss: 1.772224 - Hamming-Loss: 0.001988 - Subset-Accuracy: 0.888582 - F1-Score: 0.905545\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8646564508156204\n",
      "\n",
      "\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1287.1557\n",
      "Function value obtained: -0.8647\n",
      "Current minimum: -0.8647\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 12, 'window_size': 4, 'embed_size': 4, 'latent_dim': 4, 'dropout_rate': 0.4963351832156078, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 12 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_104 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_104 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_104 (Bidirecti (None, None, 512)         610304    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_104 (Spati (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, None, 300)         153900    \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,592,761\n",
      "Trainable params: 2,592,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 195s 247ms/step - loss: 0.0241 - acc: 0.9943 - val_loss: 0.0069 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.960990 - Log-Loss: 3.399576 - Hamming-Loss: 0.004219 - Subset-Accuracy: 0.784710 - F1-Score: 0.802153\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 157s 199ms/step - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977324 - Log-Loss: 2.693851 - Hamming-Loss: 0.002705 - Subset-Accuracy: 0.873797 - F1-Score: 0.874814\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 157s 199ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982049 - Log-Loss: 2.298760 - Hamming-Loss: 0.002168 - Subset-Accuracy: 0.888966 - F1-Score: 0.897970\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 157s 199ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984727 - Log-Loss: 1.970348 - Hamming-Loss: 0.001767 - Subset-Accuracy: 0.902459 - F1-Score: 0.915783\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 158s 200ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987195 - Log-Loss: 1.706064 - Hamming-Loss: 0.001722 - Subset-Accuracy: 0.904760 - F1-Score: 0.918212\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8582210757619183\n",
      "\n",
      "\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 990.8465\n",
      "Function value obtained: -0.8582\n",
      "Current minimum: -0.8647\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 6, 'window_size': 5, 'embed_size': 4, 'latent_dim': 5, 'dropout_rate': 0.15509608440640063, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 6 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_105 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_105 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_105 (Bidirecti (None, None, 640)         926720    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_105 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,947,577\n",
      "Trainable params: 2,947,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 167s 211ms/step - loss: 0.0202 - acc: 0.9953 - val_loss: 0.0067 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.972743 - Log-Loss: 3.157207 - Hamming-Loss: 0.002577 - Subset-Accuracy: 0.873128 - F1-Score: 0.877809\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 132s 167ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.978265 - Log-Loss: 2.586890 - Hamming-Loss: 0.002658 - Subset-Accuracy: 0.879145 - F1-Score: 0.875447\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 132s 168ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983605 - Log-Loss: 2.106198 - Hamming-Loss: 0.001788 - Subset-Accuracy: 0.915821 - F1-Score: 0.916217\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 133s 168ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985708 - Log-Loss: 1.836160 - Hamming-Loss: 0.001511 - Subset-Accuracy: 0.923791 - F1-Score: 0.928597\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 132s 167ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986598 - Log-Loss: 1.642196 - Hamming-Loss: 0.001479 - Subset-Accuracy: 0.923934 - F1-Score: 0.929988\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8640424069893001\n",
      "\n",
      "\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 857.8353\n",
      "Function value obtained: -0.8640\n",
      "Current minimum: -0.8647\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 11, 'window_size': 3, 'embed_size': 4, 'latent_dim': 3, 'dropout_rate': 0.02303396937163466, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 11 times...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_106 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_106 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_106 (Bidirecti (None, None, 384)         359424    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_106 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,303,481\n",
      "Trainable params: 2,303,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 160s 203ms/step - loss: 0.0233 - acc: 0.9945 - val_loss: 0.0065 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.971582 - Log-Loss: 3.132575 - Hamming-Loss: 0.003146 - Subset-Accuracy: 0.851155 - F1-Score: 0.851754\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980098 - Log-Loss: 2.431921 - Hamming-Loss: 0.002305 - Subset-Accuracy: 0.907433 - F1-Score: 0.894006\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983619 - Log-Loss: 1.989164 - Hamming-Loss: 0.001771 - Subset-Accuracy: 0.925122 - F1-Score: 0.917424\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985371 - Log-Loss: 1.733922 - Hamming-Loss: 0.001649 - Subset-Accuracy: 0.922669 - F1-Score: 0.922475\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986191 - Log-Loss: 1.541051 - Hamming-Loss: 0.001700 - Subset-Accuracy: 0.909154 - F1-Score: 0.919150\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8596873144666534\n",
      "\n",
      "\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 824.5920\n",
      "Function value obtained: -0.8597\n",
      "Current minimum: -0.8647\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 7, 'window_size': 5, 'embed_size': 4, 'latent_dim': 5, 'dropout_rate': 0.384700492970829, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 7 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_107 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_107 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_107 (Bidirecti (None, None, 640)         926720    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_107 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,947,577\n",
      "Trainable params: 2,947,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 178s 226ms/step - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0069 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.968972 - Log-Loss: 3.280782 - Hamming-Loss: 0.002867 - Subset-Accuracy: 0.815303 - F1-Score: 0.858418\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 143s 181ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980301 - Log-Loss: 2.611518 - Hamming-Loss: 0.001678 - Subset-Accuracy: 0.916284 - F1-Score: 0.920658\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 142s 180ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984297 - Log-Loss: 2.181201 - Hamming-Loss: 0.001428 - Subset-Accuracy: 0.925823 - F1-Score: 0.932403\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 143s 181ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986588 - Log-Loss: 1.809584 - Hamming-Loss: 0.001339 - Subset-Accuracy: 0.930090 - F1-Score: 0.936645\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 142s 180ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987723 - Log-Loss: 1.585742 - Hamming-Loss: 0.001452 - Subset-Accuracy: 0.920136 - F1-Score: 0.931073\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8666145884190997\n",
      "\n",
      "\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 918.6291\n",
      "Function value obtained: -0.8666\n",
      "Current minimum: -0.8666\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 9, 'window_size': 4, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.16410871766341692, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 9 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_108 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_108 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_108 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_108 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0226 - acc: 0.9946 - val_loss: 0.0064 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.968323 - Log-Loss: 3.095440 - Hamming-Loss: 0.003683 - Subset-Accuracy: 0.754647 - F1-Score: 0.813744\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 112s 142ms/step - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980801 - Log-Loss: 2.497474 - Hamming-Loss: 0.002105 - Subset-Accuracy: 0.879252 - F1-Score: 0.898650\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 112s 142ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984756 - Log-Loss: 2.072491 - Hamming-Loss: 0.001819 - Subset-Accuracy: 0.901197 - F1-Score: 0.913135\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 112s 142ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986748 - Log-Loss: 1.808071 - Hamming-Loss: 0.001758 - Subset-Accuracy: 0.901736 - F1-Score: 0.915902\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 111s 141ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987762 - Log-Loss: 1.607764 - Hamming-Loss: 0.001770 - Subset-Accuracy: 0.894663 - F1-Score: 0.914841\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8690222652468539\n",
      "\n",
      "\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 765.9548\n",
      "Function value obtained: -0.8690\n",
      "Current minimum: -0.8690\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 10, 'window_size': 5, 'embed_size': 3, 'latent_dim': 4, 'dropout_rate': 0.10844386503943218, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 10 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_109 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_109 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_109 (Bidirecti (None, None, 512)         589824    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_109 (Spati (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, None, 300)         153900    \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,122,441\n",
      "Trainable params: 2,122,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 181s 229ms/step - loss: 0.0221 - acc: 0.9949 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.961876 - Log-Loss: 3.269592 - Hamming-Loss: 0.005772 - Subset-Accuracy: 0.745507 - F1-Score: 0.740564\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 142s 180ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.972538 - Log-Loss: 2.672842 - Hamming-Loss: 0.004188 - Subset-Accuracy: 0.805545 - F1-Score: 0.807339\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 141s 179ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980736 - Log-Loss: 2.256897 - Hamming-Loss: 0.002513 - Subset-Accuracy: 0.873191 - F1-Score: 0.881884\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 140s 177ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984186 - Log-Loss: 1.941607 - Hamming-Loss: 0.001979 - Subset-Accuracy: 0.894710 - F1-Score: 0.906695\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 141s 179ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985816 - Log-Loss: 1.682370 - Hamming-Loss: 0.001747 - Subset-Accuracy: 0.904801 - F1-Score: 0.917214\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8532182882078746\n",
      "\n",
      "\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 916.3865\n",
      "Function value obtained: -0.8532\n",
      "Current minimum: -0.8690\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 8, 'window_size': 3, 'embed_size': 4, 'latent_dim': 3, 'dropout_rate': 0.10481713956672548, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 8 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_110 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_110 (Embedding)    (None, None, 40)          1799360   \n",
      "_________________________________________________________________\n",
      "bidirectional_110 (Bidirecti (None, None, 384)         359424    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_110 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,303,481\n",
      "Trainable params: 2,303,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 140s 177ms/step - loss: 0.0221 - acc: 0.9950 - val_loss: 0.0064 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974617 - Log-Loss: 3.076037 - Hamming-Loss: 0.003141 - Subset-Accuracy: 0.855190 - F1-Score: 0.853485\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 104s 132ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982180 - Log-Loss: 2.400815 - Hamming-Loss: 0.001927 - Subset-Accuracy: 0.908495 - F1-Score: 0.909443\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 106s 134ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985458 - Log-Loss: 2.009051 - Hamming-Loss: 0.001812 - Subset-Accuracy: 0.909481 - F1-Score: 0.914739\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 106s 134ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986892 - Log-Loss: 1.782964 - Hamming-Loss: 0.001770 - Subset-Accuracy: 0.900258 - F1-Score: 0.916792\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 106s 134ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987730 - Log-Loss: 1.523631 - Hamming-Loss: 0.001661 - Subset-Accuracy: 0.910235 - F1-Score: 0.921151\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8631247849805868\n",
      "\n",
      "\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 735.5680\n",
      "Function value obtained: -0.8631\n",
      "Current minimum: -0.8690\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.5, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_111 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_111 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_111 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_111 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 162s 205ms/step - loss: 0.0206 - acc: 0.9952 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975613 - Log-Loss: 3.108691 - Hamming-Loss: 0.002009 - Subset-Accuracy: 0.894235 - F1-Score: 0.904215\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981870 - Log-Loss: 2.475042 - Hamming-Loss: 0.001705 - Subset-Accuracy: 0.917520 - F1-Score: 0.919607\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985442 - Log-Loss: 2.015417 - Hamming-Loss: 0.001568 - Subset-Accuracy: 0.927186 - F1-Score: 0.926390\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987326 - Log-Loss: 1.772388 - Hamming-Loss: 0.001452 - Subset-Accuracy: 0.928204 - F1-Score: 0.931596\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988798 - Log-Loss: 1.543107 - Hamming-Loss: 0.001454 - Subset-Accuracy: 0.928898 - F1-Score: 0.931517\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989735 - Log-Loss: 1.314846 - Hamming-Loss: 0.001414 - Subset-Accuracy: 0.931869 - F1-Score: 0.933461\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8732003635146123\n",
      "\n",
      "\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 963.0317\n",
      "Function value obtained: -0.8732\n",
      "Current minimum: -0.8732\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.06067263531925067, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_112 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_112 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_112 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_112 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 126s 159ms/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.978757 - Log-Loss: 2.764577 - Hamming-Loss: 0.001456 - Subset-Accuracy: 0.936107 - F1-Score: 0.931079\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0092 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.984490 - Log-Loss: 2.149488 - Hamming-Loss: 0.001425 - Subset-Accuracy: 0.937829 - F1-Score: 0.932920\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 86s 108ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987150 - Log-Loss: 1.767632 - Hamming-Loss: 0.001329 - Subset-Accuracy: 0.940000 - F1-Score: 0.937486\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988139 - Log-Loss: 1.540690 - Hamming-Loss: 0.001316 - Subset-Accuracy: 0.938127 - F1-Score: 0.938007\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988582 - Log-Loss: 1.367575 - Hamming-Loss: 0.001329 - Subset-Accuracy: 0.935182 - F1-Score: 0.937360\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988900 - Log-Loss: 1.248373 - Hamming-Loss: 0.001351 - Subset-Accuracy: 0.931748 - F1-Score: 0.936287\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8785485183589449\n",
      "\n",
      "\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 742.4937\n",
      "Function value obtained: -0.8785\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.48105107120337953, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_113 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_113 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_113 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_113 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0229 - acc: 0.9942 - val_loss: 0.0066 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.971591 - Log-Loss: 3.139089 - Hamming-Loss: 0.002554 - Subset-Accuracy: 0.851060 - F1-Score: 0.875618\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981315 - Log-Loss: 2.438004 - Hamming-Loss: 0.001962 - Subset-Accuracy: 0.911170 - F1-Score: 0.908004\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984761 - Log-Loss: 2.088446 - Hamming-Loss: 0.001549 - Subset-Accuracy: 0.922247 - F1-Score: 0.926934\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986632 - Log-Loss: 1.851549 - Hamming-Loss: 0.001467 - Subset-Accuracy: 0.921524 - F1-Score: 0.930395\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987967 - Log-Loss: 1.635406 - Hamming-Loss: 0.001482 - Subset-Accuracy: 0.918050 - F1-Score: 0.929600\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8603378999854773\n",
      "\n",
      "\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 639.5731\n",
      "Function value obtained: -0.8603\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_114 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_114 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_114 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_114 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 161s 203ms/step - loss: 0.0190 - acc: 0.9958 - val_loss: 0.0066 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975498 - Log-Loss: 3.052525 - Hamming-Loss: 0.002222 - Subset-Accuracy: 0.886921 - F1-Score: 0.893395\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981728 - Log-Loss: 2.414924 - Hamming-Loss: 0.001963 - Subset-Accuracy: 0.910260 - F1-Score: 0.907725\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984522 - Log-Loss: 2.074238 - Hamming-Loss: 0.001805 - Subset-Accuracy: 0.909553 - F1-Score: 0.914554\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985967 - Log-Loss: 1.910874 - Hamming-Loss: 0.001696 - Subset-Accuracy: 0.903448 - F1-Score: 0.918856\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986360 - Log-Loss: 1.759088 - Hamming-Loss: 0.001879 - Subset-Accuracy: 0.882787 - F1-Score: 0.909195\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986808 - Log-Loss: 1.618263 - Hamming-Loss: 0.002168 - Subset-Accuracy: 0.856725 - F1-Score: 0.893746\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8754661432777232\n",
      "\n",
      "\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 961.8308\n",
      "Function value obtained: -0.8755\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_115 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_115 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_115 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_115 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 162s 205ms/step - loss: 0.0187 - acc: 0.9958 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975077 - Log-Loss: 2.978539 - Hamming-Loss: 0.001959 - Subset-Accuracy: 0.877861 - F1-Score: 0.903884\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981883 - Log-Loss: 2.277428 - Hamming-Loss: 0.001443 - Subset-Accuracy: 0.933302 - F1-Score: 0.931768\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985321 - Log-Loss: 1.933015 - Hamming-Loss: 0.001335 - Subset-Accuracy: 0.938612 - F1-Score: 0.937040\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986858 - Log-Loss: 1.718848 - Hamming-Loss: 0.001286 - Subset-Accuracy: 0.934982 - F1-Score: 0.939140\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987789 - Log-Loss: 1.529659 - Hamming-Loss: 0.001260 - Subset-Accuracy: 0.935908 - F1-Score: 0.940449\n",
      "Epoch 6/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988356 - Log-Loss: 1.393181 - Hamming-Loss: 0.001255 - Subset-Accuracy: 0.936304 - F1-Score: 0.940823\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8765116507718023\n",
      "\n",
      "\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 967.9207\n",
      "Function value obtained: -0.8765\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 14, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.044437795254285324, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 14 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_116 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_116 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_116 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_116 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.954643 - Log-Loss: 3.150433 - Hamming-Loss: 0.009006 - Subset-Accuracy: 0.697022 - F1-Score: 0.636691\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 215s 272ms/step - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.965130 - Log-Loss: 2.725232 - Hamming-Loss: 0.006607 - Subset-Accuracy: 0.735235 - F1-Score: 0.708383\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 216s 274ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.976245 - Log-Loss: 2.350887 - Hamming-Loss: 0.003812 - Subset-Accuracy: 0.805316 - F1-Score: 0.820413\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 218s 276ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981676 - Log-Loss: 2.028118 - Hamming-Loss: 0.002673 - Subset-Accuracy: 0.844402 - F1-Score: 0.871304\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 217s 274ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.983146 - Log-Loss: 1.858198 - Hamming-Loss: 0.002218 - Subset-Accuracy: 0.860336 - F1-Score: 0.892770\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8695439420630261\n",
      "\n",
      "\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 1303.7929\n",
      "Function value obtained: -0.8695\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.030118349221440473, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_117 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_117 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_117 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_117 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 164s 208ms/step - loss: 0.0194 - acc: 0.9956 - val_loss: 0.0066 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974512 - Log-Loss: 3.093812 - Hamming-Loss: 0.001975 - Subset-Accuracy: 0.892482 - F1-Score: 0.904739\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982352 - Log-Loss: 2.349235 - Hamming-Loss: 0.001336 - Subset-Accuracy: 0.939278 - F1-Score: 0.936894\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985476 - Log-Loss: 1.991499 - Hamming-Loss: 0.001255 - Subset-Accuracy: 0.940219 - F1-Score: 0.940722\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986956 - Log-Loss: 1.778856 - Hamming-Loss: 0.001271 - Subset-Accuracy: 0.934608 - F1-Score: 0.939918\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987337 - Log-Loss: 1.625098 - Hamming-Loss: 0.001382 - Subset-Accuracy: 0.924374 - F1-Score: 0.934320\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.862801835960886\n",
      "\n",
      "\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 832.1942\n",
      "Function value obtained: -0.8628\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.07437277778600178, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_118 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_118 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_118 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_118 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "790/790 [==============================] - 190s 240ms/step - loss: 0.0233 - acc: 0.9947 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.938950 - Log-Loss: 3.248653 - Hamming-Loss: 0.006248 - Subset-Accuracy: 0.645860 - F1-Score: 0.692587\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 150s 189ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.972298 - Log-Loss: 2.572432 - Hamming-Loss: 0.002993 - Subset-Accuracy: 0.830304 - F1-Score: 0.856679\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 149s 189ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.979798 - Log-Loss: 2.160248 - Hamming-Loss: 0.002219 - Subset-Accuracy: 0.877373 - F1-Score: 0.894737\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984176 - Log-Loss: 1.845860 - Hamming-Loss: 0.001750 - Subset-Accuracy: 0.903755 - F1-Score: 0.916659\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985735 - Log-Loss: 1.600775 - Hamming-Loss: 0.001744 - Subset-Accuracy: 0.901973 - F1-Score: 0.917211\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8656702071418273\n",
      "\n",
      "\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 970.5338\n",
      "Function value obtained: -0.8657\n",
      "Current minimum: -0.8785\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_119 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_119 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_119 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_119 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 162s 205ms/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.976331 - Log-Loss: 2.995676 - Hamming-Loss: 0.001563 - Subset-Accuracy: 0.912527 - F1-Score: 0.924463\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982389 - Log-Loss: 2.351753 - Hamming-Loss: 0.001533 - Subset-Accuracy: 0.919134 - F1-Score: 0.926788\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985955 - Log-Loss: 1.986679 - Hamming-Loss: 0.001406 - Subset-Accuracy: 0.930965 - F1-Score: 0.933520\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987937 - Log-Loss: 1.734079 - Hamming-Loss: 0.001321 - Subset-Accuracy: 0.935105 - F1-Score: 0.937602\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988839 - Log-Loss: 1.533191 - Hamming-Loss: 0.001323 - Subset-Accuracy: 0.936605 - F1-Score: 0.937655\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989321 - Log-Loss: 1.367876 - Hamming-Loss: 0.001347 - Subset-Accuracy: 0.934627 - F1-Score: 0.936520\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.880604922217406\n",
      "\n",
      "\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 967.0453\n",
      "Function value obtained: -0.8806\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.017770953066644782, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_120 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_120 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_120 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_120 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 165s 209ms/step - loss: 0.0182 - acc: 0.9961 - val_loss: 0.0065 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.974268 - Log-Loss: 2.974268 - Hamming-Loss: 0.001688 - Subset-Accuracy: 0.902630 - F1-Score: 0.918142\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 121s 153ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982126 - Log-Loss: 2.269004 - Hamming-Loss: 0.001519 - Subset-Accuracy: 0.929932 - F1-Score: 0.928475\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985132 - Log-Loss: 1.882571 - Hamming-Loss: 0.001356 - Subset-Accuracy: 0.936919 - F1-Score: 0.936229\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986710 - Log-Loss: 1.666127 - Hamming-Loss: 0.001332 - Subset-Accuracy: 0.935743 - F1-Score: 0.937219\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8459940201692597\n",
      "\n",
      "\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 689.7896\n",
      "Function value obtained: -0.8460\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_121 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_121 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_121 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_121 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 191s 242ms/step - loss: 0.0229 - acc: 0.9947 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.952018 - Log-Loss: 3.242858 - Hamming-Loss: 0.007348 - Subset-Accuracy: 0.695167 - F1-Score: 0.684747\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 146s 185ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.970572 - Log-Loss: 2.718874 - Hamming-Loss: 0.003974 - Subset-Accuracy: 0.783077 - F1-Score: 0.815886\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 146s 185ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.977138 - Log-Loss: 2.328686 - Hamming-Loss: 0.003143 - Subset-Accuracy: 0.812583 - F1-Score: 0.850438\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981238 - Log-Loss: 2.023888 - Hamming-Loss: 0.002419 - Subset-Accuracy: 0.849541 - F1-Score: 0.883712\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.982675 - Log-Loss: 1.805621 - Hamming-Loss: 0.002382 - Subset-Accuracy: 0.842827 - F1-Score: 0.885355\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8589623340079972\n",
      "\n",
      "\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 957.1518\n",
      "Function value obtained: -0.8590\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4967510553263506, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_122 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_122 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_122 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_122 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 269s 340ms/step - loss: 0.0238 - acc: 0.9944 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.956335 - Log-Loss: 3.321228 - Hamming-Loss: 0.007198 - Subset-Accuracy: 0.718617 - F1-Score: 0.688969\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 226s 287ms/step - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.969819 - Log-Loss: 2.812233 - Hamming-Loss: 0.004799 - Subset-Accuracy: 0.802102 - F1-Score: 0.785341\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978216 - Log-Loss: 2.404340 - Hamming-Loss: 0.002727 - Subset-Accuracy: 0.851748 - F1-Score: 0.871374\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983385 - Log-Loss: 1.994815 - Hamming-Loss: 0.001843 - Subset-Accuracy: 0.897310 - F1-Score: 0.912582\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985501 - Log-Loss: 1.722616 - Hamming-Loss: 0.001776 - Subset-Accuracy: 0.901168 - F1-Score: 0.915821\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8629919746263637\n",
      "\n",
      "\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1364.9678\n",
      "Function value obtained: -0.8630\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.4770935522032088, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_123 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_123 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_123 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_123 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 192s 243ms/step - loss: 0.0268 - acc: 0.9937 - val_loss: 0.0074 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.951608 - Log-Loss: 3.548652 - Hamming-Loss: 0.006668 - Subset-Accuracy: 0.714296 - F1-Score: 0.702128\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.970207 - Log-Loss: 2.835705 - Hamming-Loss: 0.004322 - Subset-Accuracy: 0.812408 - F1-Score: 0.803045\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977938 - Log-Loss: 2.438766 - Hamming-Loss: 0.002857 - Subset-Accuracy: 0.860298 - F1-Score: 0.865901\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981263 - Log-Loss: 2.093680 - Hamming-Loss: 0.002020 - Subset-Accuracy: 0.887051 - F1-Score: 0.903365\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985033 - Log-Loss: 1.832019 - Hamming-Loss: 0.001708 - Subset-Accuracy: 0.903609 - F1-Score: 0.918419\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986588 - Log-Loss: 1.608084 - Hamming-Loss: 0.001759 - Subset-Accuracy: 0.900281 - F1-Score: 0.916018\n",
      "Epoch 7/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adiitional val metrics: - ROC-AUC: 0.988616 - Log-Loss: 1.429473 - Hamming-Loss: 0.001666 - Subset-Accuracy: 0.912480 - F1-Score: 0.921107\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8658273897850749\n",
      "\n",
      "\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 1302.8385\n",
      "Function value obtained: -0.8658\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.5, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_124 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_124 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_124 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_124 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 132s 167ms/step - loss: 0.0223 - acc: 0.9949 - val_loss: 0.0065 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.973604 - Log-Loss: 3.164493 - Hamming-Loss: 0.001969 - Subset-Accuracy: 0.889984 - F1-Score: 0.904639\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982489 - Log-Loss: 2.370183 - Hamming-Loss: 0.001402 - Subset-Accuracy: 0.938111 - F1-Score: 0.933965\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985984 - Log-Loss: 2.019008 - Hamming-Loss: 0.001351 - Subset-Accuracy: 0.935001 - F1-Score: 0.936135\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988090 - Log-Loss: 1.723088 - Hamming-Loss: 0.001339 - Subset-Accuracy: 0.934208 - F1-Score: 0.936752\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988975 - Log-Loss: 1.538055 - Hamming-Loss: 0.001409 - Subset-Accuracy: 0.928264 - F1-Score: 0.933365\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 88s 111ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.990200 - Log-Loss: 1.361781 - Hamming-Loss: 0.001353 - Subset-Accuracy: 0.931298 - F1-Score: 0.935954\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8722041674632001\n",
      "\n",
      "\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 766.6600\n",
      "Function value obtained: -0.8722\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.462018956431319, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_125 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_125 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_125 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_125 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 195s 246ms/step - loss: 0.0263 - acc: 0.9937 - val_loss: 0.0069 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.944147 - Log-Loss: 3.518683 - Hamming-Loss: 0.007448 - Subset-Accuracy: 0.712438 - F1-Score: 0.683943\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0137 - acc: 0.9968 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.963059 - Log-Loss: 2.879150 - Hamming-Loss: 0.004606 - Subset-Accuracy: 0.787661 - F1-Score: 0.791591\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 151s 191ms/step - loss: 0.0110 - acc: 0.9973 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.975375 - Log-Loss: 2.492613 - Hamming-Loss: 0.003055 - Subset-Accuracy: 0.841451 - F1-Score: 0.855548\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 151s 191ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981718 - Log-Loss: 2.159315 - Hamming-Loss: 0.002188 - Subset-Accuracy: 0.873071 - F1-Score: 0.895066\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985755 - Log-Loss: 1.776861 - Hamming-Loss: 0.001819 - Subset-Accuracy: 0.895700 - F1-Score: 0.912991\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 149s 189ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987250 - Log-Loss: 1.529948 - Hamming-Loss: 0.001712 - Subset-Accuracy: 0.905255 - F1-Score: 0.918439\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8520395848419019\n",
      "\n",
      "\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 1147.6605\n",
      "Function value obtained: -0.8520\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.010765752808737874, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_126 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_126 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_126 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_126 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "790/790 [==============================] - 165s 209ms/step - loss: 0.0196 - acc: 0.9958 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.972676 - Log-Loss: 3.223338 - Hamming-Loss: 0.002044 - Subset-Accuracy: 0.897161 - F1-Score: 0.901195\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980203 - Log-Loss: 2.476182 - Hamming-Loss: 0.001719 - Subset-Accuracy: 0.929241 - F1-Score: 0.919089\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983036 - Log-Loss: 2.122668 - Hamming-Loss: 0.001619 - Subset-Accuracy: 0.932068 - F1-Score: 0.924320\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985184 - Log-Loss: 1.864603 - Hamming-Loss: 0.001553 - Subset-Accuracy: 0.927430 - F1-Score: 0.926945\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986391 - Log-Loss: 1.629561 - Hamming-Loss: 0.001595 - Subset-Accuracy: 0.914445 - F1-Score: 0.924185\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8540709706728585\n",
      "\n",
      "\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 843.3843\n",
      "Function value obtained: -0.8541\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.4883129861421911, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_127 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_127 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_127 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_127 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 132s 167ms/step - loss: 0.0215 - acc: 0.9955 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.976591 - Log-Loss: 3.218094 - Hamming-Loss: 0.001575 - Subset-Accuracy: 0.917717 - F1-Score: 0.924472\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982173 - Log-Loss: 2.496087 - Hamming-Loss: 0.001466 - Subset-Accuracy: 0.925284 - F1-Score: 0.930329\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985989 - Log-Loss: 2.132585 - Hamming-Loss: 0.001396 - Subset-Accuracy: 0.929979 - F1-Score: 0.933873\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987955 - Log-Loss: 1.835588 - Hamming-Loss: 0.001386 - Subset-Accuracy: 0.927877 - F1-Score: 0.934192\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 90s 113ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989341 - Log-Loss: 1.590809 - Hamming-Loss: 0.001384 - Subset-Accuracy: 0.928943 - F1-Score: 0.934516\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.990022 - Log-Loss: 1.432980 - Hamming-Loss: 0.001441 - Subset-Accuracy: 0.925050 - F1-Score: 0.931822\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8753095827776719\n",
      "\n",
      "\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 777.2892\n",
      "Function value obtained: -0.8753\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.4974338472683289, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_128 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_128 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_128 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_128 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 136s 172ms/step - loss: 0.0220 - acc: 0.9945 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974450 - Log-Loss: 3.144375 - Hamming-Loss: 0.002638 - Subset-Accuracy: 0.856861 - F1-Score: 0.873274\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981355 - Log-Loss: 2.454500 - Hamming-Loss: 0.001684 - Subset-Accuracy: 0.909389 - F1-Score: 0.919743\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984724 - Log-Loss: 2.121067 - Hamming-Loss: 0.001466 - Subset-Accuracy: 0.923800 - F1-Score: 0.930467\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987119 - Log-Loss: 1.776989 - Hamming-Loss: 0.001351 - Subset-Accuracy: 0.931736 - F1-Score: 0.936109\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988454 - Log-Loss: 1.689441 - Hamming-Loss: 0.001497 - Subset-Accuracy: 0.919971 - F1-Score: 0.928945\n",
      "predicting test data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8595311299000769\n",
      "\n",
      "\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 680.9285\n",
      "Function value obtained: -0.8595\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.5, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_129 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_129 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_129 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_129 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 136s 173ms/step - loss: 0.0217 - acc: 0.9951 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.972712 - Log-Loss: 3.161498 - Hamming-Loss: 0.002808 - Subset-Accuracy: 0.806746 - F1-Score: 0.858269\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980893 - Log-Loss: 2.531830 - Hamming-Loss: 0.001750 - Subset-Accuracy: 0.895097 - F1-Score: 0.915406\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984728 - Log-Loss: 2.053810 - Hamming-Loss: 0.001434 - Subset-Accuracy: 0.924263 - F1-Score: 0.931772\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986924 - Log-Loss: 1.770783 - Hamming-Loss: 0.001417 - Subset-Accuracy: 0.924945 - F1-Score: 0.932633\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988352 - Log-Loss: 1.535410 - Hamming-Loss: 0.001336 - Subset-Accuracy: 0.927484 - F1-Score: 0.936428\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8620905889730356\n",
      "\n",
      "\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 674.9999\n",
      "Function value obtained: -0.8621\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4114153172892308, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_130 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_130 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_130 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_130 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 275s 348ms/step - loss: 0.0237 - acc: 0.9944 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.944013 - Log-Loss: 3.459244 - Hamming-Loss: 0.007275 - Subset-Accuracy: 0.627667 - F1-Score: 0.654247\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.967387 - Log-Loss: 2.838025 - Hamming-Loss: 0.004314 - Subset-Accuracy: 0.779121 - F1-Score: 0.795503\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0042 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977039 - Log-Loss: 2.434031 - Hamming-Loss: 0.003030 - Subset-Accuracy: 0.826072 - F1-Score: 0.853967\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982972 - Log-Loss: 1.998758 - Hamming-Loss: 0.002090 - Subset-Accuracy: 0.880276 - F1-Score: 0.899911\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985932 - Log-Loss: 1.689237 - Hamming-Loss: 0.001719 - Subset-Accuracy: 0.904278 - F1-Score: 0.918100\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8604272439888878\n",
      "\n",
      "\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 1380.6411\n",
      "Function value obtained: -0.8604\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.4922708408267803, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_131 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_131 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_131 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_131 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 274s 347ms/step - loss: 0.0260 - acc: 0.9937 - val_loss: 0.0076 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.932574 - Log-Loss: 3.670648 - Hamming-Loss: 0.008952 - Subset-Accuracy: 0.625080 - F1-Score: 0.610707\n",
      "Epoch 2/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0140 - acc: 0.9967 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.971166 - Log-Loss: 2.841194 - Hamming-Loss: 0.004777 - Subset-Accuracy: 0.822445 - F1-Score: 0.791380\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977614 - Log-Loss: 2.372977 - Hamming-Loss: 0.002952 - Subset-Accuracy: 0.859990 - F1-Score: 0.862702\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982284 - Log-Loss: 1.946114 - Hamming-Loss: 0.002236 - Subset-Accuracy: 0.879928 - F1-Score: 0.893824\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984763 - Log-Loss: 1.721794 - Hamming-Loss: 0.001918 - Subset-Accuracy: 0.893347 - F1-Score: 0.908411\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986211 - Log-Loss: 1.487843 - Hamming-Loss: 0.001822 - Subset-Accuracy: 0.892216 - F1-Score: 0.912362\n",
      "Epoch 7/21\n",
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987447 - Log-Loss: 1.350006 - Hamming-Loss: 0.001956 - Subset-Accuracy: 0.891100 - F1-Score: 0.906660\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8669519733713742\n",
      "\n",
      "\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 1854.8478\n",
      "Function value obtained: -0.8670\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.05261203073294375, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_132 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_132 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_132 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_132 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 134s 169ms/step - loss: 0.0209 - acc: 0.9952 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974325 - Log-Loss: 3.165286 - Hamming-Loss: 0.002456 - Subset-Accuracy: 0.867843 - F1-Score: 0.882775\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981339 - Log-Loss: 2.495446 - Hamming-Loss: 0.001974 - Subset-Accuracy: 0.911747 - F1-Score: 0.907469\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 88s 111ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984913 - Log-Loss: 2.068280 - Hamming-Loss: 0.001510 - Subset-Accuracy: 0.930632 - F1-Score: 0.928828\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986492 - Log-Loss: 1.868944 - Hamming-Loss: 0.001470 - Subset-Accuracy: 0.924843 - F1-Score: 0.930304\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987533 - Log-Loss: 1.665412 - Hamming-Loss: 0.001523 - Subset-Accuracy: 0.917977 - F1-Score: 0.927576\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8540028231498286\n",
      "\n",
      "\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 665.9963\n",
      "Function value obtained: -0.8540\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.5, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_133 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_133 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_133 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_133 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 273s 346ms/step - loss: 0.0246 - acc: 0.9940 - val_loss: 0.0067 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.955242 - Log-Loss: 3.413261 - Hamming-Loss: 0.006059 - Subset-Accuracy: 0.675080 - F1-Score: 0.708513\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.974541 - Log-Loss: 2.797834 - Hamming-Loss: 0.003175 - Subset-Accuracy: 0.819240 - F1-Score: 0.847435\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 228s 289ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980869 - Log-Loss: 2.350754 - Hamming-Loss: 0.002137 - Subset-Accuracy: 0.874256 - F1-Score: 0.897884\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983614 - Log-Loss: 2.077949 - Hamming-Loss: 0.001960 - Subset-Accuracy: 0.883000 - F1-Score: 0.906015\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 225s 285ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986016 - Log-Loss: 1.799981 - Hamming-Loss: 0.001705 - Subset-Accuracy: 0.898233 - F1-Score: 0.918187\n",
      "predicting test data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8618127786032689\n",
      "\n",
      "\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 1371.5595\n",
      "Function value obtained: -0.8618\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_134 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_134 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_134 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_134 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 195s 247ms/step - loss: 0.0234 - acc: 0.9946 - val_loss: 0.0064 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.957518 - Log-Loss: 3.147562 - Hamming-Loss: 0.004847 - Subset-Accuracy: 0.735125 - F1-Score: 0.766655\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.976145 - Log-Loss: 2.556290 - Hamming-Loss: 0.002774 - Subset-Accuracy: 0.840243 - F1-Score: 0.867263\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980986 - Log-Loss: 2.208115 - Hamming-Loss: 0.002123 - Subset-Accuracy: 0.877962 - F1-Score: 0.898800\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984516 - Log-Loss: 1.870840 - Hamming-Loss: 0.001775 - Subset-Accuracy: 0.902706 - F1-Score: 0.915587\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985412 - Log-Loss: 1.705521 - Hamming-Loss: 0.001840 - Subset-Accuracy: 0.896571 - F1-Score: 0.912077\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8645199584508088\n",
      "\n",
      "\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 968.9101\n",
      "Function value obtained: -0.8645\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.4922399891052413, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_135 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_135 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_135 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_135 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 135s 171ms/step - loss: 0.0225 - acc: 0.9946 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975269 - Log-Loss: 3.070815 - Hamming-Loss: 0.002068 - Subset-Accuracy: 0.896698 - F1-Score: 0.902048\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981187 - Log-Loss: 2.406033 - Hamming-Loss: 0.001535 - Subset-Accuracy: 0.930997 - F1-Score: 0.927982\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984429 - Log-Loss: 2.083929 - Hamming-Loss: 0.001442 - Subset-Accuracy: 0.927640 - F1-Score: 0.931739\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987000 - Log-Loss: 1.793938 - Hamming-Loss: 0.001435 - Subset-Accuracy: 0.928600 - F1-Score: 0.932161\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988341 - Log-Loss: 1.575781 - Hamming-Loss: 0.001433 - Subset-Accuracy: 0.930404 - F1-Score: 0.932422\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8592721641502129\n",
      "\n",
      "\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 671.9114\n",
      "Function value obtained: -0.8593\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.028723320332029796, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_136 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_136 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_136 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_136 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "790/790 [==============================] - 171s 216ms/step - loss: 0.0192 - acc: 0.9956 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975094 - Log-Loss: 3.017358 - Hamming-Loss: 0.001316 - Subset-Accuracy: 0.937978 - F1-Score: 0.936954\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981523 - Log-Loss: 2.370786 - Hamming-Loss: 0.001264 - Subset-Accuracy: 0.937677 - F1-Score: 0.939585\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 122s 154ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984987 - Log-Loss: 2.010185 - Hamming-Loss: 0.001170 - Subset-Accuracy: 0.944407 - F1-Score: 0.944662\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 123s 155ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986605 - Log-Loss: 1.758700 - Hamming-Loss: 0.001163 - Subset-Accuracy: 0.945681 - F1-Score: 0.945203\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987641 - Log-Loss: 1.577381 - Hamming-Loss: 0.001249 - Subset-Accuracy: 0.936389 - F1-Score: 0.941186\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988512 - Log-Loss: 1.398189 - Hamming-Loss: 0.001294 - Subset-Accuracy: 0.931866 - F1-Score: 0.938660\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8733882695104217\n",
      "\n",
      "\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 989.6249\n",
      "Function value obtained: -0.8734\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4704326018066529, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_137 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_137 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_137 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_137 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 279s 353ms/step - loss: 0.0244 - acc: 0.9944 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.958803 - Log-Loss: 3.457107 - Hamming-Loss: 0.006213 - Subset-Accuracy: 0.725620 - F1-Score: 0.721318\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0127 - acc: 0.9970 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.971589 - Log-Loss: 2.924957 - Hamming-Loss: 0.003861 - Subset-Accuracy: 0.805874 - F1-Score: 0.819609\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 228s 289ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980211 - Log-Loss: 2.490760 - Hamming-Loss: 0.002322 - Subset-Accuracy: 0.862954 - F1-Score: 0.888283\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 229s 289ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983533 - Log-Loss: 2.077458 - Hamming-Loss: 0.001953 - Subset-Accuracy: 0.882378 - F1-Score: 0.906639\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985340 - Log-Loss: 1.833822 - Hamming-Loss: 0.001724 - Subset-Accuracy: 0.900804 - F1-Score: 0.917557\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8599641802604191\n",
      "\n",
      "\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 1387.7115\n",
      "Function value obtained: -0.8600\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_138 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_138 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_138 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_138 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 175s 222ms/step - loss: 0.0189 - acc: 0.9956 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.978207 - Log-Loss: 2.900317 - Hamming-Loss: 0.001307 - Subset-Accuracy: 0.940482 - F1-Score: 0.937846\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0093 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983096 - Log-Loss: 2.237080 - Hamming-Loss: 0.001422 - Subset-Accuracy: 0.930112 - F1-Score: 0.932344\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985608 - Log-Loss: 1.896131 - Hamming-Loss: 0.001332 - Subset-Accuracy: 0.932211 - F1-Score: 0.936740\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987258 - Log-Loss: 1.659036 - Hamming-Loss: 0.001335 - Subset-Accuracy: 0.930933 - F1-Score: 0.936544\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8485004108463434\n",
      "\n",
      "\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 720.5403\n",
      "Function value obtained: -0.8485\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.4987294707587122, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_139 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_139 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_139 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_139 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 173s 219ms/step - loss: 0.0218 - acc: 0.9948 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.966462 - Log-Loss: 3.552477 - Hamming-Loss: 0.002876 - Subset-Accuracy: 0.805814 - F1-Score: 0.854462\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981429 - Log-Loss: 2.697523 - Hamming-Loss: 0.001719 - Subset-Accuracy: 0.924675 - F1-Score: 0.919320\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985332 - Log-Loss: 2.208895 - Hamming-Loss: 0.001311 - Subset-Accuracy: 0.940393 - F1-Score: 0.938455\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987112 - Log-Loss: 1.891769 - Hamming-Loss: 0.001228 - Subset-Accuracy: 0.943564 - F1-Score: 0.942231\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0042 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988384 - Log-Loss: 1.599236 - Hamming-Loss: 0.001261 - Subset-Accuracy: 0.941110 - F1-Score: 0.940638\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8474406991260924\n",
      "\n",
      "\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 862.8043\n",
      "Function value obtained: -0.8474\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_140 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_140 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_140 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_140 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 202s 256ms/step - loss: 0.0234 - acc: 0.9946 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.964282 - Log-Loss: 3.130979 - Hamming-Loss: 0.003935 - Subset-Accuracy: 0.777748 - F1-Score: 0.811020\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.976408 - Log-Loss: 2.587352 - Hamming-Loss: 0.002812 - Subset-Accuracy: 0.844272 - F1-Score: 0.866480\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 151s 191ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982142 - Log-Loss: 2.168074 - Hamming-Loss: 0.002104 - Subset-Accuracy: 0.887140 - F1-Score: 0.900095\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984697 - Log-Loss: 1.878175 - Hamming-Loss: 0.001803 - Subset-Accuracy: 0.896949 - F1-Score: 0.914236\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 151s 191ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985117 - Log-Loss: 1.768097 - Hamming-Loss: 0.002414 - Subset-Accuracy: 0.840430 - F1-Score: 0.883246\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8660016706795735\n",
      "\n",
      "\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 999.8350\n",
      "Function value obtained: -0.8660\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.011405306900188707, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_141 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_141 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_141 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_141 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 286s 362ms/step - loss: 0.0219 - acc: 0.9947 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.950041 - Log-Loss: 3.197771 - Hamming-Loss: 0.006207 - Subset-Accuracy: 0.725119 - F1-Score: 0.725878\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 228s 289ms/step - loss: 0.0112 - acc: 0.9973 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.968036 - Log-Loss: 2.683336 - Hamming-Loss: 0.004211 - Subset-Accuracy: 0.797924 - F1-Score: 0.808580\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980471 - Log-Loss: 2.262703 - Hamming-Loss: 0.002679 - Subset-Accuracy: 0.864584 - F1-Score: 0.876080\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 226s 287ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984116 - Log-Loss: 1.919370 - Hamming-Loss: 0.001918 - Subset-Accuracy: 0.898128 - F1-Score: 0.909635\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985588 - Log-Loss: 1.676188 - Hamming-Loss: 0.001771 - Subset-Accuracy: 0.905974 - F1-Score: 0.916262\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8686578973395312\n",
      "\n",
      "\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 1397.6728\n",
      "Function value obtained: -0.8687\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_142 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_142 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_142 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_142 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 210s 266ms/step - loss: 0.0235 - acc: 0.9945 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.964405 - Log-Loss: 3.232853 - Hamming-Loss: 0.004281 - Subset-Accuracy: 0.777891 - F1-Score: 0.797736\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 155s 196ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.976256 - Log-Loss: 2.643426 - Hamming-Loss: 0.003080 - Subset-Accuracy: 0.840094 - F1-Score: 0.856166\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 154s 195ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980763 - Log-Loss: 2.253350 - Hamming-Loss: 0.002424 - Subset-Accuracy: 0.868379 - F1-Score: 0.885383\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 155s 196ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982628 - Log-Loss: 1.994156 - Hamming-Loss: 0.002222 - Subset-Accuracy: 0.864311 - F1-Score: 0.893177\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 154s 195ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984692 - Log-Loss: 1.742969 - Hamming-Loss: 0.002229 - Subset-Accuracy: 0.857318 - F1-Score: 0.891522\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8637968229064523\n",
      "\n",
      "\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 1024.1944\n",
      "Function value obtained: -0.8638\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_143 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_143 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_143 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_143 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 143s 181ms/step - loss: 0.0198 - acc: 0.9956 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.971950 - Log-Loss: 2.965322 - Hamming-Loss: 0.002164 - Subset-Accuracy: 0.871159 - F1-Score: 0.894529\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 93s 117ms/step - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981448 - Log-Loss: 2.364251 - Hamming-Loss: 0.001685 - Subset-Accuracy: 0.904779 - F1-Score: 0.918944\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 91s 116ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985217 - Log-Loss: 2.023394 - Hamming-Loss: 0.001465 - Subset-Accuracy: 0.916515 - F1-Score: 0.929712\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986913 - Log-Loss: 1.786621 - Hamming-Loss: 0.001596 - Subset-Accuracy: 0.904215 - F1-Score: 0.923198\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986911 - Log-Loss: 1.642414 - Hamming-Loss: 0.002026 - Subset-Accuracy: 0.862450 - F1-Score: 0.900526\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 87s 111ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987347 - Log-Loss: 1.491062 - Hamming-Loss: 0.001931 - Subset-Accuracy: 0.872028 - F1-Score: 0.905731\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8752796964685281\n",
      "\n",
      "\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 796.3247\n",
      "Function value obtained: -0.8753\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.002411288265240064, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_144 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_144 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_144 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_144 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 138s 175ms/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975177 - Log-Loss: 3.061375 - Hamming-Loss: 0.001665 - Subset-Accuracy: 0.908983 - F1-Score: 0.919413\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.983317 - Log-Loss: 2.300861 - Hamming-Loss: 0.001299 - Subset-Accuracy: 0.943690 - F1-Score: 0.938753\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985630 - Log-Loss: 1.880213 - Hamming-Loss: 0.001328 - Subset-Accuracy: 0.943564 - F1-Score: 0.937600\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 85s 108ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986972 - Log-Loss: 1.636882 - Hamming-Loss: 0.001367 - Subset-Accuracy: 0.939693 - F1-Score: 0.935640\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 86s 108ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987932 - Log-Loss: 1.433923 - Hamming-Loss: 0.001295 - Subset-Accuracy: 0.939782 - F1-Score: 0.938894\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8540408908731164\n",
      "\n",
      "\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 675.6883\n",
      "Function value obtained: -0.8540\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_145 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_145 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_145 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_145 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 137s 173ms/step - loss: 0.0201 - acc: 0.9952 - val_loss: 0.0067 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.974533 - Log-Loss: 3.102908 - Hamming-Loss: 0.002021 - Subset-Accuracy: 0.871970 - F1-Score: 0.900930\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.983272 - Log-Loss: 2.411299 - Hamming-Loss: 0.001475 - Subset-Accuracy: 0.919815 - F1-Score: 0.929610\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 85s 107ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985979 - Log-Loss: 2.059455 - Hamming-Loss: 0.001493 - Subset-Accuracy: 0.915038 - F1-Score: 0.928569\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 86s 109ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987202 - Log-Loss: 1.790966 - Hamming-Loss: 0.001513 - Subset-Accuracy: 0.908742 - F1-Score: 0.927322\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 85s 107ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987750 - Log-Loss: 1.597104 - Hamming-Loss: 0.001575 - Subset-Accuracy: 0.905813 - F1-Score: 0.924413\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8655760323248249\n",
      "\n",
      "\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 675.2233\n",
      "Function value obtained: -0.8656\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.48906822409938283, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_146 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_146 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_146 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_146 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 209s 264ms/step - loss: 0.0251 - acc: 0.9941 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.965228 - Log-Loss: 3.239943 - Hamming-Loss: 0.003981 - Subset-Accuracy: 0.776258 - F1-Score: 0.809332\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977936 - Log-Loss: 2.617840 - Hamming-Loss: 0.002646 - Subset-Accuracy: 0.865177 - F1-Score: 0.876069\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0101 - acc: 0.9974 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982383 - Log-Loss: 2.230604 - Hamming-Loss: 0.002063 - Subset-Accuracy: 0.890408 - F1-Score: 0.902558\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985225 - Log-Loss: 1.946079 - Hamming-Loss: 0.001800 - Subset-Accuracy: 0.901175 - F1-Score: 0.914415\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986684 - Log-Loss: 1.730095 - Hamming-Loss: 0.001732 - Subset-Accuracy: 0.905096 - F1-Score: 0.917752\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8608361364728496\n",
      "\n",
      "\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 1001.2204\n",
      "Function value obtained: -0.8608\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.00038611392926801724, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_147 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_147 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_147 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_147 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 282s 357ms/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.936198 - Log-Loss: 3.353661 - Hamming-Loss: 0.009479 - Subset-Accuracy: 0.647604 - F1-Score: 0.619703\n",
      "Epoch 2/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.968653 - Log-Loss: 2.746360 - Hamming-Loss: 0.005683 - Subset-Accuracy: 0.790055 - F1-Score: 0.762269\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.976451 - Log-Loss: 2.395417 - Hamming-Loss: 0.003318 - Subset-Accuracy: 0.836508 - F1-Score: 0.849897\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0080 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980221 - Log-Loss: 2.072037 - Hamming-Loss: 0.002432 - Subset-Accuracy: 0.869193 - F1-Score: 0.886702\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 226s 287ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981517 - Log-Loss: 1.854341 - Hamming-Loss: 0.002217 - Subset-Accuracy: 0.872034 - F1-Score: 0.894203\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8544707803453907\n",
      "\n",
      "\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 1389.4072\n",
      "Function value obtained: -0.8545\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4994359370526713, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_148 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_148 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_148 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_148 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 287s 364ms/step - loss: 0.0245 - acc: 0.9941 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.955987 - Log-Loss: 3.341720 - Hamming-Loss: 0.007611 - Subset-Accuracy: 0.715517 - F1-Score: 0.682453\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0051 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.969668 - Log-Loss: 2.737617 - Hamming-Loss: 0.004470 - Subset-Accuracy: 0.802295 - F1-Score: 0.796653\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0043 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980299 - Log-Loss: 2.268314 - Hamming-Loss: 0.002610 - Subset-Accuracy: 0.869390 - F1-Score: 0.878240\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.982849 - Log-Loss: 1.982948 - Hamming-Loss: 0.002107 - Subset-Accuracy: 0.879931 - F1-Score: 0.899866\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 231s 292ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984665 - Log-Loss: 1.728742 - Hamming-Loss: 0.002042 - Subset-Accuracy: 0.872528 - F1-Score: 0.902837\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8565830346475508\n",
      "\n",
      "\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 1413.1582\n",
      "Function value obtained: -0.8566\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.4872413270226367, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_149 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_149 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_149 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_149 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 208s 263ms/step - loss: 0.0255 - acc: 0.9939 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.967193 - Log-Loss: 3.248706 - Hamming-Loss: 0.004860 - Subset-Accuracy: 0.798161 - F1-Score: 0.785078\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.976824 - Log-Loss: 2.675137 - Hamming-Loss: 0.003471 - Subset-Accuracy: 0.849773 - F1-Score: 0.843304\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 149s 188ms/step - loss: 0.0099 - acc: 0.9975 - val_loss: 0.0045 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981929 - Log-Loss: 2.318745 - Hamming-Loss: 0.002344 - Subset-Accuracy: 0.884648 - F1-Score: 0.890651\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984695 - Log-Loss: 1.956384 - Hamming-Loss: 0.001910 - Subset-Accuracy: 0.899463 - F1-Score: 0.910132\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 149s 188ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986633 - Log-Loss: 1.714186 - Hamming-Loss: 0.001802 - Subset-Accuracy: 0.904174 - F1-Score: 0.914976\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988754 - Log-Loss: 1.472326 - Hamming-Loss: 0.001728 - Subset-Accuracy: 0.908799 - F1-Score: 0.918395\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8682074889658773\n",
      "\n",
      "\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 1168.1956\n",
      "Function value obtained: -0.8682\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 6, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.041411331190169716, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 6 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_150 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_150 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_150 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_150 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0208 - acc: 0.9953 - val_loss: 0.0069 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.977348 - Log-Loss: 3.029243 - Hamming-Loss: 0.001579 - Subset-Accuracy: 0.922317 - F1-Score: 0.924531\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 92s 116ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.983231 - Log-Loss: 2.395604 - Hamming-Loss: 0.001413 - Subset-Accuracy: 0.934899 - F1-Score: 0.933216\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 93s 118ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986464 - Log-Loss: 1.995934 - Hamming-Loss: 0.001330 - Subset-Accuracy: 0.933863 - F1-Score: 0.937020\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 93s 117ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988118 - Log-Loss: 1.725394 - Hamming-Loss: 0.001361 - Subset-Accuracy: 0.927862 - F1-Score: 0.935270\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 92s 116ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988689 - Log-Loss: 1.529907 - Hamming-Loss: 0.001459 - Subset-Accuracy: 0.918871 - F1-Score: 0.930352\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8647704590818363\n",
      "\n",
      "\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 723.7525\n",
      "Function value obtained: -0.8648\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4716496266848345, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_151 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_151 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_151 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_151 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 288s 365ms/step - loss: 0.0238 - acc: 0.9944 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.951294 - Log-Loss: 3.367206 - Hamming-Loss: 0.007158 - Subset-Accuracy: 0.710305 - F1-Score: 0.693473\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0123 - acc: 0.9971 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.972511 - Log-Loss: 2.783213 - Hamming-Loss: 0.004010 - Subset-Accuracy: 0.810107 - F1-Score: 0.817493\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0098 - acc: 0.9975 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.979985 - Log-Loss: 2.360406 - Hamming-Loss: 0.002466 - Subset-Accuracy: 0.870303 - F1-Score: 0.884070\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983768 - Log-Loss: 1.999892 - Hamming-Loss: 0.001837 - Subset-Accuracy: 0.901682 - F1-Score: 0.913035\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 228s 289ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985324 - Log-Loss: 1.765766 - Hamming-Loss: 0.001919 - Subset-Accuracy: 0.893832 - F1-Score: 0.908584\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986766 - Log-Loss: 1.616170 - Hamming-Loss: 0.001953 - Subset-Accuracy: 0.882274 - F1-Score: 0.906121\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8666634885827335\n",
      "\n",
      "\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 1649.9891\n",
      "Function value obtained: -0.8667\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.47832595568582564, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_152 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_152 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_152 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_152 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0221 - acc: 0.9950 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.976094 - Log-Loss: 3.089418 - Hamming-Loss: 0.001414 - Subset-Accuracy: 0.925623 - F1-Score: 0.932002\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982060 - Log-Loss: 2.491715 - Hamming-Loss: 0.001360 - Subset-Accuracy: 0.929371 - F1-Score: 0.935199\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986607 - Log-Loss: 2.072245 - Hamming-Loss: 0.001292 - Subset-Accuracy: 0.936649 - F1-Score: 0.939038\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988025 - Log-Loss: 1.825402 - Hamming-Loss: 0.001312 - Subset-Accuracy: 0.932357 - F1-Score: 0.937784\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989177 - Log-Loss: 1.611168 - Hamming-Loss: 0.001307 - Subset-Accuracy: 0.932439 - F1-Score: 0.938071\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989863 - Log-Loss: 1.456935 - Hamming-Loss: 0.001358 - Subset-Accuracy: 0.928302 - F1-Score: 0.935642\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8701640285017455\n",
      "\n",
      "\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 804.9263\n",
      "Function value obtained: -0.8702\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_153 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_153 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_153 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_153 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 145s 183ms/step - loss: 0.0199 - acc: 0.9954 - val_loss: 0.0064 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974279 - Log-Loss: 3.021165 - Hamming-Loss: 0.001897 - Subset-Accuracy: 0.878476 - F1-Score: 0.906844\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983577 - Log-Loss: 2.254971 - Hamming-Loss: 0.001344 - Subset-Accuracy: 0.934240 - F1-Score: 0.936286\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986758 - Log-Loss: 1.864811 - Hamming-Loss: 0.001266 - Subset-Accuracy: 0.936925 - F1-Score: 0.939888\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 88s 112ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987642 - Log-Loss: 1.629620 - Hamming-Loss: 0.001308 - Subset-Accuracy: 0.931878 - F1-Score: 0.937783\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988428 - Log-Loss: 1.433495 - Hamming-Loss: 0.001317 - Subset-Accuracy: 0.930391 - F1-Score: 0.937397\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.988744 - Log-Loss: 1.293841 - Hamming-Loss: 0.001364 - Subset-Accuracy: 0.926346 - F1-Score: 0.935107\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8798539497705631\n",
      "\n",
      "\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 810.2841\n",
      "Function value obtained: -0.8799\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.03227919375014155, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_154 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_154 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_154 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_154 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 180s 228ms/step - loss: 0.0189 - acc: 0.9958 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974665 - Log-Loss: 2.974617 - Hamming-Loss: 0.001910 - Subset-Accuracy: 0.908203 - F1-Score: 0.909033\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981692 - Log-Loss: 2.331512 - Hamming-Loss: 0.001542 - Subset-Accuracy: 0.933314 - F1-Score: 0.927268\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984678 - Log-Loss: 1.981534 - Hamming-Loss: 0.001410 - Subset-Accuracy: 0.933853 - F1-Score: 0.933291\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986026 - Log-Loss: 1.747787 - Hamming-Loss: 0.001358 - Subset-Accuracy: 0.929738 - F1-Score: 0.935443\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987426 - Log-Loss: 1.575918 - Hamming-Loss: 0.001303 - Subset-Accuracy: 0.933032 - F1-Score: 0.938246\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987894 - Log-Loss: 1.407660 - Hamming-Loss: 0.001344 - Subset-Accuracy: 0.930721 - F1-Score: 0.936223\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8804730258014074\n",
      "\n",
      "\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 1025.8175\n",
      "Function value obtained: -0.8805\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_155 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_155 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_155 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_155 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 153s 193ms/step - loss: 0.0203 - acc: 0.9954 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.977791 - Log-Loss: 2.884746 - Hamming-Loss: 0.001307 - Subset-Accuracy: 0.938082 - F1-Score: 0.937473\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.983877 - Log-Loss: 2.180071 - Hamming-Loss: 0.001207 - Subset-Accuracy: 0.943361 - F1-Score: 0.942726\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 87s 110ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986089 - Log-Loss: 1.815067 - Hamming-Loss: 0.001199 - Subset-Accuracy: 0.944099 - F1-Score: 0.943302\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987415 - Log-Loss: 1.544140 - Hamming-Loss: 0.001179 - Subset-Accuracy: 0.944819 - F1-Score: 0.944332\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8387567032852606\n",
      "\n",
      "\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 603.2679\n",
      "Function value obtained: -0.8388\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.044093859923925734, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_156 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_156 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_156 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_156 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0211 - acc: 0.9954 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.971809 - Log-Loss: 3.122686 - Hamming-Loss: 0.002315 - Subset-Accuracy: 0.883783 - F1-Score: 0.890118\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 94s 119ms/step - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981200 - Log-Loss: 2.390165 - Hamming-Loss: 0.001565 - Subset-Accuracy: 0.925858 - F1-Score: 0.926271\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985085 - Log-Loss: 2.014145 - Hamming-Loss: 0.001306 - Subset-Accuracy: 0.939851 - F1-Score: 0.938391\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 89s 113ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986710 - Log-Loss: 1.740655 - Hamming-Loss: 0.001272 - Subset-Accuracy: 0.941189 - F1-Score: 0.940051\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 89s 112ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987451 - Log-Loss: 1.576258 - Hamming-Loss: 0.001306 - Subset-Accuracy: 0.938035 - F1-Score: 0.938584\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8540840602696272\n",
      "\n",
      "\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 718.2517\n",
      "Function value obtained: -0.8541\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.4743036510791354, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_157 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_157 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_157 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_157 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 211s 268ms/step - loss: 0.0276 - acc: 0.9932 - val_loss: 0.0071 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.954387 - Log-Loss: 3.601014 - Hamming-Loss: 0.007324 - Subset-Accuracy: 0.708587 - F1-Score: 0.684784\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0054 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.970253 - Log-Loss: 2.880133 - Hamming-Loss: 0.004136 - Subset-Accuracy: 0.818029 - F1-Score: 0.809970\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 146s 185ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.977376 - Log-Loss: 2.420208 - Hamming-Loss: 0.002916 - Subset-Accuracy: 0.849988 - F1-Score: 0.862015\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981264 - Log-Loss: 2.114279 - Hamming-Loss: 0.002340 - Subset-Accuracy: 0.873124 - F1-Score: 0.888307\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 147s 186ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983472 - Log-Loss: 1.862371 - Hamming-Loss: 0.002052 - Subset-Accuracy: 0.879642 - F1-Score: 0.901268\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985470 - Log-Loss: 1.611580 - Hamming-Loss: 0.001839 - Subset-Accuracy: 0.888037 - F1-Score: 0.911423\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.858597502401537\n",
      "\n",
      "\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 1175.0442\n",
      "Function value obtained: -0.8586\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.00509828632715681, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_158 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_158 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_158 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_158 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 286s 362ms/step - loss: 0.0215 - acc: 0.9952 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.941854 - Log-Loss: 3.184759 - Hamming-Loss: 0.008347 - Subset-Accuracy: 0.685155 - F1-Score: 0.656985\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 231s 292ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.966107 - Log-Loss: 2.714310 - Hamming-Loss: 0.004826 - Subset-Accuracy: 0.774451 - F1-Score: 0.784317\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.977548 - Log-Loss: 2.347334 - Hamming-Loss: 0.003004 - Subset-Accuracy: 0.839121 - F1-Score: 0.859961\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981996 - Log-Loss: 2.010393 - Hamming-Loss: 0.002029 - Subset-Accuracy: 0.887149 - F1-Score: 0.904069\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 227s 288ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984029 - Log-Loss: 1.749027 - Hamming-Loss: 0.001857 - Subset-Accuracy: 0.891512 - F1-Score: 0.911385\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8616943537779509\n",
      "\n",
      "\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 1411.6250\n",
      "Function value obtained: -0.8617\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 3, 'latent_dim': 3, 'dropout_rate': 0.4838972917021487, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_159 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_159 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_159 (Bidirecti (None, None, 384)         344064    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_159 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 1,838,281\n",
      "Trainable params: 1,838,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 146s 184ms/step - loss: 0.0230 - acc: 0.9947 - val_loss: 0.0077 - val_acc: 0.9986\n",
      "Adiitional val metrics: - ROC-AUC: 0.968037 - Log-Loss: 3.346383 - Hamming-Loss: 0.003044 - Subset-Accuracy: 0.823631 - F1-Score: 0.850627\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 91s 115ms/step - loss: 0.0116 - acc: 0.9974 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.979785 - Log-Loss: 2.551206 - Hamming-Loss: 0.002294 - Subset-Accuracy: 0.905080 - F1-Score: 0.893007\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 90s 113ms/step - loss: 0.0089 - acc: 0.9978 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984491 - Log-Loss: 2.100248 - Hamming-Loss: 0.001629 - Subset-Accuracy: 0.927002 - F1-Score: 0.923373\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986607 - Log-Loss: 1.830839 - Hamming-Loss: 0.001455 - Subset-Accuracy: 0.929022 - F1-Score: 0.931254\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 90s 114ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988244 - Log-Loss: 1.538504 - Hamming-Loss: 0.001375 - Subset-Accuracy: 0.932370 - F1-Score: 0.935103\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8436482084690554\n",
      "\n",
      "\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 714.9169\n",
      "Function value obtained: -0.8436\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_160 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_160 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_160 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_160 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 186s 235ms/step - loss: 0.0189 - acc: 0.9958 - val_loss: 0.0063 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.974520 - Log-Loss: 3.019364 - Hamming-Loss: 0.001940 - Subset-Accuracy: 0.899482 - F1-Score: 0.906488\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 124s 156ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981025 - Log-Loss: 2.358251 - Hamming-Loss: 0.001652 - Subset-Accuracy: 0.928971 - F1-Score: 0.922159\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984028 - Log-Loss: 1.987111 - Hamming-Loss: 0.001353 - Subset-Accuracy: 0.936523 - F1-Score: 0.935946\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985625 - Log-Loss: 1.740315 - Hamming-Loss: 0.001286 - Subset-Accuracy: 0.936443 - F1-Score: 0.939151\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 122s 155ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986700 - Log-Loss: 1.571232 - Hamming-Loss: 0.001313 - Subset-Accuracy: 0.933251 - F1-Score: 0.937767\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 123s 156ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.987167 - Log-Loss: 1.431558 - Hamming-Loss: 0.001352 - Subset-Accuracy: 0.930249 - F1-Score: 0.935932\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8710222752585521\n",
      "\n",
      "\n",
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 1030.7922\n",
      "Function value obtained: -0.8710\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.49447450608392685, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_161 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_161 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_161 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_161 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 186s 236ms/step - loss: 0.0208 - acc: 0.9949 - val_loss: 0.0068 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.975453 - Log-Loss: 3.142892 - Hamming-Loss: 0.002211 - Subset-Accuracy: 0.886357 - F1-Score: 0.895058\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 127s 160ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0046 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981824 - Log-Loss: 2.430510 - Hamming-Loss: 0.001935 - Subset-Accuracy: 0.909290 - F1-Score: 0.909125\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 126s 160ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985207 - Log-Loss: 2.051722 - Hamming-Loss: 0.001441 - Subset-Accuracy: 0.927843 - F1-Score: 0.931861\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 125s 159ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987074 - Log-Loss: 1.791412 - Hamming-Loss: 0.001389 - Subset-Accuracy: 0.928708 - F1-Score: 0.934199\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.838343053686257\n",
      "\n",
      "\n",
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 761.0637\n",
      "Function value obtained: -0.8383\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.006770703328188412, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_162 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_162 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_162 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_162 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 294s 372ms/step - loss: 0.0237 - acc: 0.9947 - val_loss: 0.0083 - val_acc: 0.9985\n",
      "Adiitional val metrics: - ROC-AUC: 0.932201 - Log-Loss: 3.544953 - Hamming-Loss: 0.008684 - Subset-Accuracy: 0.648314 - F1-Score: 0.628420\n",
      "Epoch 2/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0052 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.969550 - Log-Loss: 2.837601 - Hamming-Loss: 0.004545 - Subset-Accuracy: 0.811613 - F1-Score: 0.798330\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0101 - acc: 0.9975 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.975268 - Log-Loss: 2.499363 - Hamming-Loss: 0.003447 - Subset-Accuracy: 0.820182 - F1-Score: 0.840886\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.980892 - Log-Loss: 2.126721 - Hamming-Loss: 0.002454 - Subset-Accuracy: 0.859261 - F1-Score: 0.884604\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 228s 289ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984372 - Log-Loss: 1.826545 - Hamming-Loss: 0.001863 - Subset-Accuracy: 0.894657 - F1-Score: 0.911266\n",
      "Epoch 6/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986158 - Log-Loss: 1.585095 - Hamming-Loss: 0.001754 - Subset-Accuracy: 0.899716 - F1-Score: 0.916231\n",
      "Epoch 7/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.986986 - Log-Loss: 1.369009 - Hamming-Loss: 0.001656 - Subset-Accuracy: 0.900984 - F1-Score: 0.920722\n",
      "Epoch 8/21\n",
      "790/790 [==============================] - 227s 287ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.987245 - Log-Loss: 1.241475 - Hamming-Loss: 0.001698 - Subset-Accuracy: 0.896188 - F1-Score: 0.918359\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8685553233879196\n",
      "\n",
      "\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 2148.6271\n",
      "Function value obtained: -0.8686\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 5, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.005048865457676522, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_163 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_163 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_163 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_163 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 207s 262ms/step - loss: 0.0225 - acc: 0.9948 - val_loss: 0.0057 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.956191 - Log-Loss: 3.101755 - Hamming-Loss: 0.005636 - Subset-Accuracy: 0.737984 - F1-Score: 0.746840\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.971150 - Log-Loss: 2.576626 - Hamming-Loss: 0.003529 - Subset-Accuracy: 0.813261 - F1-Score: 0.835678\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978711 - Log-Loss: 2.186247 - Hamming-Loss: 0.002577 - Subset-Accuracy: 0.861090 - F1-Score: 0.878296\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 148s 187ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980542 - Log-Loss: 1.971479 - Hamming-Loss: 0.002364 - Subset-Accuracy: 0.859882 - F1-Score: 0.886315\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 148s 188ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.982806 - Log-Loss: 1.747828 - Hamming-Loss: 0.002212 - Subset-Accuracy: 0.861991 - F1-Score: 0.892842\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8671832584768767\n",
      "\n",
      "\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 1013.6419\n",
      "Function value obtained: -0.8672\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_164 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_164 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_164 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_164 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 294s 372ms/step - loss: 0.0225 - acc: 0.9948 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.960173 - Log-Loss: 3.095972 - Hamming-Loss: 0.005104 - Subset-Accuracy: 0.771240 - F1-Score: 0.769784\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.976273 - Log-Loss: 2.504762 - Hamming-Loss: 0.002773 - Subset-Accuracy: 0.849268 - F1-Score: 0.870909\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.981360 - Log-Loss: 2.080276 - Hamming-Loss: 0.001964 - Subset-Accuracy: 0.891559 - F1-Score: 0.906898\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984345 - Log-Loss: 1.776323 - Hamming-Loss: 0.001696 - Subset-Accuracy: 0.909401 - F1-Score: 0.919701\n",
      "Epoch 5/21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 230s 291ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0040 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.985463 - Log-Loss: 1.597537 - Hamming-Loss: 0.001685 - Subset-Accuracy: 0.911972 - F1-Score: 0.920166\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8641449648480047\n",
      "\n",
      "\n",
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 1439.7728\n",
      "Function value obtained: -0.8641\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_165 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_165 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_165 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_165 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 290s 368ms/step - loss: 0.0223 - acc: 0.9948 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.953327 - Log-Loss: 3.217213 - Hamming-Loss: 0.005548 - Subset-Accuracy: 0.713453 - F1-Score: 0.736038\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 228s 288ms/step - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.974219 - Log-Loss: 2.586350 - Hamming-Loss: 0.002899 - Subset-Accuracy: 0.835801 - F1-Score: 0.861487\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980539 - Log-Loss: 2.148297 - Hamming-Loss: 0.002142 - Subset-Accuracy: 0.878951 - F1-Score: 0.897921\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983533 - Log-Loss: 1.843529 - Hamming-Loss: 0.002117 - Subset-Accuracy: 0.869028 - F1-Score: 0.899680\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 231s 293ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984787 - Log-Loss: 1.631695 - Hamming-Loss: 0.001981 - Subset-Accuracy: 0.881522 - F1-Score: 0.906227\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8689450222882614\n",
      "\n",
      "\n",
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 1429.2737\n",
      "Function value obtained: -0.8689\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.0, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_166 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_166 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_166 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_166 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 220s 279ms/step - loss: 0.0234 - acc: 0.9946 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.960477 - Log-Loss: 3.092228 - Hamming-Loss: 0.005563 - Subset-Accuracy: 0.746579 - F1-Score: 0.751010\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 154s 195ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0048 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.974648 - Log-Loss: 2.570807 - Hamming-Loss: 0.003702 - Subset-Accuracy: 0.817053 - F1-Score: 0.830156\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 150s 190ms/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.979916 - Log-Loss: 2.189465 - Hamming-Loss: 0.002433 - Subset-Accuracy: 0.865744 - F1-Score: 0.884947\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 152s 193ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.982280 - Log-Loss: 1.878238 - Hamming-Loss: 0.002021 - Subset-Accuracy: 0.880479 - F1-Score: 0.902930\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 153s 194ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.983120 - Log-Loss: 1.701947 - Hamming-Loss: 0.002044 - Subset-Accuracy: 0.872538 - F1-Score: 0.900990\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8627761031773484\n",
      "\n",
      "\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 1054.2203\n",
      "Function value obtained: -0.8628\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.4979297119339538, 'epochs': 21, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_167 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_167 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_167 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_167 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/21\n",
      "790/790 [==============================] - 290s 367ms/step - loss: 0.0257 - acc: 0.9941 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.938759 - Log-Loss: 3.626954 - Hamming-Loss: 0.007889 - Subset-Accuracy: 0.669212 - F1-Score: 0.651642\n",
      "Epoch 2/21\n",
      "790/790 [==============================] - 226s 286ms/step - loss: 0.0141 - acc: 0.9968 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.965101 - Log-Loss: 2.886066 - Hamming-Loss: 0.004509 - Subset-Accuracy: 0.796995 - F1-Score: 0.792078\n",
      "Epoch 3/21\n",
      "790/790 [==============================] - 226s 287ms/step - loss: 0.0112 - acc: 0.9973 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.978274 - Log-Loss: 2.335069 - Hamming-Loss: 0.002539 - Subset-Accuracy: 0.875753 - F1-Score: 0.881577\n",
      "Epoch 4/21\n",
      "790/790 [==============================] - 232s 293ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.981641 - Log-Loss: 2.015857 - Hamming-Loss: 0.002057 - Subset-Accuracy: 0.890171 - F1-Score: 0.902745\n",
      "Epoch 5/21\n",
      "790/790 [==============================] - 229s 290ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.984237 - Log-Loss: 1.692869 - Hamming-Loss: 0.001664 - Subset-Accuracy: 0.909290 - F1-Score: 0.920928\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8456179665806012\n",
      "\n",
      "\n",
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 1430.6802\n",
      "Function value obtained: -0.8456\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 3, 'dropout_rate': 0.01712745728146098, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_168 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_168 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_168 (Bidirecti (None, None, 384)         374784    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_168 (Spati (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, None, 300)         115500    \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,768,681\n",
      "Trainable params: 2,768,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 222s 281ms/step - loss: 0.0241 - acc: 0.9941 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Adiitional val metrics: - ROC-AUC: 0.955866 - Log-Loss: 3.155889 - Hamming-Loss: 0.004733 - Subset-Accuracy: 0.761745 - F1-Score: 0.778376\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790/790 [==============================] - 152s 193ms/step - loss: 0.0115 - acc: 0.9972 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.973871 - Log-Loss: 2.596532 - Hamming-Loss: 0.002780 - Subset-Accuracy: 0.851881 - F1-Score: 0.868624\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 153s 193ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.980827 - Log-Loss: 2.169802 - Hamming-Loss: 0.001987 - Subset-Accuracy: 0.892003 - F1-Score: 0.905603\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 153s 193ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983317 - Log-Loss: 1.897188 - Hamming-Loss: 0.001808 - Subset-Accuracy: 0.898429 - F1-Score: 0.913795\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 152s 192ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0038 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.984331 - Log-Loss: 1.736108 - Hamming-Loss: 0.001865 - Subset-Accuracy: 0.891629 - F1-Score: 0.910647\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8650430504305043\n",
      "\n",
      "\n",
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 1057.1339\n",
      "Function value obtained: -0.8650\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.4694733439206244, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_169 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_169 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_169 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_169 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 192s 244ms/step - loss: 0.0211 - acc: 0.9951 - val_loss: 0.0069 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.971669 - Log-Loss: 3.257984 - Hamming-Loss: 0.002437 - Subset-Accuracy: 0.832742 - F1-Score: 0.877569\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.982641 - Log-Loss: 2.449371 - Hamming-Loss: 0.001361 - Subset-Accuracy: 0.932826 - F1-Score: 0.935553\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986480 - Log-Loss: 2.067271 - Hamming-Loss: 0.001311 - Subset-Accuracy: 0.936095 - F1-Score: 0.937955\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 124s 158ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988186 - Log-Loss: 1.789414 - Hamming-Loss: 0.001320 - Subset-Accuracy: 0.935505 - F1-Score: 0.937637\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 124s 158ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.988972 - Log-Loss: 1.563800 - Hamming-Loss: 0.001379 - Subset-Accuracy: 0.929136 - F1-Score: 0.934715\n",
      "Epoch 6/20\n",
      "790/790 [==============================] - 125s 158ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Adiitional val metrics: - ROC-AUC: 0.989511 - Log-Loss: 1.352283 - Hamming-Loss: 0.001403 - Subset-Accuracy: 0.923740 - F1-Score: 0.933292\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8752441289953794\n",
      "\n",
      "\n",
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 1054.8132\n",
      "Function value obtained: -0.8752\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 5, 'embed_size': 3, 'latent_dim': 5, 'dropout_rate': 0.008752104841334209, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_170 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_170 (Embedding)    (None, None, 30)          1349520   \n",
      "_________________________________________________________________\n",
      "bidirectional_170 (Bidirecti (None, None, 640)         901120    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_170 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 2,472,137\n",
      "Trainable params: 2,472,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 190s 241ms/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.0068 - val_acc: 0.9987\n",
      "Adiitional val metrics: - ROC-AUC: 0.972211 - Log-Loss: 3.186176 - Hamming-Loss: 0.002595 - Subset-Accuracy: 0.869498 - F1-Score: 0.876794\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 124s 157ms/step - loss: 0.0103 - acc: 0.9977 - val_loss: 0.0049 - val_acc: 0.9989\n",
      "Adiitional val metrics: - ROC-AUC: 0.979736 - Log-Loss: 2.440480 - Hamming-Loss: 0.002325 - Subset-Accuracy: 0.911310 - F1-Score: 0.893377\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 124s 156ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.0042 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.983205 - Log-Loss: 2.054130 - Hamming-Loss: 0.001778 - Subset-Accuracy: 0.924187 - F1-Score: 0.916882\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 124s 158ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.985420 - Log-Loss: 1.766879 - Hamming-Loss: 0.001528 - Subset-Accuracy: 0.930201 - F1-Score: 0.928257\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 124s 158ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Adiitional val metrics: - ROC-AUC: 0.986472 - Log-Loss: 1.566204 - Hamming-Loss: 0.001414 - Subset-Accuracy: 0.932588 - F1-Score: 0.933359\n",
      "predicting test data ...\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8555972952667168\n",
      "\n",
      "\n",
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 908.0216\n",
      "Function value obtained: -0.8556\n",
      "Current minimum: -0.8806\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 15, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.486227426309179, 'epochs': 20, 'category': None}\n",
      "********************************************************************************\n",
      "upsampling for 15 times...\n",
      "preparing features ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_171 (InputLayer)       (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_171 (Embedding)    (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_171 (Bidirecti (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_171 (Spati (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, None, 97)          29197     \n",
      "=================================================================\n",
      "Total params: 3,423,017\n",
      "Trainable params: 3,423,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "Epoch 1/20\n",
      " 28/790 [>.............................] - ETA: 30:31 - loss: 0.1675 - acc: 0.9436"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,19556,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bidirectional_171/ReverseV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_170/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-722906180c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m#res_torch = gp_minimize(bayes_opt_torch, space, x0=x0, n_calls=50, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;31m# save opt results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callback=callback, n_jobs=n_jobs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-722906180c48>\u001b[0m in \u001b[0;36mbayes_opt\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0mgold_labels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                     results_file=results_file)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-722906180c48>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(param, notes_train, labels_train, up_notes_train, up_labels_train, gold_labels_train, notes_test, labels_test, gold_labels_test, results_file, verbose)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustevl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                 verbose=v)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# prediction of test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,19556,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bidirectional_171/ReverseV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_170/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss, f1_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from models import get_rnn_model\n",
    "from cm import multilabel_confusion_matrix\n",
    "from data_process import get_embedding_matrix, data_generator, get_all_notes_labels, get_features, get_targets, get_gold_label_targets\n",
    "\n",
    "# Customized Evaluation for keras model\n",
    "class CustomEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = list(validation_data)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = []\n",
    "            for x in self.X_val:\n",
    "                y = np.squeeze(self.model.predict_on_batch(x))\n",
    "                y_pred.append(y)\n",
    "            y_pred = np.concatenate(y_pred)\n",
    "            y_pred_ham = y_pred > 0.5\n",
    "            y_val = np.concatenate(self.y_val)\n",
    "            roc = roc_auc_score(y_val, y_pred, average='micro')\n",
    "            loss = log_loss(y_val, y_pred)\n",
    "            ham = hamming_loss(y_val, y_pred_ham)\n",
    "            sub = accuracy_score(y_val, y_pred_ham)\n",
    "            f1 = f1_score(y_val, y_pred_ham, average='micro')\n",
    "            print(\"Adiitional val metrics: - ROC-AUC: %.6f - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1-Score: %.6f\" % (roc, loss, ham, sub, f1))\n",
    "            \n",
    "def model_train(param, \n",
    "                notes_train, \n",
    "                labels_train, \n",
    "                up_notes_train, \n",
    "                up_labels_train, \n",
    "                gold_labels_train, \n",
    "                notes_test, \n",
    "                labels_test, \n",
    "                gold_labels_test,\n",
    "                results_file,\n",
    "                verbose=1):\n",
    "    \n",
    "    print('*'*80)\n",
    "    print(\"Parameters (note: embed_size*10, latent_dim*64):\\n\", param)\n",
    "    print('*'*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # assign parameters\n",
    "    up = int(param['up'])\n",
    "    window_size = int(param['window_size'])\n",
    "    embed_size = int(param['embed_size'] * 10)\n",
    "    latent_dim = int(param['latent_dim'] * 64)\n",
    "    dropout_rate = param['dropout_rate']\n",
    "    epochs = param['epochs']\n",
    "    category = param['category']\n",
    "    max_features = 60000 #param['max_features']\n",
    "    train_embed = True #param['train_embed']\n",
    "    model_type = 'CuDNNLSTM' #param['model_type']\n",
    "    \n",
    "    # upsampling\n",
    "    if up > 0:\n",
    "        if verbose != 0: print('upsampling for %d times...' % (up))\n",
    "        notes_train = [note + up * up_note for note, up_note in zip(notes_train, up_notes_train)]\n",
    "        labels_train = [label + up * up_label for label, up_label in zip(labels_train, up_labels_train)]\n",
    "    notes = notes_train + notes_test\n",
    "    labels = labels_train + labels_test\n",
    "    gold_labels = gold_labels_train + gold_labels_test\n",
    "    \n",
    "    # prepare features\n",
    "    X_train_seq, X_test_seq, word_index = get_features(max_features, notes_train, notes_test, verbose=1)\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "\n",
    "    # prepare embedding matrix\n",
    "    if train_embed:\n",
    "        if verbose != 0: print('preparing pretrained embedding matrix ...')\n",
    "        w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "        embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "        embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, \n",
    "                                                word_index=word_index, \n",
    "                                                max_features=max_features, \n",
    "                                                embed_size=embed_size)\n",
    "        \n",
    "    # prepare targets\n",
    "    Y_train, Y_test, mlb, num_labels = get_targets(labels_train, labels_test, category, verbose=1)  \n",
    "\n",
    "    # get rnn model\n",
    "    model = get_rnn_model(nb_words=nb_words, \n",
    "                          num_labels=num_labels, \n",
    "                          embed_size=embed_size, \n",
    "                          latent_dim=latent_dim, \n",
    "                          model_type=model_type, \n",
    "                          embedding_matrix=embedding_matrix, \n",
    "                          dropout=dropout_rate, \n",
    "                          train_embed=train_embed)\n",
    "    if verbose != 0: \n",
    "        print('model summary:')\n",
    "        print(model.summary())\n",
    "    \n",
    "    # model compiling\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # model training\n",
    "    if verbose != 0: print('\\ntraining model ...')\n",
    "    custevl = CustomEvaluation(validation_data=(X_test_seq, Y_test), interval=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=2, verbose=0, mode='auto')\n",
    "    train_gen = data_generator(X_train_seq, Y_train)\n",
    "    test_gen = data_generator(X_test_seq, Y_test)\n",
    "    v = 1 if verbose != 0 else 0  \n",
    "    hist = model.fit_generator(train_gen,\n",
    "                                steps_per_epoch=len(Y_train),\n",
    "                                epochs=epochs,\n",
    "                                validation_data=test_gen,\n",
    "                                validation_steps=len(Y_test),\n",
    "                                callbacks=[custevl, earlystop],\n",
    "                                verbose=v)\n",
    "\n",
    "    # prediction of test data\n",
    "    if verbose != 0: print('predicting test data ...')\n",
    "    Y_pred = []\n",
    "    for x in X_test_seq:\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y_pred = np.squeeze(model.predict_on_batch(x))\n",
    "        Y_pred.append(y_pred)\n",
    "    Y_pred_concat = np.concatenate(Y_pred)\n",
    "    Y_val = np.concatenate(Y_test)\n",
    "\n",
    "    # confusion matrix \n",
    "    if verbose == 2: \n",
    "        cm = multilabel_confusion_matrix(Y_val, np.where(Y_pred_concat > 0.5, 1, 0))\n",
    "        for i, j in zip(cm, mlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # prepare gold label targets\n",
    "    Y_gold_test, Y_gold_pred, gmlb = get_gold_label_targets(Y_pred, gold_labels, gold_labels_test, mlb, category=category, verbose=1) \n",
    "\n",
    "    # f1 scores for gold label\n",
    "    f1 = f1_score(Y_gold_test, Y_gold_pred, average='micro')\n",
    "    print('\\nF1 Scores for global labels:\\nALL (average=\"micro\"):', f1)\n",
    "    \n",
    "    # confusion matrix for gold label\n",
    "    if verbose == 2: \n",
    "        gcm = multilabel_confusion_matrix(np.concatenate(Y_gold_test), np.concatenate(Y_gold_pred))\n",
    "        for i, j in zip(gcm, gmlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "    \n",
    "    # f1 score list\n",
    "    if verbose == 2: \n",
    "        f1_all = f1_score(Y_gold_test, Y_gold_pred, average=None)\n",
    "        for i, j in zip(f1_all, gmlb.classes_):\n",
    "            print(j+': '+str(i))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # save results\n",
    "    with open(results_file,\"a\") as f:\n",
    "        f.write(\"Parameters (note: embed_size*10, ltent_dim*64):\\n\" + str(param))\n",
    "        f.write('\\nF1 Scores for global labels(average=\"micro\"): %.3f; Running time: %.1f\\n' % (f1, elapsed_time))\n",
    "          \n",
    "    return f1\n",
    "\n",
    "def bayes_opt(space):\n",
    "    \n",
    "    results_file = \"opt_results_\" + time.strftime(\"%Y%m%d\") + \".txt\"\n",
    "    \n",
    "    param = {\n",
    "            'up': space[0],               # Times of upsampling for training data\n",
    "            'window_size': space[1],                # Window size for word2vec\n",
    "            'embed_size': space[2],                # Length of the vector that we willl get from the embedding layer\n",
    "            'latent_dim': space[3],               # Hidden layers dimension \n",
    "            'dropout_rate': space[4],             # Rate of the dropout layers\n",
    "            'epochs': space[5],               # Max num of vocabulary\n",
    "            'category': space[6]}                 # Number of epochs\n",
    "            #'max_features': space[0],              # Is categoty labels\n",
    "            #'train_embed': space[0],               # Using pre-made embedidng matrix as weight\n",
    "            #'model_type': space[0]\n",
    "            #}\n",
    "                \n",
    "    f1 = model_train(param, \n",
    "                    notes_train, \n",
    "                    labels_train, \n",
    "                    up_notes_train, \n",
    "                    up_labels_train, \n",
    "                    gold_labels_train, \n",
    "                    notes_test, \n",
    "                    labels_test, \n",
    "                    gold_labels_test,\n",
    "                    results_file=results_file)\n",
    "    \n",
    "    return (-f1)    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # loading data \n",
    "    if os.path.exists('loaded_data.dat'):\n",
    "        \n",
    "        with open('loaded_data.dat','rb') as f:\n",
    "            notes_train = pickle.load(f)\n",
    "            labels_train = pickle.load(f)\n",
    "            up_notes_train = pickle.load(f)\n",
    "            up_labels_train = pickle.load(f)\n",
    "            gold_labels_train = pickle.load(f)\n",
    "            notes_test = pickle.load(f)\n",
    "            labels_test = pickle.load(f)\n",
    "            gold_labels_test = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        notes_train_1, labels_train_1, up_notes_train_1, up_labels_train_1, gold_labels_train_1 = get_all_notes_labels('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1') \n",
    "        notes_train_2, labels_train_2, up_notes_train_2, up_labels_train_2, gold_labels_train_2 = get_all_notes_labels('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2') \n",
    "\n",
    "        notes_train = notes_train_1 + notes_train_2\n",
    "        labels_train = labels_train_1 + labels_train_2\n",
    "        up_notes_train = up_notes_train_1 + up_notes_train_2\n",
    "        up_labels_train = up_labels_train_1 + up_labels_train_2\n",
    "        gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "\n",
    "        notes_test, labels_test, _1, _2, gold_labels_test = get_all_notes_labels('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete')\n",
    "\n",
    "        with open('loaded_data.dat','wb') as f:\n",
    "            pickle.dump(notes_train, f)\n",
    "            pickle.dump(labels_train, f)\n",
    "            pickle.dump(up_notes_train, f)\n",
    "            pickle.dump(up_labels_train, f)\n",
    "            pickle.dump(gold_labels_train, f)\n",
    "            pickle.dump(notes_test, f)\n",
    "            pickle.dump(labels_test, f)\n",
    "            pickle.dump(gold_labels_test, f)\n",
    "\n",
    "    # loading parameters space\n",
    "    param = {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 20, 'category': None}\n",
    "    \n",
    "    model_train(param, \n",
    "                notes_train, \n",
    "                labels_train, \n",
    "                up_notes_train, \n",
    "                up_labels_train, \n",
    "                gold_labels_train, \n",
    "                notes_test, \n",
    "                labels_test, \n",
    "                gold_labels_test,\n",
    "                results_file=results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
