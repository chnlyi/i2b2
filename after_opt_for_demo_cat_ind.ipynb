{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:04:56.704095Z",
     "start_time": "2019-06-04T14:54:13.164980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Parameters (note: embed_size*10, latent_dim*64):\n",
      " {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 20, 'category': 'cat_ind'}\n",
      "********************************************************************************\n",
      "upsampling for 5 times...\n",
      "preparing features ...\n",
      "preparing pretrained embedding matrix ...\n",
      "preparing targets ...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          2249200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 640)         952320    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, None, 640)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 300)         192300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, None, 39)          11739     \n",
      "=================================================================\n",
      "Total params: 3,405,559\n",
      "Trainable params: 3,405,559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training model ...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "790/790 [==============================] - 116s 147ms/step - loss: 0.0253 - acc: 0.9940 - val_loss: 0.0106 - val_acc: 0.9978\n",
      "Adiitional val metrics: - ROC-AUC: 0.982506 - Log-Loss: 2.153378 - Hamming-Loss: 0.003217 - Subset-Accuracy: 0.915231 - F1-Score: 0.936161\n",
      "Epoch 2/20\n",
      "790/790 [==============================] - 113s 143ms/step - loss: 0.0142 - acc: 0.9964 - val_loss: 0.0078 - val_acc: 0.9980\n",
      "Adiitional val metrics: - ROC-AUC: 0.987078 - Log-Loss: 1.574913 - Hamming-Loss: 0.002646 - Subset-Accuracy: 0.935841 - F1-Score: 0.947947\n",
      "Epoch 3/20\n",
      "790/790 [==============================] - 113s 144ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0071 - val_acc: 0.9983\n",
      "Adiitional val metrics: - ROC-AUC: 0.988625 - Log-Loss: 1.287441 - Hamming-Loss: 0.002609 - Subset-Accuracy: 0.935594 - F1-Score: 0.948492\n",
      "Epoch 4/20\n",
      "790/790 [==============================] - 114s 144ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0072 - val_acc: 0.9983\n",
      "Adiitional val metrics: - ROC-AUC: 0.989440 - Log-Loss: 1.065843 - Hamming-Loss: 0.002554 - Subset-Accuracy: 0.934437 - F1-Score: 0.949558\n",
      "Epoch 5/20\n",
      "790/790 [==============================] - 113s 143ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0070 - val_acc: 0.9983\n",
      "Adiitional val metrics: - ROC-AUC: 0.989972 - Log-Loss: 0.936047 - Hamming-Loss: 0.002542 - Subset-Accuracy: 0.934754 - F1-Score: 0.949800\n",
      "predicting test data ...\n",
      "CAD.event:\n",
      " [[313464    638]\n",
      " [   786    547]] \n",
      "\n",
      "CAD.mention:\n",
      " [[314651    213]\n",
      " [   142    429]] \n",
      "\n",
      "CAD.symptom:\n",
      " [[315085     11]\n",
      " [   329     10]] \n",
      "\n",
      "CAD.test:\n",
      " [[313353    234]\n",
      " [  1476    372]] \n",
      "\n",
      "DIABETES.A1C:\n",
      " [[314977     35]\n",
      " [   358     65]] \n",
      "\n",
      "DIABETES.glucose:\n",
      " [[315206      0]\n",
      " [   229      0]] \n",
      "\n",
      "DIABETES.mention:\n",
      " [[313929    351]\n",
      " [   170    985]] \n",
      "\n",
      "FAMILY_HIST.present:\n",
      " [[315221      0]\n",
      " [   214      0]] \n",
      "\n",
      "HYPERLIPIDEMIA.high_LDL:\n",
      " [[315343      0]\n",
      " [    92      0]] \n",
      "\n",
      "HYPERLIPIDEMIA.high_chol:\n",
      " [[315376      0]\n",
      " [    59      0]] \n",
      "\n",
      "HYPERLIPIDEMIA.mention:\n",
      " [[315014     55]\n",
      " [    84    282]] \n",
      "\n",
      "HYPERTENSION.high_bp:\n",
      " [[314387    300]\n",
      " [   409    339]] \n",
      "\n",
      "HYPERTENSION.mention:\n",
      " [[314610    148]\n",
      " [    68    609]] \n",
      "\n",
      "MEDICATION.ACE_inhibitor:\n",
      " [[314943     56]\n",
      " [   189    247]] \n",
      "\n",
      "MEDICATION.ARB:\n",
      " [[315295      4]\n",
      " [   101     35]] \n",
      "\n",
      "MEDICATION.DPP4_inhibitors:\n",
      " [[315431      0]\n",
      " [     4      0]] \n",
      "\n",
      "MEDICATION.anti_diabetes:\n",
      " [[315435      0]\n",
      " [     0      0]] \n",
      "\n",
      "MEDICATION.aspirin:\n",
      " [[314866     79]\n",
      " [   146    344]] \n",
      "\n",
      "MEDICATION.beta_blocker:\n",
      " [[314646     73]\n",
      " [   334    382]] \n",
      "\n",
      "MEDICATION.calcium_channel_blocker:\n",
      " [[315158      9]\n",
      " [   163    105]] \n",
      "\n",
      "MEDICATION.diuretic:\n",
      " [[315230     27]\n",
      " [    91     87]] \n",
      "\n",
      "MEDICATION.ezetimibe:\n",
      " [[315414      0]\n",
      " [    21      0]] \n",
      "\n",
      "MEDICATION.fibrate:\n",
      " [[315370      0]\n",
      " [    65      0]] \n",
      "\n",
      "MEDICATION.insulin:\n",
      " [[314737    171]\n",
      " [   229    298]] \n",
      "\n",
      "MEDICATION.metformin:\n",
      " [[315052     42]\n",
      " [   149    192]] \n",
      "\n",
      "MEDICATION.niacin:\n",
      " [[315419      0]\n",
      " [    16      0]] \n",
      "\n",
      "MEDICATION.nitrate:\n",
      " [[315147     36]\n",
      " [   147    105]] \n",
      "\n",
      "MEDICATION.statin:\n",
      " [[314827     53]\n",
      " [   233    322]] \n",
      "\n",
      "MEDICATION.sulfonylureas:\n",
      " [[315206     10]\n",
      " [   116    103]] \n",
      "\n",
      "MEDICATION.thiazolidinedione:\n",
      " [[315375      0]\n",
      " [    54      6]] \n",
      "\n",
      "MEDICATION.thienopyridine:\n",
      " [[315197     40]\n",
      " [    55    143]] \n",
      "\n",
      "O:\n",
      " [[  8120   6094]\n",
      " [  3901 297320]] \n",
      "\n",
      "OBESE.BMI:\n",
      " [[315399      0]\n",
      " [    36      0]] \n",
      "\n",
      "OBESE.mention:\n",
      " [[315249     46]\n",
      " [    17    123]] \n",
      "\n",
      "SMOKER.current:\n",
      " [[315219      5]\n",
      " [   210      1]] \n",
      "\n",
      "SMOKER.ever:\n",
      " [[315419      0]\n",
      " [    16      0]] \n",
      "\n",
      "SMOKER.never:\n",
      " [[315033     69]\n",
      " [   117    216]] \n",
      "\n",
      "SMOKER.past:\n",
      " [[314323    250]\n",
      " [   320    542]] \n",
      "\n",
      "SMOKER.unknown:\n",
      " [[315133     92]\n",
      " [   181     29]] \n",
      "\n",
      "preparing gold label targets ...\n",
      "\n",
      "F1 Scores for global labels:\n",
      "ALL (average=\"micro\"): 0.8263177385507963\n",
      "CAD.event:\n",
      " [[ 3347   935]\n",
      " [  472 14778]] \n",
      "\n",
      "CAD.mention:\n",
      " [[14778   472]\n",
      " [  935  3347]] \n",
      "\n",
      "CAD.event: 0.8052805280528054\n",
      "CAD.mention: 0.8888888888888888\n",
      "CAD.symptom: 0.30136986301369867\n",
      "CAD.test: 0.6990291262135923\n",
      "DIABETES.A1C: 0.4672897196261683\n",
      "DIABETES.glucose: 0.0\n",
      "DIABETES.mention: 0.9491525423728814\n",
      "FAMILY_HIST.present: 0.0\n",
      "HYPERLIPIDEMIA.high_LDL: 0.0\n",
      "HYPERLIPIDEMIA.high_chol: 0.0\n",
      "HYPERLIPIDEMIA.mention: 0.9164785553047403\n",
      "HYPERTENSION.high_bp: 0.6733167082294264\n",
      "HYPERTENSION.mention: 0.9796472184531886\n",
      "MEDICATION.ACE_inhibitor: 0.8894348894348895\n",
      "MEDICATION.ARB: 0.5684210526315789\n",
      "MEDICATION.DPP4_inhibitors: 0.0\n",
      "MEDICATION.anti_diabetes: 0.0\n",
      "MEDICATION.aspirin: 0.9581056466302368\n",
      "MEDICATION.beta_blocker: 0.9219858156028368\n",
      "MEDICATION.calcium_channel_blocker: 0.7747747747747747\n",
      "MEDICATION.diuretic: 0.8625\n",
      "MEDICATION.ezetimibe: 0.0\n",
      "MEDICATION.fibrate: 0.0\n",
      "MEDICATION.insulin: 0.9236363636363637\n",
      "MEDICATION.metformin: 0.974169741697417\n",
      "MEDICATION.niacin: 0.0\n",
      "MEDICATION.nitrate: 0.7804878048780487\n",
      "MEDICATION.statin: 0.9285714285714286\n",
      "MEDICATION.sulfonylureas: 0.8235294117647058\n",
      "MEDICATION.thiazolidinedione: 0.3571428571428571\n",
      "MEDICATION.thienopyridine: 0.9441624365482234\n",
      "OBESE.BMI: 0.0\n",
      "OBESE.mention: 0.9392265193370165\n",
      "SMOKER.current: 0.054054054054054064\n",
      "SMOKER.ever: 0.0\n",
      "SMOKER.never: 0.761904761904762\n",
      "SMOKER.past: 0.7634854771784233\n",
      "SMOKER.unknown: 0.2597402597402597\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, hamming_loss, f1_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from models import get_rnn_model\n",
    "from cm import multilabel_confusion_matrix\n",
    "from data_process import get_embedding_matrix, data_generator, get_all_notes_labels, get_features, get_targets, get_gold_label_targets\n",
    "\n",
    "# Customized Evaluation for keras model\n",
    "class CustomEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = list(validation_data)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = []\n",
    "            for x in self.X_val:\n",
    "                y = np.squeeze(self.model.predict_on_batch(x))\n",
    "                y_pred.append(y)\n",
    "            y_pred = np.concatenate(y_pred)\n",
    "            y_pred_ham = y_pred > 0.5\n",
    "            y_val = np.concatenate(self.y_val)\n",
    "            roc = roc_auc_score(y_val, y_pred, average='micro')\n",
    "            loss = log_loss(y_val, y_pred)\n",
    "            ham = hamming_loss(y_val, y_pred_ham)\n",
    "            sub = accuracy_score(y_val, y_pred_ham)\n",
    "            f1 = f1_score(y_val, y_pred_ham, average='micro')\n",
    "            print(\"Adiitional val metrics: - ROC-AUC: %.6f - Log-Loss: %.6f - Hamming-Loss: %.6f - Subset-Accuracy: %.6f - F1-Score: %.6f\" % (roc, loss, ham, sub, f1))\n",
    "            \n",
    "def model_train(param, \n",
    "                notes_train, \n",
    "                labels_train, \n",
    "                up_notes_train, \n",
    "                up_labels_train, \n",
    "                gold_labels_train, \n",
    "                notes_test, \n",
    "                labels_test, \n",
    "                gold_labels_test,\n",
    "                results_file,\n",
    "                verbose=1):\n",
    "    \n",
    "    print('*'*80)\n",
    "    print(\"Parameters (note: embed_size*10, latent_dim*64):\\n\", param)\n",
    "    print('*'*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # assign parameters\n",
    "    up = int(param['up'])\n",
    "    window_size = int(param['window_size'])\n",
    "    embed_size = int(param['embed_size'] * 10)\n",
    "    latent_dim = int(param['latent_dim'] * 64)\n",
    "    dropout_rate = param['dropout_rate']\n",
    "    epochs = param['epochs']\n",
    "    category = param['category']\n",
    "    max_features = 60000 #param['max_features']\n",
    "    train_embed = True #param['train_embed']\n",
    "    model_type = 'CuDNNLSTM' #param['model_type']\n",
    "    \n",
    "    # upsampling\n",
    "    if up > 0:\n",
    "        if verbose != 0: print('upsampling for %d times...' % (up))\n",
    "        notes_train = [note + up * up_note for note, up_note in zip(notes_train, up_notes_train)]\n",
    "        labels_train = [label + up * up_label for label, up_label in zip(labels_train, up_labels_train)]\n",
    "    notes = notes_train + notes_test\n",
    "    labels = labels_train + labels_test\n",
    "    gold_labels = gold_labels_train + gold_labels_test\n",
    "    \n",
    "    # prepare features\n",
    "    X_train_seq, X_test_seq, word_index = get_features(max_features, notes_train, notes_test, verbose=1)\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "\n",
    "    # prepare embedding matrix\n",
    "    if train_embed:\n",
    "        if verbose != 0: print('preparing pretrained embedding matrix ...')\n",
    "        w2v = Word2Vec(notes, size=embed_size, window=window_size, min_count=1, workers=4)\n",
    "        embedding_index = dict(zip(w2v.wv.index2word, w2v.wv.vectors))\n",
    "        embedding_matrix = get_embedding_matrix(embedding_index=embedding_index, \n",
    "                                                word_index=word_index, \n",
    "                                                max_features=max_features, \n",
    "                                                embed_size=embed_size)\n",
    "        \n",
    "    # prepare targets\n",
    "    Y_train, Y_test, mlb, num_labels = get_targets(labels_train, labels_test, category, verbose=1)  \n",
    "\n",
    "    # get rnn model\n",
    "    model = get_rnn_model(nb_words=nb_words, \n",
    "                          num_labels=num_labels, \n",
    "                          embed_size=embed_size, \n",
    "                          latent_dim=latent_dim, \n",
    "                          model_type=model_type, \n",
    "                          embedding_matrix=embedding_matrix, \n",
    "                          dropout=dropout_rate, \n",
    "                          train_embed=train_embed)\n",
    "    if verbose != 0: \n",
    "        print('model summary:')\n",
    "        print(model.summary())\n",
    "    \n",
    "    # model compiling\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # model training\n",
    "    if verbose != 0: print('\\ntraining model ...')\n",
    "    custevl = CustomEvaluation(validation_data=(X_test_seq, Y_test), interval=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=2, verbose=0, mode='auto')\n",
    "    train_gen = data_generator(X_train_seq, Y_train)\n",
    "    test_gen = data_generator(X_test_seq, Y_test)\n",
    "    v = 1 if verbose != 0 else 0  \n",
    "    hist = model.fit_generator(train_gen,\n",
    "                                steps_per_epoch=len(Y_train),\n",
    "                                epochs=epochs,\n",
    "                                validation_data=test_gen,\n",
    "                                validation_steps=len(Y_test),\n",
    "                                callbacks=[custevl, earlystop],\n",
    "                                verbose=v)\n",
    "\n",
    "    # prediction of test data\n",
    "    if verbose != 0: print('predicting test data ...')\n",
    "    Y_pred = []\n",
    "    for x in X_test_seq:\n",
    "        x = np.array(x).reshape((1,-1))\n",
    "        y_pred = np.squeeze(model.predict_on_batch(x))\n",
    "        Y_pred.append(y_pred)\n",
    "    Y_pred_concat = np.concatenate(Y_pred)\n",
    "    Y_val = np.concatenate(Y_test)\n",
    "\n",
    "    # confusion matrix \n",
    "    if verbose == 2: \n",
    "        cm = multilabel_confusion_matrix(Y_val, np.where(Y_pred_concat > 0.5, 1, 0))\n",
    "        for i, j in zip(cm, mlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "\n",
    "    # prepare gold label targets\n",
    "    Y_gold_test, Y_gold_pred, gmlb = get_gold_label_targets(Y_pred, gold_labels, gold_labels_test, mlb, category=category, verbose=1) \n",
    "\n",
    "    # f1 scores for gold label\n",
    "    f1 = f1_score(Y_gold_test, Y_gold_pred, average='micro')\n",
    "    print('\\nF1 Scores for global labels:\\nALL (average=\"micro\"):', f1)\n",
    "    \n",
    "    # confusion matrix for gold label\n",
    "    if verbose == 2: \n",
    "        gcm = multilabel_confusion_matrix(np.concatenate(Y_gold_test), np.concatenate(Y_gold_pred))\n",
    "        for i, j in zip(gcm, gmlb.classes_):\n",
    "            print(j+':\\n', i,'\\n')\n",
    "    \n",
    "    # f1 score list\n",
    "    if verbose == 2: \n",
    "        f1_all = f1_score(Y_gold_test, Y_gold_pred, average=None)\n",
    "        for i, j in zip(f1_all, gmlb.classes_):\n",
    "            print(j+': '+str(i))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # save results\n",
    "    with open(results_file,\"a\") as f:\n",
    "        f.write(\"Parameters (note: embed_size*10, ltent_dim*64):\\n\" + str(param))\n",
    "        f.write('\\nF1 Scores for global labels(average=\"micro\"): %.3f; Running time: %.1f\\n' % (f1, elapsed_time))\n",
    "          \n",
    "    return f1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # loading data \n",
    "    if os.path.exists('loaded_data.dat'):\n",
    "        \n",
    "        with open('loaded_data.dat','rb') as f:\n",
    "            notes_train = pickle.load(f)\n",
    "            labels_train = pickle.load(f)\n",
    "            up_notes_train = pickle.load(f)\n",
    "            up_labels_train = pickle.load(f)\n",
    "            gold_labels_train = pickle.load(f)\n",
    "            notes_test = pickle.load(f)\n",
    "            labels_test = pickle.load(f)\n",
    "            gold_labels_test = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        notes_train_1, labels_train_1, up_notes_train_1, up_labels_train_1, gold_labels_train_1 = get_all_notes_labels('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set1') \n",
    "        notes_train_2, labels_train_2, up_notes_train_2, up_labels_train_2, gold_labels_train_2 = get_all_notes_labels('/host_home/data/i2b2/2014/training/training-RiskFactors-Complete-Set2') \n",
    "\n",
    "        notes_train = notes_train_1 + notes_train_2\n",
    "        labels_train = labels_train_1 + labels_train_2\n",
    "        up_notes_train = up_notes_train_1 + up_notes_train_2\n",
    "        up_labels_train = up_labels_train_1 + up_labels_train_2\n",
    "        gold_labels_train = gold_labels_train_1 + gold_labels_train_2\n",
    "\n",
    "        notes_test, labels_test, _1, _2, gold_labels_test = get_all_notes_labels('/host_home/data/i2b2/2014/testing/testing-RiskFactors-Complete')\n",
    "\n",
    "        with open('loaded_data.dat','wb') as f:\n",
    "            pickle.dump(notes_train, f)\n",
    "            pickle.dump(labels_train, f)\n",
    "            pickle.dump(up_notes_train, f)\n",
    "            pickle.dump(up_labels_train, f)\n",
    "            pickle.dump(gold_labels_train, f)\n",
    "            pickle.dump(notes_test, f)\n",
    "            pickle.dump(labels_test, f)\n",
    "            pickle.dump(gold_labels_test, f)\n",
    "\n",
    "    # loading parameters space\n",
    "    param = {'up': 5, 'window_size': 3, 'embed_size': 5, 'latent_dim': 5, 'dropout_rate': 0.0, 'epochs': 20, 'category': 'cat_ind'}\n",
    "    \n",
    "    results_file = \"demo_results_\" + time.strftime(\"%Y%m%d\") + \".txt\"\n",
    "    \n",
    "    model_train(param, \n",
    "                notes_train, \n",
    "                labels_train, \n",
    "                up_notes_train, \n",
    "                up_labels_train, \n",
    "                gold_labels_train, \n",
    "                notes_test, \n",
    "                labels_test, \n",
    "                gold_labels_test,\n",
    "                results_file=results_file,\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
